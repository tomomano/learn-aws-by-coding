<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="Tomoyuki Mano">
<title>Learn AWS by Coding (LABC)</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Learn AWS by Coding (LABC)</h1>
<div class="details">
<span id="author" class="author">Tomoyuki Mano</span><br>
<span id="email" class="email"><a href="mailto:tomoyukimano@gmail.com">tomoyukimano@gmail.com</a></span><br>
<span id="revnumber">version 1.0-en,</span>
<span id="revdate">2021-09-17</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introduction">1. Introduction</a>
<ul class="sectlevel2">
<li><a href="#_purpose_and_content_of_this_book">1.1. Purpose and content of this book</a></li>
<li><a href="#_philosophy_of_this_book">1.2. Philosophy of this book</a></li>
<li><a href="#_aws_account">1.3. AWS account</a></li>
<li><a href="#_setting_up_an_environment">1.4. Setting up an environment</a></li>
<li><a href="#_docker_image_for_the_hands_on_exercise">1.5. Docker image for the hands-on exercise</a></li>
<li><a href="#_prerequisite_knowledge">1.6. Prerequisite knowledge</a></li>
<li><a href="#_source_code">1.7. Source code</a></li>
<li><a href="#_notations_used_in_this_book">1.8. Notations used in this book</a></li>
</ul>
</li>
<li><a href="#chap_cloud_basics">2. Cloud Computing Basics</a>
<ul class="sectlevel2">
<li><a href="#_what_is_the_cloud">2.1. What is the cloud?</a></li>
<li><a href="#_why_use_the_cloud">2.2. Why use the cloud?</a></li>
</ul>
</li>
<li><a href="#sec_aws_general_introduction">3. Introduction to AWS</a>
<ul class="sectlevel2">
<li><a href="#_what_is_aws">3.1. What is AWS?</a></li>
<li><a href="#_functions_and_services_provided_by_aws">3.2. Functions and services provided by AWS</a></li>
<li><a href="#_regions_and_availability_zones">3.3. Regions and Availability Zones</a></li>
<li><a href="#_cloud_development_in_aws">3.4. Cloud development in AWS</a></li>
<li><a href="#sec:intro_cloudformation">3.5. CloudFormation and AWS CDK</a></li>
</ul>
</li>
<li><a href="#sec_first_ec2">4. Hands-on #1: Launching an EC2 instance</a>
<ul class="sectlevel2">
<li><a href="#handson_01_prep">4.1. Preparation</a></li>
<li><a href="#_ssh">4.2. SSH</a></li>
<li><a href="#_reading_the_application_source_code">4.3. Reading the application source code</a></li>
<li><a href="#sec_handson_ec2_run">4.4. Deploying the application</a></li>
<li><a href="#_summary">4.5. Summary</a></li>
</ul>
</li>
<li><a href="#sec_scientific_computing">5. Scientific computing and machine learning in the cloud</a>
<ul class="sectlevel2">
<li><a href="#_why_use_the_cloud_for_machine_learning">5.1. Why use the cloud for machine learning?</a></li>
<li><a href="#_accelerating_deep_learning_by_gpu">5.2. Accelerating deep learning by GPU</a></li>
</ul>
</li>
<li><a href="#sec_jupyter_and_deep_learning">6. Hands-on #2: Running Deep Learning on AWS</a>
<ul class="sectlevel2">
<li><a href="#sec:jupyter_and_deep_learning_setup">6.1. Preparation</a></li>
<li><a href="#_reading_the_application_source_code_2">6.2. Reading the application source code</a></li>
<li><a href="#_deploying_the_application">6.3. Deploying the application</a></li>
<li><a href="#_log_in_to_the_instance">6.4. Log in to the instance</a></li>
<li><a href="#_launching_jupyter_notebook">6.5. Launching Jupyter Notebook</a></li>
<li><a href="#_introduction_to_pytorch">6.6. Introduction to PyTorch</a></li>
<li><a href="#sec_mnist_using_jupyter">6.7. MNIST Handwritten Digit Recognition Task</a></li>
<li><a href="#_deleting_the_stack">6.8. Deleting the stack</a></li>
</ul>
</li>
<li><a href="#sec_docker_introduction">7. Introduction to Docker</a>
<ul class="sectlevel2">
<li><a href="#_scaling_up_machine_learning">7.1. Scaling up machine learning</a></li>
<li><a href="#_what_is_docker">7.2. What is Docker?</a></li>
<li><a href="#_docker_tutorial">7.3. Docker tutorial</a></li>
<li><a href="#_elastic_container_service_ecs">7.4. Elastic Container Service (ECS)</a></li>
</ul>
</li>
<li><a href="#sec_fargate_qabot">8. Hands-on #3: Deploying a question-answering bot on AWS</a>
<ul class="sectlevel2">
<li><a href="#_fargate">8.1. Fargate</a></li>
<li><a href="#_preparations">8.2. Preparations</a></li>
<li><a href="#_a_question_answering_bot_using_transformer">8.3. A question-answering bot using Transformer</a></li>
<li><a href="#_reading_the_application_source_code_3">8.4. Reading the application source code</a></li>
<li><a href="#_deploying_the_application_2">8.5. Deploying the application</a></li>
<li><a href="#_executing_a_task">8.6. Executing a task</a></li>
<li><a href="#_executing_tasks_in_parallel">8.7. Executing tasks in parallel</a></li>
<li><a href="#_deleting_the_stack_2">8.8. Deleting the stack</a></li>
</ul>
</li>
<li><a href="#sec_aws_batch">9. Hands-on #4: Using AWS Batch to Parallelize Hyperparameter Search for Machine Learning</a>
<ul class="sectlevel2">
<li><a href="#_auto_scaling_groups_asg">9.1. Auto scaling groups (ASG)</a></li>
<li><a href="#_aws_batch">9.2. AWS Batch</a></li>
<li><a href="#_preparations_2">9.3. Preparations</a></li>
<li><a href="#sec_run_mnist_docker_local">9.4. Revisiting MNIST handwritten digit recognition task</a></li>
<li><a href="#sec:aws_batch_code">9.5. Reading the application source code</a></li>
<li><a href="#_deploying_the_stack">9.6. Deploying the stack</a></li>
<li><a href="#sec:aws_batch_deploy_docker_on_ecr">9.7. Deploying Docker image on ECR</a></li>
<li><a href="#_submitting_a_single_job">9.8. Submitting a single job</a></li>
<li><a href="#sec:batch_parallel_jobs">9.9. Submitting parallel jobs</a></li>
<li><a href="#sec:batch_destroy_app">9.10. Deleting the stack</a></li>
<li><a href="#_short_summary">9.11. Short summary</a></li>
</ul>
</li>
<li><a href="#_how_to_create_web_services">10. How to create web services</a>
<ul class="sectlevel2">
<li><a href="#_how_web_services_workusing_twitter_as_an_example">10.1. How Web Services Work&#8201;&#8212;&#8201;Using Twitter as an Example</a></li>
<li><a href="#sec_rest_api">10.2. REST API</a></li>
<li><a href="#_twitter_api">10.3. Twitter API</a></li>
</ul>
</li>
<li><a href="#sec_serverless">11. Serverless architecture</a>
<ul class="sectlevel2">
<li><a href="#chap_serverful_cloud">11.1. Serverful cloud (conventional cloud)</a></li>
<li><a href="#_to_the_serverless_cloud">11.2. To the serverless cloud</a></li>
<li><a href="#_components_that_make_up_a_serverless_cloud">11.3. Components that make up a serverless cloud</a></li>
</ul>
</li>
<li><a href="#sec_intro_serverless">12. Hands-on #5: Introduction to serverless computing</a>
<ul class="sectlevel2">
<li><a href="#_lambda_hands_on">12.1. Lambda hands-on</a></li>
<li><a href="#sec:dynamodb_tutorial">12.2. DynamoDB hands-on</a></li>
<li><a href="#sec:s3_tutorial">12.3. S3 hands-on</a></li>
</ul>
</li>
<li><a href="#sec_bashoutter">13. Hands-on #6: Bashoutter</a>
<ul class="sectlevel2">
<li><a href="#_preparation">13.1. Preparation</a></li>
<li><a href="#_reading_the_application_source_code_4">13.2. Reading the application source code</a></li>
<li><a href="#_deploying_the_application_4">13.3. Deploying the application</a></li>
<li><a href="#sec:bashoutter_test_api">13.4. Sending API requests</a></li>
<li><a href="#_simulating_a_large_simultaneous_api_request">13.5. Simulating a large simultaneous API request</a></li>
<li><a href="#_interacting_with_bashoutter_gui">13.6. Interacting with Bashoutter GUI</a></li>
<li><a href="#_deleting_the_stack_5">13.7. Deleting the stack</a></li>
<li><a href="#_short_summary_2">13.8. Short summary</a></li>
</ul>
</li>
<li><a href="#sec:appendix_settingup">14. Appendix: Environment setup</a>
<ul class="sectlevel2">
<li><a href="#sec:create_aws_account">14.1. Creating an AWS account</a></li>
<li><a href="#aws_secrets">14.2. Creating AWS access key</a></li>
<li><a href="#aws_cli_install">14.3. Installing AWS CLI</a></li>
<li><a href="#aws_cdk_install">14.4. Installing AWS CDK</a></li>
<li><a href="#sec:install_wsl">14.5. Installing WSL</a></li>
<li><a href="#sec:install_docker">14.6. Installing Docker</a></li>
<li><a href="#venv_quick_guide">14.7. Quick tutorial on Python <code>venv</code></a></li>
<li><a href="#sec_handson_docker">14.8. Working with Docker image for the hands-on exercise</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>The source code of the hands-on exercises are available at the following link: <a href="https://github.com/tomomano/learn-aws-by-coding" class="bare">https://github.com/tomomano/learn-aws-by-coding</a></p>
</div>
<div class="paragraph">
<p><strong>ðŸŒŽJapanese version is available
<a href="https://tomomano.github.io/learn-aws-by-coding/">here</a>ðŸŒŽ</strong></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_purpose_and_content_of_this_book">1.1. Purpose and content of this book</h3>
<div class="paragraph">
<p>This book was prepared as a lecture material for "Special Lectures on Information Physics and Computing", which was offered in the S1/S2 term of the 2021 academic year at the Department of Mathematical Engineering and Information Physics, the University of Tokyo.</p>
</div>
<div class="paragraph">
<p>The purpose of this book is to explain the basic knowledge and concepts of cloud computing for beginners.
It provides hands-on tutorials to use real cloud environment provided by Amazon Web Services (AWS).</p>
</div>
<div class="paragraph">
<p>We assume that the readers would be students majoring science or engineering at college, or software engineers who are starting to develop cloud applications.
We will introduce pracitcal steps to use the cloud for research and web application development.
We plan to keep this course as interactive and practical as possible, and for that purpose, less emphasis is placed on the theories and knowledge, and more effort is placed on writing real programs.
I hope that this book serves as a stepping stone for readers to use cloud computing in their future research and applications.</p>
</div>
<div class="paragraph">
<p>The book is divided into three parts:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Structure of this book</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 40%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"></th>
<th class="tableblock halign-left valign-top">Theme</th>
<th class="tableblock halign-left valign-top">Hands-on</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1st Part (Section 1 to 4)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloud Fundamentals</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="ulist">
<ul>
<li>
<p>Launching an EC2 instance</p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2nd Part (Section 5 to 9)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Machine Learning using Cloud</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="ulist">
<ul>
<li>
<p>Deep Learning by using AWS and Jupyter</p>
</li>
<li>
<p>Creating a scalable question-answering bot</p>
</li>
<li>
<p>Massively parallelized hyperparameter search</p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3rd Part (Section 10 to 13)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Introduction to Serverless Architecture</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="ulist">
<ul>
<li>
<p>Tutorials on Lambda, DynamoDB, and S3</p>
</li>
<li>
<p>"Bashoutter", a SNS for Haiku</p>
</li>
</ul>
</div></div></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>In the first part, we explain the basic concepts and knowledge of cloud computing.
Essential ideas necessary to safely and cleverly use cloud will be covered, including security and networking.
In the hands-on session, we will practice setting up <strong>a simple virtual server on AWS using AWS API and AWS CDK</strong>.</p>
</div>
<div class="paragraph">
<p>In the second part, we introduce the cocenpts and techniques for running <strong>scientific computing</strong> (especially <strong>machine learning</strong>) in the cloud.
In parallel, we will learn a modern virtual coumputing environment called <a href="https://www.docker.com/">Docker</a>.
In the first hands-on session, we will run Jupyter Notebook in the AWS cloud and run a simple machine learning program.
In the second hands-on, we will create a bot that automatically generates answers to questions using natural language model powered by deep neural network.
In the third hands-on, we will show how to launch a cluster with multiple GPU instances and perform massively parallel hyperparameter search for deep learning.</p>
</div>
<div class="paragraph">
<p>In the third part, we introduce the latest cloud architecture called <strong>serverless architecture</strong>.
This architecture introduces radically different design concept to the cloud than the previous one (often referred to as Serverful), as it allows the processing capacity of the cloud system to be scaled up or down more flexibly depending on the load.
In the first hands-on session, we will provide exercises on Lambda, DynamoDB, and S3, which are the main components of the serverless cloud.
In addition, we will create a simple yet quite useful social network service (SNS) in the cloud using serverless technology.</p>
</div>
<div class="paragraph">
<p>These extensive hands-on sessions will provide you with the knowledge and skills to develop your own cloud system on AWS.
All of the hands-on programs are designed to be practical, and can be customized for a variety of applications.</p>
</div>
</div>
<div class="sect2">
<h3 id="_philosophy_of_this_book">1.2. Philosophy of this book</h3>
<div class="paragraph">
<p>The philosophy of this book can be summed up in one word:
<strong>"Let&#8217;s fly to space in a rocket and look at the earth once!"</strong></p>
</div>
<div class="paragraph">
<p>What does that mean?</p>
</div>
<div class="paragraph">
<p>The "Earth" here refers to the whole picture of cloud computing.
Needless to say, cloud computing is a very broad and complex concept, and it is the sum of many information technologies, hardware, and algorithms that have been elaborately woven together.
Today, many parts of our society, from scientific research to everyday infrastructure, are supported by cloud technology.</p>
</div>
<div class="paragraph">
<p>The word "rocket" here refers to this lecture.
In this lecture, readers will fly into space on a rocket and look at the entire earth (cloud) with their own eyes.
In this journey, we do not ask deeply about the detailed machinery of the rocket (i.e. elaborate theories and algorithms).
Rather, the purpose of this book is to let you actually touch the cutting edge technologies of cloud computing and realize what kind of views (and applications) are possible from there.</p>
</div>
<div class="paragraph">
<p>For this reason, this book covers a wide range of topics from the basics to advanced applications of cloud computing.
The first part of the book starts with the basics of cloud computing, and the second part takes it to the next level by explaining how to execute machine learning algorithms in the cloud.
In the third part, we will explain serverless architecture, a completely new cloud design that has been established in the last few years.
Each of these topic is worth more than one book, but this book was written with the ambitious intention of combining them into a single volume and providing a integrative and comprehensive overview.</p>
</div>
<div class="paragraph">
<p>It may not be an easy ride, but we promise you that if you hang on to this rocket, you will get to see some very exciting sights.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="imgs/earth_from_earth.jpg" alt="earth" width="500">
</div>
<div class="title">Figure 1. Earth viewed from space (Image from NASA <a href="https://www.nasa.gov/image-feature/planet-of-clouds" class="bare">https://www.nasa.gov/image-feature/planet-of-clouds</a>)</div>
</div>
</div>
<div class="sect2">
<h3 id="_aws_account">1.3. AWS account</h3>
<div class="paragraph">
<p>This book provides hands-on tutorials to run and deploy applications on AWS.
Readers must have their own AWS account to run the hands-on excercises.
A brief description of how to create an AWS account is given in the appendix at the end of the book (<a href="#sec:create_aws_account">Section 14.1</a>), so please refer to it if necessary.</p>
</div>
<div class="paragraph">
<p>AWS offers free access to some features, and some hands-on excercises can be done for free.
Other hands-on sessions (especially those dealing with machine learning) will cost a few dollars.
The approximate cost of each hands-on is described at the begining of the excercise, so please be aware of the potential cost.</p>
</div>
<div class="paragraph">
<p>In addition, when using AWS in lectures at universities and other educational institutions,
<a href="https://aws.amazon.com/education/awseducate/">AWS Educate</a>
program is available.
This program offers educators various teaching resources, including the AWS credits which students taking the course can use to run applications in the AWS cloud.
By using AWS Educate, students can experience AWS without any financial cost.
It is also possible for individuals to participate in AWS Educate without going through lectures.
AWS Educate provides a variety of learning materials, and I encourage you to take advantage of them.</p>
</div>
</div>
<div class="sect2">
<h3 id="_setting_up_an_environment">1.4. Setting up an environment</h3>
<div class="paragraph">
<p>In this book, we will provide hands-on sessions to deploy a cloud application on AWS.
The following computer environment is required to run the programs provided in this book.
The installation procedure is described in the appendix at the end of the book (<a href="#sec:appendix_settingup">Section 14</a>).
Refer to the appendix as necessary and set up an environment in your local computer.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>UNIX console</strong>:
A UNIX console is required to execute the commands and access the server via SSH.
Mac or Linux users can use the console (also known as a terminal) that comes standard with the OS.
For Windows users, we recommend to install
<a href="https://docs.microsoft.com/en-us/windows/wsl/about">Windows Subsystem for Linux (WSL)</a>
and set up a virtual Linux environment
(see <a href="#sec:install_wsl">Section 14.5</a> for more details).</p>
</li>
<li>
<p><strong><a href="https://www.docker.com/">Docker</a></strong>:
This book explains how to use a virtual computing environment called Docker.
For the installation procedure, see <a href="#sec:install_docker">Section 14.6</a>.</p>
</li>
<li>
<p><strong><a href="https://github.com/python">Python</a></strong>:
Version 3.6 or later is required.
We will also use <code>venv</code> module to run programs.
A quick tutorial on <code>venv</code> module is provided in the appendix (<a href="#venv_quick_guide">Section 14.7</a>).</p>
</li>
<li>
<p><strong><a href="https://github.com/nodejs/node">Node.js</a></strong>:
Version 12.0 or later is required.</p>
</li>
<li>
<p><strong><a href="https://github.com/aws/aws-cli">AWS CLI</a></strong>:
WS CLI
<a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">Version 2</a>
is required.
Refer to <a href="#aws_cli_install">Section 14.3</a> for installation and setup procedure.</p>
</li>
<li>
<p><strong><a href="https://github.com/aws/aws-cdk">AWS CDK</a></strong>:
Version 1.00 or later is required.
The tutorials are not compatible with version 2.
Refer to <a href="#aws_cdk_install">Section 14.4</a> for installation and setup procedure.</p>
</li>
<li>
<p><strong>AWS secret keys</strong>:
In order to call the AWS API from the command line, an authentication key (secret key) must be set.
Refer to <a href="#aws_cli_install">Section 14.3</a> for the setting of the authentication key.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_docker_image_for_the_hands_on_exercise">1.5. Docker image for the hands-on exercise</h3>
<div class="paragraph">
<p>We provide a Docker image with the required programs installed, such as Python, Node.js, and AWS CDK.
The source code of the hands-on program has also been included in the image.
If you already know how to use Docker, then you can use this image to immediately start the hands-on tutorials without having to install anything else.</p>
</div>
<div class="paragraph">
<p>Start the the container with the followign command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">-it</span> tomomano/labc</code></pre>
</div>
</div>
<div class="paragraph">
<p>More details on this Docker image is given in the appendix (<a href="#sec_handson_docker">Section 14.8</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="_prerequisite_knowledge">1.6. Prerequisite knowledge</h3>
<div class="paragraph">
<p>The only prerequisite knowledge required to read this book is an elementary level understanding of the computer science taught at the universities (OS, programming, etc.).
No further prerequisite knowledge is assumed.
There is no need to have any experience using cloud computing.
However, the following prior knowledge will help you to understand more smoothly.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Basic skills in Python</strong>:
In this book, we will use Python to write programs.
The libraries we will be using are sufficiently abstract that most of the functions make sense just by looking at their names.
There is no need to worry if you are not very familiar with Python.</p>
</li>
<li>
<p><strong>Basic skills in Linux command line</strong>:
When using the cloud, the servers that are launched on the cloud are usually Linux.
If you have knowledge of the Linux command line, it will be easier to troubleshoot.
If you feel unconfident about using command line, I recommend this book:
<a href="http://linuxcommand.org/tlcl.php">The Linux Command Line by William Shotts</a>.
It is available for free on the web.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_source_code">1.7. Source code</h3>
<div class="paragraph">
<p>The source code of the hands-on tutorials is available at the following GitHub repository.</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/tomomano/learn-aws-by-coding" class="bare">https://github.com/tomomano/learn-aws-by-coding</a></p>
</div>
</div>
<div class="sect2">
<h3 id="_notations_used_in_this_book">1.8. Notations used in this book</h3>
<div class="ulist">
<ul>
<li>
<p>Code and shell commands are displayed with <code>monospace letters</code></p>
</li>
<li>
<p>The shell commands are prefixed with <code>$</code> symbol to make it clear that they are shell command.
The <code>$</code> must be removed when copying and pasting the command.
On the other hand, note that the output of a command does not have the <code>$</code> prefix.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In addition, we provide warnings and tips in the boxes.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Additional comments are provided here.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Advanced discussions and ideas are provided here.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Common mistakes will be provided here.
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Mistakes that should never be made will be provided here.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="chap_cloud_basics">2. Cloud Computing Basics</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_what_is_the_cloud">2.1. What is the cloud?</h3>
<div class="imageblock text-center">
<div class="content">
<img src="imgs/cloud_word_art.png" alt="Cloud" width="400">
</div>
</div>
<div class="paragraph">
<p>What is the cloud?
The term "cloud" has a very broad meaning in itself, so it is difficult to give a strict definition.
In academic context,
<a href="https://csrc.nist.gov/publications/detail/sp/800-145/final">The NIST Definition of Cloud Computing</a>,
published by National Institute of Standards and Technology (NIST), is often cited to define cloud computing.
The definition and model of cloud described here is illustrated in <a href="#fig:nist_cloud_definition">Figure 2</a>.</p>
</div>
<div id="fig:nist_cloud_definition" class="imageblock text-center">
<div class="content">
<img src="imgs/nist_cloud_definition.png" alt="Cost" width="700">
</div>
<div class="title">Figure 2. The NIST Definition of Cloud Computing</div>
</div>
<div class="paragraph">
<p>According to this, a cloud is a collection of hardware and software that meets the following requirements.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>On-demand self-service</strong>:
Computational resources are automatically allocated according to the user&#8217;s request.</p>
</li>
<li>
<p><strong>Broad network access</strong>:
Users can access the cloud through the network.</p>
</li>
<li>
<p><strong>Resource pooling</strong>:
The cloud provider allocates computational resources to multiple users by dividing the owned computational resources.</p>
</li>
<li>
<p><strong>Rapid elasticity</strong>:
To be able to quickly expand or reduce computational resources according to the user&#8217;s request.</p>
</li>
<li>
<p><strong>Measured service</strong>:
To be able to measure and monitor the amount of computing resources used.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This may sound too abstract for you to understand.
Let&#8217;s talk about it in more concrete terms.</p>
</div>
<div class="paragraph">
<p>If you wanted to upgrade the CPU on your personal computer, you would have to physically open the chassis, expose the CPU socket, and replace it with a new CPU.
Or, if the storage is full, you will need to remove the old disk and insert a new one.
When the computer is moved to a new location, it will not be able to connect to the network until the LAN cable of the new room is plugged in.</p>
</div>
<div class="paragraph">
<p>In the cloud, these operations can be <strong>performed by commands from a program</strong>.
If you want 1000 CPUs, you can send a request to the cloud provider.
Within a few minutes, you will be allocated 1000 CPUs.
If you want to expand your storage from 1TB to 10TB, you can send such command (you may be familiar with this from services such as Google Drive or Dropbox).
When you are done using the compute resources, you can tell the provider about it, and the allocation will be deleted immediately.
The cloud provider accurately monitors the amount of computing resources used, and calculates the usage fee based on that amount.</p>
</div>
<div class="paragraph">
<p>Namely, the essence of the cloud is the virtualization and abstraction of physical hardware, and <strong>users can manage and operate physical hardware through commands as if it were a part of software</strong>.
Of course, behind the scenes, a huge number of computers in data centers are running, consuming a lot of power.
The cloud provider achieves this virtualization and abstraction by cleverly managing the computational resources in the data center and providing the user with a software interface.
From the cloud provider&#8217;s point of view, they are able to maximize their profit margin by renting out computers to a large number of users and keeping the data center utilization rate close to 100% at all times.</p>
</div>
<div class="paragraph">
<p>In the author&#8217;s words, the key characteristics of the cloud can be defined as follows:</p>
</div>
<div class="quoteblock">
<blockquote>
The cloud is an abstraction of computing hardware.
In other words, it is a technology that makes it possible to manipulate, expand, and connect physical hardware as if it were part of software.
</blockquote>
</div>
<div class="paragraph">
<p>Coming back to The NIST Definition of Cloud Computing mentioned above, the following three forms of cloud services are defined (<a href="#fig:nist_cloud_definition">Figure 2</a>).</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Software as a Service (SaaS)</strong></p>
<div class="paragraph">
<p>A form of service that provides users with application running in the cloud.
Examples include Google Drive and Slack.
The user does not directly touch the underlying cloud infrastructure (network, servers, etc.), but use the cloud services provided as applications.</p>
</div>
</li>
<li>
<p><strong>Platform as a Service (PaaS)</strong></p>
<div class="paragraph">
<p>A form of service that provides users with an environment for deploying customer-created applications (which in most cases consist of a database and server code for processing API requests).
In PaaS, the user does not have direct access to the cloud infrastructure, and the scaling of the server is handled by the cloud provider.
Examples include Google App Engine and Heroku.</p>
</div>
</li>
<li>
<p><strong>Infrastructure as a Service (IaaS)</strong></p>
<div class="paragraph">
<p>A form of service that provides users with actual cloud computing infrastructure on a pay-as-you-go basis.
The users rent the necessary network, servers, and storage from the provider, and deploy and operate their own applications on it.
An example of IaaS is AWS EC2.</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>This book mainly deals with cloud development in IaaS.
In other words, it is cloud development in which the developer directly manipulates the cloud infrastructure, configures the desired network, server, and storage from scratch, and deploys the application on it.
In this sense, cloud development can be divided into two steps: <strong>the step of building a program that defines the cloud infrastructure</strong> and <strong>the step of crafting an application that actually runs on the infrastructure</strong>.
These two steps can be separated to some extent as a programmer&#8217;s skill set, but an understanding of both is essential to build the most efficient and optimized cloud system.
This book primarily focuses on the former (operating the cloud infrastructure), but also covers the application layer.
PaaS is a concept where the developer focuses on the application layer development and relies on the cloud provider for the cloud infrastructure.
PaaS reduces development time by eliminating the need to develop the cloud infrastructure, but has the limitation of not being able to control the detailed behavior of the infrastructure.
This book does not cover PaaS techniques and concepts.</p>
</div>
<div class="paragraph">
<p>SaaS can be considered a development "product" in the context of this book.
In other words, the final goal of development is to provide a computational service or database on the available to the general public by deploying the programs on IaaS platform.
As a practical demonstration, we will provide hands-on exercises such as creating a simple SNS (<a href="#sec_bashoutter">Section 13</a>).</p>
</div>
<div class="paragraph">
<p>Recently, Function as a Service (FaaS) and serverless computing have been recognized as new cloud categories.
These concepts will be discussed in detail in later chapters (<a href="#sec_intro_serverless">Section 12</a>).
As will become clear as you read through this book, cloud technology is constantly and rapidly evolving.
This book first touches on traditional cloud design concepts from a practical and educational point of view, and then covers the latest technologies such as serverless.</p>
</div>
<div class="paragraph">
<p>Finally, according to The NIST Definition of Cloud Computing, the following four types of cloud deployment model are defined (<a href="#fig:nist_cloud_definition">Figure 2</a>).
<strong>Private cloud</strong> is a cloud used only within a specific organization, group, or company.
For example, universities and research institutes often operate large-scale computer servers for their members.
In a private cloud, any member of the organization can run computations for free or at a very low cost.
However, the upper limit of available computing resources is often limited, and there may be a lack of flexibility when expanding.</p>
</div>
<div class="paragraph">
<p><strong>Pubclic cloud</strong> is a cloud that is offered as a commercial service to general customers.
Examples of famous public cloud platforms include
<a href="https://cloud.google.com/">Google Cloud Platform (GCP)</a> provided by Google,
<a href="https://azure.microsoft">Azure</a> provided by Microsoft,
and <a href="https://aws.amazon.com">Amazon Web Services (AWS)</a> provided by Amazon.
When you use a public cloud, you pay the usage cost set by the provider.
In return, you get access to the computational resources of the company operating the huge data center, so it is not an exaggeration to say that the computational capacity is inexhaustible.</p>
</div>
<div class="paragraph">
<p>The third type of cloud operation is called <strong>community cloud</strong>.
This refers to a cloud that is shared and operated by groups and organizations that share the same objectives and roles, such as government agencies.
Finally, there is the <strong>hybrid cloud</strong>, which is a cloud composed of a combination of private, public, and community clouds.
An example of hybrid cloud would be a case where some sensitive and privacy-related information is kept in the private cloud, while the rest of the system depends on the public cloud.</p>
</div>
<div class="paragraph">
<p>This book is basically about cloud development using public clouds.
In particular, we will use Amazon Web Services (AWS) to learn specific techniques and concepts.
Note, however, that techniques such as server scaling and virtual computing environments are common to all clouds, so you should be able to acquire knowledge that is generally applicable regardless of the cloud platform.</p>
</div>
</div>
<div class="sect2">
<h3 id="_why_use_the_cloud">2.2. Why use the cloud?</h3>
<div class="paragraph">
<p>As mentioned above, the cloud is a computational environment where computational resources can be flexibly manipulated through programs.
In this section, we would like to discuss why using the cloud is better than using a real local computing environment.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Scalable server size</strong></p>
<div class="paragraph">
<p>When you start a new project, it&#8217;s hard to know in advance how much compute capacity you&#8217;ll ever need.
Buying a large server is risky.
On the other hand, a server that is too small can be troublesome to upgrade later on.
By using the cloud, you can secure the right amount of computing resources you need as you proceed with your project.</p>
</div>
</li>
<li>
<p><strong>Free from hardware maintainance</strong></p>
<div class="paragraph">
<p>Sadly, computers do get old.
With the rate at which technology is advancing these days, after five years, even the newest computers of the day are no more than fossils.
Replacing the server every five years would be a considerable hassle.
It is also necessary to deal with unexpected failures such as power outages and breakdowns of servers.
With cloud computing, there is no need for the user to worry about such things, as the provider automatically takes care of the infrastructure maintenance.</p>
</div>
</li>
<li>
<p><strong>Zero initial cost</strong></p>
<div class="paragraph">
<p><a href="#cloud_economic_curve">Figure 3</a> shows the economic cost of using your own computing environment versus the cloud.
The initial cost of using the cloud is basically zero.
After that, the cost increases according to the amount
of usage.
On the other hand, a large initial cost is incurred when using your own computing environment.
After the initial investment, the increase in cost is limited to electricity and server maintenance costs, so the slope is smaller than in the case of using the cloud.
Then, after a certain period of time, there may be step-like expenditures for server upgrades.
The cloud, on the other hand, incur no such discontinuous increase in cost.
In the areas where cost curve of the cloud is below that of local computing environment, using the cloud will lead to economic cost savings.</p>
</div>
</li>
</ol>
</div>
<div id="cloud_economic_curve" class="imageblock text-center">
<div class="content">
<img src="imgs/cloud_cost.png" alt="Cost" width="500">
</div>
<div class="title">Figure 3. Cost curve for cloud and local server</div>
</div>
<div class="paragraph">
<p>In particular, point 1 is important in research situations.
In research, there are few cases in which one must keep running computations all the time.
Rather, the computational load is likely to increase intensively and unexpectedly when a new algorithm is conceived, or when new data arrives.
In such cases, the ability to flexibly increase computing power is a major advantage of using the cloud.</p>
</div>
<div class="paragraph">
<p>So far, we have discussed the advantages of using the cloud, but there are also some disadvantages.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>The cloud must be used wisely</strong></p>
<div class="paragraph">
<p>As shown in the cost curve in <a href="#cloud_economic_curve">Figure 3</a>, depending on your use case, there may be situations where it is more cost effective to use local computing environment.
When using the cloud, users are required to manage their computing resources wisely, such as deleting intances immediately after use.</p>
</div>
</li>
<li>
<p><strong>Security</strong></p>
<div class="paragraph">
<p>The cloud is accessible from anywhere in the world via the Internet, and can be easily hacked if security management is neglected.
If the cloud is hacked, not only will information be leaked, but there is also the possibility of financial loss.</p>
</div>
</li>
<li>
<p><strong>Learning Curve</strong></p>
<div class="paragraph">
<p>As described above, there are many points to keep in mind when using the cloud, such as cost and security.
In order to use the cloud wisely, it is indispensable to have a good understanding of the cloud and to overcome the learning curve.</p>
</div>
</li>
</ol>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Column: Origin of the word "Terminal"</div>
<div class="paragraph">
<p>The black screen that you use to enter commands on Mac or Linux is called a terminal.
Do you know the origin of this word?</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="imgs/terminal.png" alt="Terminal" width="400">
</div>
</div>
<div class="paragraph">
<p>The origin of this word goes back to the early days of computers.
At that time, a computer was a machine the size of a conference room, with thousands of vacuum tubes connected together.
Since it was such an expensive and complex piece of equipment, it was natural that it would be shared by many people.
In order for users to access the computer, there were several cables running from the machine, each with a keyboard and screen attached to it&#8230;&#8203;
This was called a <strong>Terminal</strong>.
People took turns sitting in front of the terminal and interacting with the computer.</p>
</div>
<div class="paragraph">
<p>Times change, and with the advent of personal computers such as Windows and Mac, computers have become something that is owned by individuals rather than shared by everyone.</p>
</div>
<div class="paragraph">
<p>The recent rise of cloud computing can be seen as a return to the original usage of computers, where everyone shared a large computer.
At the same time, edge devices such as smartphones and wearables are becoming more and more popular, and the trend of individuals owning multiple "small" computers is progressing at the same time.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_aws_general_introduction">3. Introduction to AWS</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_what_is_aws">3.1. What is AWS?</h3>
<div class="paragraph">
<p>In this book, AWS is used as the platform for implementing cloud applications.
In this chapter, we will explain the essential knowledge of AWS that is required for hands-on tutorials.</p>
</div>
<div class="paragraph">
<p><a href="https://aws.amazon.com">AWS (Amazon Web Services)</a>
is a general cloud platform provided by Amazon.
AWS was born in 2006 as a cloud service that leases vast computing resources that Amazon owns.
In 2021, AWS holds the largest market share (about 32%) as a cloud provider
(<a href="https://www.canalys.com/newsroom/global-cloud-market-Q121">Ref</a>).
Many web-related services, including Netflix and Slack, have some or all of their server resources provided by AWS.
Therefore, most of the readers would be benefiting from AWS without knowing it.</p>
</div>
<div class="paragraph">
<p>Because it has the largest market share, it offers a wider range of functions and services than any other cloud platforms.
In addition, reflecting the large number of users, there are many official and third-party technical articles on the web, which is helpful in learning and debugging.
In the early days, most of the users were companies engaged in web business, but recently, there is a growing number of users embracing AWS for scientific and engineering research.</p>
</div>
</div>
<div class="sect2">
<h3 id="_functions_and_services_provided_by_aws">3.2. Functions and services provided by AWS</h3>
<div class="paragraph">
<p><a href="#fig_aws_services">Figure 4</a> shows a list of the major services provided by AWS at the time of writing.</p>
</div>
<div id="fig_aws_services" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_services.png" alt="AWS services" width="350">
</div>
<div class="title">Figure 4. List of major services provided by AWS</div>
</div>
<div class="paragraph">
<p>The various elements required to compose a cloud, such as computation, storage, database, network, and security, are provided as <strong>independent components</strong>.
Essentially, a cloud system is created by combining these components.
There are also pre-packaged services for specific applications, such as machine learning, speech recognition, and augmented reality (AR) and virtual reality (VR).
In total, there are more than 170 services provided.</p>
</div>
<div class="paragraph">
<p>AWS beginners often fall into a situation where they are overwhelmed by the large number of services and left at a loss.
It&#8217;s not even clear what concepts to learn and in what order, and this is undoubtedly a major barrier to entry.
However, the truth is that the essential components of AWS are limited to just a couple.
If you know how to use the essential components, you are almost ready to start developing on AWS.
Many of the other services are combinations of the basic elements that AWS has prepared as specialized packages for specific applications.
Recognizing this point is the first step in learning AWS.</p>
</div>
<div class="paragraph">
<p>Here, we list the essential components for building a cloud system on AWS.
You will experience them while writing programs in the hands-on sessions in later chapters.
At this point, it is enough if you could just memorize the names in a corner of your mind.</p>
</div>
<div class="sect3">
<h4 id="_computation">3.2.1. computation</h4>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/EC2.png" alt="S3" width="40"></span>
<strong>EC2 (Elastic Compute Cloud)</strong>
Virtual machines with various specifications can be created and used to perform calculations.
This is the most basic component of AWS.
We will explore more on EC2 in later chapters (<a href="#sec_first_ec2">Section 4</a>, <a href="#sec_jupyter_and_deep_learning">Section 6</a>, <a href="#sec_aws_batch">Section 9</a>).</p>
</div>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/Lambda.png" alt="S3" width="40"></span>
<strong>Lambda</strong>
Lambda is a part of the cloud called Function as a Service (FaaS), a service for performing small computations without a server.
It will be described in detail in the chapter on serverless architecture (<a href="#sec_serverless">Section 11</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_storage">3.2.2. Storage</h4>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/EBS.png" alt="S3" width="40"></span>
<strong>EBS (Elastic Block Store)</strong>
A virtual data drive that can be assigned to EC2.
Think of a "conventional" file system as used in common operating systems.</p>
</div>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/S3.png" alt="S3" width="40"></span>
<strong>S3 (Simple Storage Service)</strong>
S3 is a "cloud-bative" data storage system called Object Storage, which uses APIs to read and write data.
It will be described in detail in the chapter on serverless architecture (<a href="#sec_serverless">Section 11</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_database">3.2.3. Database</h4>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/DynamoDB.png" alt="S3" width="40"></span>
<strong>DynamoDB</strong>
DynamoDB is a NoSQL type database service (think of <code>mongoDB</code> if you know it).
It will be described in detail in the chapter on serverless architecture (<a href="#sec_serverless">Section 11</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_networking">3.2.4. Networking</h4>
<div class="paragraph">
<p><span class="image left"><img src="imgs/aws_logos/VPC.png" alt="S3" width="40"></span>
<strong>VPC(Virtual Private Cloud)</strong>
With VPC, one can create a virtual network environment on AWS, define connections between virtual servers, and manage external access.
EC2 must be placed inside a VPC.</p>
</div>
<div class="paragraph">
<p><strong>API Gateway</strong>
<span class="image left"><img src="imgs/aws_logos/APIGateway.png" alt="S3" width="40"></span>
API Gateway acts as a reverse proxy to connect API endpoints to backend services (such as Lambda).
It will be described in detail in <a href="#sec_bashoutter">Section 13</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_regions_and_availability_zones">3.3. Regions and Availability Zones</h3>
<div class="paragraph">
<p>One of the most important concepts you need to know when using AWS is <strong>Region</strong> and <strong>Availability Zone (AZ)</strong> (<a href="#fig_aws_regions_and_azs">Figure 5</a>).
In the following, we will briefly describe these concepts.
For more detailed information, also see
<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">official documentation "Regions, Availability Zones, and Local Zones"</a>.</p>
</div>
<div id="fig_aws_regions_and_azs" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_region_and_az.png" alt="AWS regions and azs" width="500">
</div>
<div class="title">Figure 5. Regions and availability zones in AWS</div>
</div>
<div class="paragraph">
<p>A <strong>region</strong> roughly means the location of a data center.
At the time of writing, AWS has data centers in 25 geographical locations around the world, as shown in <a href="#fig_aws_regions">Figure 6</a>.
In Japan, there are data centers in Tokyo and Osaka.
Each region has a unique ID, for example, Tokyo is defined as <code>ap-northeast-1</code>, Ohio as <code>us-east-2</code>, and so on.</p>
</div>
<div id="fig_aws_regions" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_regions.png" alt="AWS regions" width="600">
</div>
<div class="title">Figure 6. Regions in AWS (Source: <a href="https://aws.amazon.com/about-aws/global-infrastructure/" class="bare">https://aws.amazon.com/about-aws/global-infrastructure/</a>)</div>
</div>
<div class="paragraph">
<p>When you log in to the AWS console, you can select a region from the menu bar at the top right of the screen (<a href="#fig_aws_console_regions">Figure 7</a>, circled in red).
AWS resources such as EC2 are completely independent for each region.
Therefore, when deploying new resources or viewing deployed resources, you need to <strong>make sure that the console region is set correctly</strong>.
If you are developing a web business, you will need to deploy the cloud in various parts of the world.
However, if you are using it for personal research, you are most likely fine just using the nearest region (e.g. Tokyo).</p>
</div>
<div id="fig_aws_console_regions" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_regions2.png" alt="AWS console select regions" width="600">
</div>
<div class="title">Figure 7. Selecting a region in AWS console</div>
</div>
<div class="paragraph">
<p>An <strong>Avaialibity Zone (AZ)</strong> is a data center that is geographically isolated within a region.
Each region has two or more AZs, so that if a fire or power failure occurs in one AZ, the other AZs can cover the failure.
In addition, the AZs are connected to each other by high-speed dedicated network lines, so data transfer between AZs is extremely fast.
AZ is a concept that should be taken into account when server downtime is unacceptable, such as in web businesses.
For personal use, there is no need to be concerned much about it.
It is sufficient to know the meaning of the term.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When using AWS, which region should you select?
In terms of Internet connection speed, it is generally best to use the region that is geographically closest to you.
On the other hand, EC2 usage fees, etc., are priced slightly differently for each region.
Therefore, it is also important to choose the region with the lowest price for the services that you use most frequently.
In addition, some services may not be available in a particular region.
It is best to make an overall judgment based on these points.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cloud_development_in_aws">3.4. Cloud development in AWS</h3>
<div class="paragraph">
<p>Now that you have a general understanding of the AWS cloud, the next topic will be an overview of how to develop and deploy a cloud system on AWS.</p>
</div>
<div class="paragraph">
<p>There are two ways to perform AWS operations such as adding, editing, and deleting resources: <strong>using the console</strong> and <strong>using the API</strong>.</p>
</div>
<div class="sect3">
<h4 id="_operating_the_resources_through_the_console">3.4.1. Operating the resources through the console</h4>
<div class="paragraph">
<p>When you log in to your AWS account, the first thing you will see is the <strong>AWS Management Console</strong> (<a href="#aws_console_window">Figure 8</a>).</p>
</div>
<div id="aws_console_window" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_console.png" alt="AWS console" width="600">
</div>
<div class="title">Figure 8. AWS Management Console</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In this book we will often call AWS Management Console AWS console or just a console.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Using the console, you can peform any operations on AWS resources through a GUI (Graphical User Interface), such as launching EC2 instances, adding and deleting data in S3, viewing logs, and so on.
<strong>AWS console is very useful when you are trying out a new function for the first time or debugging the system</strong>.</p>
</div>
<div class="paragraph">
<p>The console is useful for quickly testing functions and debugging the cloud under development, but it is rarely used directly in actual cloud development.
Rather, it is more common to use the APIs to describe cloud resources programmatically.
For this reason, this book does not cover how to use AWS console.
The AWS documentation includes many
<a href="https://aws.amazon.com/getting-started/hands-on/">tutorials</a>
which describe how to perform various operations from the AWS console.
They are valuable resources for learning.</p>
</div>
</div>
<div class="sect3">
<h4 id="_operating_the_resources_through_the_apis">3.4.2. Operating the resources through the APIs</h4>
<div class="paragraph">
<p>By using <strong>API (Application Programming Interface)</strong>, you can send commands to AWS and manipulate cloud resources.
APIs are simply a list of commands exposed by AWS, and consisted of <strong>REST APIs</strong> (REST APIs are explained in <a href="#sec_rest_api">Section 10.2</a>).
However, directly entering the REST APIs can be tedious, so various tools are provided to interact with AWS APIs more conveniently.</p>
</div>
<div class="paragraph">
<p>For example,
<a href="https://docs.aws.amazon.com/cli/latest/index.html">AWS CLI</a>
is a command line interface (CLI) to execute AWS APIs through UNIX console.
In addition to the CLI, SDKs (Software Development Kits) are available in a variety of programming languages.
Some examples are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Python &#8658; <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a></p>
</li>
<li>
<p>Ruby &#8658; <a href="https://aws.amazon.com/sdk-for-ruby/">AWS SDK for Ruby</a></p>
</li>
<li>
<p>Node.js &#8658; <a href="https://aws.amazon.com/sdk-for-node-js/">AWS SDK for Node.js</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Let&#8217;s look at a some of the API examples.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s assume that you want to add a new storage space (called a <code>Bucket</code>) to S3.
If you use the AWS CLI, you can type a command like the following.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 mb s3://my-bucket <span class="nt">--region</span> ap-northeast-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above command will create a bucket named <code>my-bucket</code> in the <code>ap-northeast-1</code> region.</p>
</div>
<div class="paragraph">
<p>To perform the same operation from Python, use the <code>boto3</code> library and run a script like the following.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">s3_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s">"s3"</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="s">"ap-northeast-1"</span><span class="p">)</span>
<span class="n">s3_client</span><span class="o">.</span><span class="n">create_bucket</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="s">"my-bucket"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s look at another example.</p>
</div>
<div class="paragraph">
<p>To start a new EC2 instance (an instance is a virtual server that is in the running state), use the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws ec2 run-instances <span class="nt">--image-id</span> ami-xxxxxxxx <span class="nt">--count</span> 1 <span class="nt">--instance-type</span> t2.micro <span class="nt">--key-name</span> MyKeyPair <span class="nt">--security-group-ids</span> sg-903004f8 <span class="nt">--subnet-id</span> subnet-6e7f829e</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will launch a
<a href="https://aws.amazon.com/ec2/instance-types/t2/">t2.micro</a>
instance with 1 vCPU and 1.0 GB RAM.
We&#8217;ll explain more about this command in later chapter (<a href="#sec_first_ec2">Section 4</a>).</p>
</div>
<div class="paragraph">
<p>To perform the same operation from Python, use a script like the following.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">ec2_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s">"ec2"</span><span class="p">)</span>
<span class="n">ec2_client</span><span class="o">.</span><span class="n">run_instances</span><span class="p">(</span>
    <span class="n">ImageId</span><span class="o">=</span><span class="s">"ami-xxxxxxxxx"</span><span class="p">,</span>
    <span class="n">MinCount</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">MaxCount</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">KeyName</span><span class="o">=</span><span class="s">"MyKeyPair"</span><span class="p">,</span>
    <span class="n">InstanceType</span><span class="o">=</span><span class="s">"t2.micro"</span><span class="p">,</span>
    <span class="n">SecurityGroupIds</span><span class="o">=</span><span class="p">[</span><span class="s">"sg-903004f8"</span><span class="p">],</span>
    <span class="n">SubnetId</span><span class="o">=</span><span class="s">"subnet-6e7f829e"</span><span class="p">,</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Through the above examples, we hope you are starting to get an idea of how APIs can be used to manipulate cloud resources.
With a single command, you can start a new virtual server, add a data storage area, or perform any other operation you want.
By combining multiple commands like this, you can build a computing environment with the desired CPU, RAM, network, and storage.
Of course, the delete operation can also be performed using the API.</p>
</div>
</div>
<div class="sect3">
<h4 id="_mini_hands_on_using_aws_cli">3.4.3. Mini hands-on: Using AWS CLI</h4>
<div class="paragraph">
<p>In this mini hands-on, we will learn how to use AWS CLI.
As mentioned earlier, AWS CLI can be used to manipulate any resource on AWS, but here we will practice the simplest case, <strong>reading and writing files using S3</strong>.
(EC2 operations are a bit more complicated, so we will cover them in <a href="#sec_first_ec2">Section 4</a>).
For detailed usage of the <code>aws s3</code> command, please refer to <a href="https://docs.aws.amazon.com/cli/latest/reference/s3/index.html#cli-aws-s3">official documentation</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For information on installing the AWS CLI, see <a href="#aws_cli_install">Section 14.3</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The hands-on exercise described below can be performed within the
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free S3 tier</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Before executing the following commands, make sure that your AWS credentials are set correctly.
This requires that the settings are written to the file <code>~/.aws/credentials</code> or that the environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_DEFAULT_REGION</code>) are defined.
See <a href="#aws_cli_install">Section 14.3</a> for details.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To begin with, let&#8217;s create a data storage space (called a <code>Bucket</code>) in S3.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ bucketName</span><span class="o">=</span><span class="s2">"mybucket-</span><span class="si">$(</span>openssl rand <span class="nt">-hex</span> 12<span class="si">)</span><span class="s2">"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$bucketName</span>
<span class="nv">$ </span>aws s3 mb <span class="s2">"s3://</span><span class="k">${</span><span class="nv">bucketName</span><span class="k">}</span><span class="s2">"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Since the name of an S3 bucket must be unique across AWS, the above command generates a bucket name that contains a random string and stores it in a variable called <code>bucketName</code>.
Then, a new bucket is created by <code>aws s3 mb</code> command (<code>mb</code> stands for make bucket).</p>
</div>
<div class="paragraph">
<p>Next, let&#8217;s obtain a list of the buckets.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 <span class="nb">ls

</span>2020-06-07 23:45:44 mybucket-c6f93855550a72b5b66f5efe</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can see that the bucket we just created is in the list.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>As a notation in this book, terminal commands are prefixed with <code>$</code> to indicate that they are commands.
The <code>$</code> must be removed when copying and pasting commands.
Conversely, the output of a command is shown without <code>$</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Next, we upload the files to the bucket.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"Hello world!"</span> <span class="o">&gt;</span> hello_world.txt
<span class="nv">$ </span>aws s3 <span class="nb">cp </span>hello_world.txt <span class="s2">"s3://</span><span class="k">${</span><span class="nv">bucketName</span><span class="k">}</span><span class="s2">/hello_world.txt"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, we generated a dummy file <code>hello_world.txt</code> and uploaded it to the bucket.</p>
</div>
<div class="paragraph">
<p>Now, let&#8217;s obtain a list of the files in teh bucket.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 <span class="nb">ls</span> <span class="s2">"s3://</span><span class="k">${</span><span class="nv">bucketName</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--human-readable</span>

2020-06-07 23:54:19   13 Bytes hello_world.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can see that the file we just uploaded is in the list.</p>
</div>
<div class="paragraph">
<p>Lastly, we delete the bucket we no longer use.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 rb <span class="s2">"s3://</span><span class="k">${</span><span class="nv">bucketName</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--force</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><code>rb</code> stands for remove bucket.
By default, you cannot delete a bucket if there are files in it.
By adding the <code>--force</code> option, a non-empty bucket are forced to be deleted.</p>
</div>
<div class="paragraph">
<p>As we just saw, we were able to perform a series of operations on S3 buckets using the AWS CLI.
In the same manner, you can use the AWS CLI to perform operation on EC2, Lambda, DynamoDB, and any other resources.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Amazon Resource Name (ARN)</strong>.</p>
</div>
<div class="paragraph">
<p>Every resource on AWS is assigned a unique ID called Amazon Resource Name (ARN).
ARNs are written in a format like <code>arn:aws:s3:::my_bucket/</code>, and ARNs can be used to uniquely refer to a specific AWS resource.</p>
</div>
<div class="paragraph">
<p>In addition to ARNs, it is also possible to define human-readable names for S3 buckets and EC2 instances.
In this case, either the ARN or the name can be used to refer to the same resource.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:intro_cloudformation">3.5. CloudFormation and AWS CDK</h3>
<div class="paragraph">
<p>As mentioned in the previous section, AWS APIs can be used to create and manage <strong>any</strong> resources in the cloud.
Therefore, in principle, you can construct cloud systems by combining API commands.</p>
</div>
<div class="paragraph">
<p>However, there is one practical point that needs to be considered here.
The AWS API can be broadly divided into <strong>commands to manipulate resources</strong> and <strong>commands to execute tasks</strong> (<a href="#fig_aws_iac">Figure 9</a>).</p>
</div>
<div id="fig_aws_iac" class="imageblock text-center">
<div class="content">
<img src="imgs/iac.png" alt="AWS console" width="500">
</div>
<div class="title">Figure 9. AWS APIs can be roughly divided into commands for manipulating resources and commands for executing tasks.</div>
</div>
<div class="paragraph">
<p><strong>Manipulating resources</strong> refers to <strong>preparing static resources</strong>, such as launching an EC2 instance, creating an S3 bucket, or adding a new table to a database.
Such commands need to be executed only once, when the cloud is deployed.</p>
</div>
<div class="paragraph">
<p><strong>Commands to execute tasks</strong> refer to operations such as submitting a job to an EC2 instance or writing data to an S3 bucket.
It describes the computation that should be performed within the premise of a static resource such as EC2 instance or S3 bucket.
Compared to the former, the latter can be regarded as being in charge of <strong>dynamic operations</strong>.</p>
</div>
<div class="paragraph">
<p>From this point of view, it would be clever to manage <strong>programs describing the infrastructure</strong> and <strong>programs executing tasks</strong> separately.
Therefore, the development of a cloud can be divided into two steps: one is to create programs that describe the static resources of the cloud, and the other is to create programs that perform dynamic operations.</p>
</div>
<div class="paragraph">
<p>CloudFormation is a mechanism for managing static resources in AWS.
CloudFormation defines the blueprint of the cloud infrastructure using text files that follow the CloudFormation syntax.
CloudFormation can be used to describe resource requirements, such as how many EC2 instances to launch, with what CPU power and networks configuration, and what access permissions to grant.
Once a CloudFormation file has been crafted, a cloud system can be deployed on AWS with a single command.
In addition, by exchanging CloudFormation files, it is possible for others to easily reproduce an identical cloud system.
This concept of describing and managing cloud infrastructure programmatically is called <strong>Infrastructure as Code (IaC)</strong>.</p>
</div>
<div class="paragraph">
<p>CloudFormation usually use a format called <strong>JSON</strong> (JavaScript Object Notation).
The following code is an example excerpt of a CloudFormation file written in JSON.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="json"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="code"><pre><span class="nl">"Resources"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="err">...</span><span class="w">
  </span><span class="nl">"WebServer"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"Type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::EC2::Instance"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"Properties"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"ImageId"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Fn::FindInMap"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="s2">"AWSRegionArch2AMI"</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::Region"</span><span class="w"> </span><span class="p">},</span><span class="w">
                        </span><span class="p">{</span><span class="w"> </span><span class="nl">"Fn::FindInMap"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="s2">"AWSInstanceType2Arch"</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"InstanceType"</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="s2">"Arch"</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="nl">"InstanceType"</span><span class="w">   </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"InstanceType"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="nl">"SecurityGroups"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="p">{</span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"WebServerSecurityGroup"</span><span class="p">}</span><span class="w"> </span><span class="p">],</span><span class="w">
      </span><span class="nl">"KeyName"</span><span class="w">        </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"KeyName"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="nl">"UserData"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Fn::Base64"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Fn::Join"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">""</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="w">
                     </span><span class="s2">"#!/bin/bash -xe</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"yum update -y aws-cfn-bootstrap</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="w">

                     </span><span class="s2">"/opt/aws/bin/cfn-init -v "</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"         --stack "</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::StackName"</span><span class="w"> </span><span class="p">},</span><span class="w">
                     </span><span class="s2">"         --resource WebServer "</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"         --configsets wordpress_install "</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"         --region "</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::Region"</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="w">

                     </span><span class="s2">"/opt/aws/bin/cfn-signal -e $? "</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"         --stack "</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::StackName"</span><span class="w"> </span><span class="p">},</span><span class="w">
                     </span><span class="s2">"         --resource WebServer "</span><span class="p">,</span><span class="w">
                     </span><span class="s2">"         --region "</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"Ref"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"AWS::Region"</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="w">
      </span><span class="p">]]}}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="err">...</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="err">...</span><span class="w">
</span><span class="p">}</span><span class="err">,</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, we have defined an EC2 instance named "WebServer".
This is a rather long and complex description, but it specifies all necessary information to create an EC2 instance.</p>
</div>
<div class="sect3">
<h4 id="_aws_cdk">3.5.1. AWS CDK</h4>
<div class="paragraph">
<p>As we saw in the previous section, CloudFormation is very complex to write, and there must not be any errors in any lines.
Further, since CloudFormation is written with JSON, we cannot use useful concepts such as variables and classes as we do in modern programming languages (strictly speaking, CloudFormation has functions that are equivalent to variables).
In addition, many parts of the CloudFormation files are repetitive, and many parts can be automated.</p>
</div>
<div class="paragraph">
<p>To solve this programmer&#8217;s pain,
<a href="https://aws.amazon.com/cdk/">AWS Cloud Development Kit (CDK)</a>
is offered by AWS.
<strong>CDK is a tool that automatically generates CloudFormations using a programming language such as Python.</strong>
CDK is a relatively new tool, released in 2019, and is being actively developed (check the releases at <a href="https://github.com/aws/aws-cdk/releases">GitHub repository</a> to see how fast this library is being improved).
CDK is supported by several languages including TypeScript (JavaScript), Python, and Java.</p>
</div>
<div class="paragraph">
<p>With CDK, programmers can use a familiar programming language to describe the deisred cloud resources and synthesize the CloudFormation files.
In addition, CDK determines many of the common parameters automatically, which reduces the amount of coding.</p>
</div>
<div class="paragraph">
<p>The following is an example excerpt of CDK code using Python.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">aws_cdk</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">core</span><span class="p">,</span>
    <span class="n">aws_ec2</span> <span class="k">as</span> <span class="n">ec2</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">class</span> <span class="nc">MyFirstEc2</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
            <span class="o">...</span> <span class="c1"># some parameters
</span>        <span class="p">)</span>

        <span class="n">sg</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">SecurityGroup</span><span class="p">(</span>
            <span class="o">...</span> <span class="c1"># some parameters
</span>        <span class="p">)</span>

        <span class="n">host</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Instance</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"MyGreatEc2"</span><span class="p">,</span>
            <span class="n">instance_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">InstanceType</span><span class="p">(</span><span class="s">"t2.micro"</span><span class="p">),</span>
            <span class="n">machine_image</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">MachineImage</span><span class="o">.</span><span class="n">latest_amazon_linux</span><span class="p">(),</span>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
            <span class="o">...</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>This code describes essentially the same thing as the JSON-based CloudFormation shown in the previous section.
You can see that CDK code is much shorter and easier to understand than the very complicated CloudFormation file.</p>
</div>
<div class="paragraph">
<p><strong>The focus of this book is to help you learn AWS concepts and techniques while writing code using CDK</strong>.
In the later chapters, we will provide various hands-on exercises using CDK.
To kick start, in the first hands-on, we will learn how to launch a simple EC2 instance using CDK.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Further reading</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/aws-samples/aws-cdk-examples">AWS CDK Examples</a>:
Many example projects using the CDK are published here.
You can use the examples here as a template to develop your own applications.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_first_ec2">4. Hands-on #1: Launching an EC2 instance</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the first hands-on session, we will create an EC2 instance (virtual server) using CDK, and log in to the server using SSH.
After this hands-on, you will be able to set up your own server on AWS and run calculations as you wish!</p>
</div>
<div class="sect2">
<h3 id="handson_01_prep">4.1. Preparation</h3>
<div class="paragraph">
<p>The source code for the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/ec2-get-started">handson/ec2-get-started</a>.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This hands-on exercise can be performed within the
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free EC2 tier</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>First, we set up the environment for the exercise.
This is a prerequisite for the hands-on sessions in later chapters as well, so make sure to do it now without mistakes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>AWS account</strong>:
You will need a personal AWS account to run the hands-on.
See <a href="#sec:create_aws_account">Section 14.1</a> for obtaining an AWS account.</p>
</li>
<li>
<p><strong>Python and Node.js</strong>:
Python (3.6 or higher) and Node.js (12.0 or higher) must be installed in order to run this hands-on.</p>
</li>
<li>
<p><strong>AWS CLI</strong>:
For information on installing the AWS CLI, see <a href="#aws_cli_install">Section 14.3</a>.
Be sure to set up the authentication key described here.</p>
</li>
<li>
<p><strong>AWS CDK</strong>:
For information on installing the AWS CDK, see <a href="#aws_cdk_install">Section 14.4</a>.</p>
</li>
<li>
<p><strong>Downloading the source code</strong>:
Download the source code of the hands-on program from GitHub using the following command.</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>git clone https://github.com/tomomano/learn-aws-by-coding.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can go to <a href="https://github.com/tomomano/learn-aws-by-coding" class="bare">https://github.com/tomomano/learn-aws-by-coding</a> and click on the download button in the upper right corner.</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Using Docker image for the hands-on exercises</strong></p>
</div>
<div class="paragraph">
<p>We provide a Docker image with the required programs installed, such as Python, Node.js, and AWS CDK.
The source code of the hands-on program has also been included in the image.
If you already know how to use Docker, then you can use this image to immediately start the hands-on tutorials without having to install anything else.</p>
</div>
<div class="paragraph">
<p>See <a href="#sec_handson_docker">Section 14.8</a> for more instructions.</p>
</div>
</div>
<div class="sect2">
<h3 id="_ssh">4.2. SSH</h3>
<div class="paragraph">
<p><strong>SSH (secure shell)</strong> is a tool to securely access Unix-like remote servers.
In this hands-on, we will use SSH to access a virtual server.
For readers who are not familiar with SSH, here we give a brief guidance.</p>
</div>
<div class="paragraph">
<p>All SSH communication is encrypted, so confidential information can be sent and received securely over the Internet.
For this hands-on, you need to have an SSH client installed on your local machine to access the remote server.
SSH clients come standard on Linux and Mac.
For Windows, it is recommended to install WSL to use an SSH client (see <a href="#environments">[environments]</a>).</p>
</div>
<div class="paragraph">
<p>The basic usage of the SSH command is shown below.
<code>&lt;host name&gt;</code> is the IP address or DNS hostname of the server to be accessed.
The <code>&lt;user name&gt;</code> is the user name of the server to be connected to.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>ssh &lt;user name&gt;@&lt;host name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>SSH can be authenticated using plain text passwords, but for stronger security, it is strongly recommended that you use <strong>Public Key Cryptography</strong> authentication, and EC2 only allows access in this way.
We do not explain the theory of public key cryptography here.
The important point in this hands-on is that the EC2 instance holds the public key, and the client computer (the reader&#8217;s local machine) holds the private key.
Only the computer with the private key can access the EC2 instance.
Conversely, if the private key is leaked, a third party will be able to access the server, so <strong>manage the private key with care to ensure that it is never leaked</strong>.</p>
</div>
<div class="paragraph">
<p>The SSH command allows you to specify the private key file to use for login with the <code>-i</code> or <code>--identity_file</code> option.
For example, use the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>ssh <span class="nt">-i</span> Ec2SecretKey.pem &lt;user name&gt;@&lt;host name&gt;</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_reading_the_application_source_code">4.3. Reading the application source code</h3>
<div class="paragraph">
<p><a href="#handson_01_architecture">Figure 10</a> shows an overview of the application we will be deploying in this hands-on.</p>
</div>
<div id="handson_01_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/app_architecture.png" alt="hands-on 01 architecture" width="600">
</div>
<div class="title">Figure 10. Application architecture</div>
</div>
<div class="paragraph">
<p>In this application, we first set up a private virtual network environment using <strong>VPC (Virtual Private Cloud)</strong>.
The virtual servers of <strong>EC2 (Elastic Compute Cloud)</strong> are placed inside the public subnet of the VPC.
For security purposes, access to the EC2 instance is restricted by the <strong>Security Group (SG)</strong>.
We will use SSH to access the virtual server and perform a simple calculation.
We use AWS CDK to construct this application.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s take a look at the source code of the CDK app
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/ec2-get-started/app.py">handson/ec2-get-started/app.py</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">MyFirstEc2</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">key_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <i class="conum" data-value="1"></i><b>(1)</b>
        <span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2-Vpc"</span><span class="p">,</span>
            <span class="n">max_azs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">cidr</span><span class="o">=</span><span class="s">"10.10.0.0/23"</span><span class="p">,</span>
            <span class="n">subnet_configuration</span><span class="o">=</span><span class="p">[</span>
                <span class="n">ec2</span><span class="o">.</span><span class="n">SubnetConfiguration</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="s">"public"</span><span class="p">,</span>
                    <span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
            <span class="n">nat_gateways</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="n">sg</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">SecurityGroup</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2Vpc-Sg"</span><span class="p">,</span>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
            <span class="n">allow_all_outbound</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">sg</span><span class="o">.</span><span class="n">add_ingress_rule</span><span class="p">(</span>
            <span class="n">peer</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Peer</span><span class="o">.</span><span class="n">any_ipv4</span><span class="p">(),</span>
            <span class="n">connection</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Port</span><span class="o">.</span><span class="n">tcp</span><span class="p">(</span><span class="mi">22</span><span class="p">),</span>
        <span class="p">)</span>

        <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="n">host</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Instance</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2Instance"</span><span class="p">,</span>
            <span class="n">instance_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">InstanceType</span><span class="p">(</span><span class="s">"t2.micro"</span><span class="p">),</span>
            <span class="n">machine_image</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">MachineImage</span><span class="o">.</span><span class="n">latest_amazon_linux</span><span class="p">(),</span>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
            <span class="n">vpc_subnets</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetSelection</span><span class="p">(</span><span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">),</span>
            <span class="n">security_group</span><span class="o">=</span><span class="n">sg</span><span class="p">,</span>
            <span class="n">key_name</span><span class="o">=</span><span class="n">key_name</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>First, we define the VPC.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Next, we define the security group.
Here, connections from any IPv4 address to port 22 (used for SSH connections) are allowed.
All other connections are rejected.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Finally, an EC2 instance is created with the VPC and SG created above.
The instance type is selected as <code>t2.micro</code>, and Amazon Linux is used as the OS.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let us explain each of these points in more detail.</p>
</div>
<div class="sect3">
<h4 id="_vpc_virtual_private_cloud">4.3.1. VPC (Virtual Private Cloud)</h4>
<div id="fig::vpc_logo" class="paragraph">
<div class="title">VPC icon</div>
<p><span class="image"><img src="imgs/aws_logos/VPC.png" alt="VPC" width="100"></span></p>
</div>
<div class="paragraph">
<p>VPC is a tool for building a private virtual network environment on AWS.
In order to build advanced computing systems, it is necessary to connect multiple servers, which requires management of the network addresses.
VPC is useful for such purposes.</p>
</div>
<div class="paragraph">
<p>In this hands-on, only one server is launched, so the benefits of VPC may not be clear to you.
However, since AWS specification require that EC2 instances must be placed inside a VPC, we have configured a minimal VPC in this application.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For those who are interested, here is a more advanced explanation of the VPC code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
</pre></td><td class="code"><pre><span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2-Vpc"</span><span class="p">,</span>
    <span class="n">max_azs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">cidr</span><span class="o">=</span><span class="s">"10.10.0.0/23"</span><span class="p">,</span>
    <span class="n">subnet_configuration</span><span class="o">=</span><span class="p">[</span>
        <span class="n">ec2</span><span class="o">.</span><span class="n">SubnetConfiguration</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s">"public"</span><span class="p">,</span>
            <span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">],</span>
    <span class="n">nat_gateways</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>max_azs=1</code>: This parameter sets the number of avaialability zones (AZs).
In this hands-on, it is set to <code>1</code> because we don&#8217;t need to worry about the failure of the data center.</p>
</li>
<li>
<p><code>cidr="10.10.0.0/23"</code>: This parameter specifies the range of IPv4 address in the VPC.
For more information about CIDR notation, see
<a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">Wikipedia article</a>.
<code>10.10.0.0/23</code> refers to a range of 512 consecutive addresses from <code>10.10.0.0</code> to <code>10.10.1.255</code>.
In other words, a maximum of 512 unique IPv4 addresses can be used in this VPC.
In this application, 512 is obviously too many since there is only one server, but since VPCs are free of charge no matter how many addresses are created, we created a big one.</p>
</li>
<li>
<p><code>subnet_configuration=&#8230;&#8203;</code> : This parameter determines what kind of subnet is created in VPC.
There are two types of subnets: <strong>private subnet</strong> and <strong>public subnet</strong>.
A private subnet is basically a subnet environment that is disconnected from the Internet.
Because it is not connected to the Internet, it is extremely secure, and EC2 instances that only need to communicate with servers inside the VPC should be placed here.
The public subnet is a subnet connected to the Internet.
Since we want to use SSH to log in to the server in this hands-on, we will place the EC2 instance in the public subnet.
For more information, refer to
<a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html#vpc-subnet-basics">official documentation "VPC and subnet basics"</a>.</p>
</li>
<li>
<p><code>natgateways=0</code>: This is a bit advanced parameter, so interested readers are referred to <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html">official documentation "NAT gateways"</a>.
Anyhow, <strong>if you don&#8217;t set this to 0, you will be charged for using the NAT Gateway</strong>.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_security_group">4.3.2. Security Group</h4>
<div class="paragraph">
<p>A security group (SG) is a virtual firewall that can be assigned to an EC2 instance.
For example, you can allow or deny connections coming from a specific IP address (inbound traffic restriction), and prohibit access to a specific IP address (outbound traffic restriction).</p>
</div>
<div class="paragraph">
<p>Let&#8217;s look at the corresponding part of the code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="n">sg</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">SecurityGroup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2Vpc-Sg"</span><span class="p">,</span>
    <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
    <span class="n">allow_all_outbound</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sg</span><span class="o">.</span><span class="n">add_ingress_rule</span><span class="p">(</span>
    <span class="n">peer</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Peer</span><span class="o">.</span><span class="n">any_ipv4</span><span class="p">(),</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Port</span><span class="o">.</span><span class="n">tcp</span><span class="p">(</span><span class="mi">22</span><span class="p">),</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, in order to allow SSH connections from the outside, we specified <code>sg.add_ingress_rule(peer=ec2.Peer.any_ipv4(), connection=ec2.Port.tcp(22))</code>, which means that access to port 22 is allowed from all IPv4 addresses.
In addition, the parameter <code>allow_all_outbound=True</code> is set so that the instance can access the Internet freely to download resources.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>SSH by default uses port 22 for remote access.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>From a security purpose, it is preferable to allow SSH connections only from specific locations such as home, university, or workplace.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_ec2_elastic_compute_cloud">4.3.3. EC2 (Elastic Compute Cloud)</h4>
<div id="fig::ec2_handson_ec2_logo" class="paragraph">
<div class="title">EC2 icon</div>
<p><span class="image"><img src="imgs/aws_logos/EC2.png" alt="EC2" width="100"></span></p>
</div>
<div class="paragraph">
<p>EC2 is a service for setting up virtual servers on AWS.
Each virtual server in a running state is called an <strong>instance</strong>.
(However, in colloquial communication, the terms server and instance are often used interchangeably.)</p>
</div>
<div class="paragraph">
<p>EC2 provides a variety of instance types to suit many use cases.
<a href="#ec2_instance_types">Table 2</a> lists some representative instance types.
A complete list of EC2 instance types can be found at
<a href="https://aws.amazon.com/ec2/instance-types/">Official Documentation "Amazon EC2 Instance Types"</a>.</p>
</div>
<table id="ec2_instance_types" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. EC2 instance types</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Instance</th>
<th class="tableblock halign-left valign-top">vCPU</th>
<th class="tableblock halign-left valign-top">Memory (GiB)</th>
<th class="tableblock halign-left valign-top">Network bandwidth (Gbps)</th>
<th class="tableblock halign-left valign-top">Price per hour ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">t2.micro</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0116</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">t2.small</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.023</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">t2.medium</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0464</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">c5.24xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">96</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">192</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4.08</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">c5n.18xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">72</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">192</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">100</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.888</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">x1e.16xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1952</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">13.344</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>As can be seen in <a href="#ec2_instance_types">Table 2</a>, the virtual CPUs (vCPUs) can be configured from 1 to 96 cores, memory from 1GB to over 2TB, and network bandwidth up to 100Gbps.
The price per hour increases approximately linearly with the number of vCPUs and memories allocated.
EC2 keeps track of the server running time in seconds, and the usage fee is determined in proportion to the usage time.
For example, if an instance of <code>t2.medium</code> is launched for 10 hours, a fee of 0.0464 * 10 = $0.464 will be charged.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>AWS has a
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free EC2 tier</a>.
With this, <code>t2.micro</code> can be used up to 750 hours per month for free.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The price listed in <a href="#ec2_instance_types">Table 2</a> is for the <code>us-east-1</code> region.
Pricing varies slightly by region.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The above price of $0.0116 / hour for t2.micro is for the <strong>on-demand instance</strong> type.
In addition to on-demand instance type, there is another type of instance called
<strong><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html">spot instance</a></strong>.
The idea of spot instances is to rent out the excess free CPUs temporarily available at AWS data center to users at a discount.
Therefore, spot instances are offered at a much lower price, but the instance may be forcibly shut down when the load on the AWS data center increases, even if the user&#8217;s program is still running.
There have been many reports of spot instance being used to reduce costs in applications such as scientific computing and web servers.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let&#8217;s take a look at the part of the code that defines the EC2 instance.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="n">host</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Instance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"MyFirstEc2Instance"</span><span class="p">,</span>
    <span class="n">instance_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">InstanceType</span><span class="p">(</span><span class="s">"t2.micro"</span><span class="p">),</span>
    <span class="n">machine_image</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">MachineImage</span><span class="o">.</span><span class="n">latest_amazon_linux</span><span class="p">(),</span>
    <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
    <span class="n">vpc_subnets</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetSelection</span><span class="p">(</span><span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">),</span>
    <span class="n">security_group</span><span class="o">=</span><span class="n">sg</span><span class="p">,</span>
    <span class="n">key_name</span><span class="o">=</span><span class="n">key_name</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, we have selected the instance type <code>t2.micro</code>.
In addition, the <code>machine_image</code> is set to
<a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux</a>
(Machine image is a concept similar to OS.
We will discuss machine image in more detail in <a href="#sec_jupyter_and_deep_learning">Section 6</a>.)
In addition, the VPC and SG defined above are assigned to this instance.</p>
</div>
<div class="paragraph">
<p>This is a brief explanation of the program we will be using.
Although it is a minimalist program, we hope it has given you an idea of the steps required to create a virtual server.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="sec_handson_ec2_run">4.4. Deploying the application</h3>
<div class="paragraph">
<p>Now that we understand the source code, let&#8217;s deploy the application on AWS.
Again, it is assumed that you have finished the preparations described in<a href="#handson_01_prep">Section 4.1</a>.</p>
</div>
<div class="sect3">
<h4 id="_installing_python_dependencies">4.4.1. Installing Python dependencies</h4>
<div class="paragraph">
<p>The first step is to install the Python dependency libraries.
In the following, we use
<a href="https://docs.python.org/3/library/venv.html">venv</a>
as a tool to manage Python libraries.</p>
</div>
<div class="paragraph">
<p>First, let&#8217;s move to the directory <code>handson/ec2-get-started</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">cd </span>handson/ec2-get-started</code></pre>
</div>
</div>
<div class="paragraph">
<p>After moving the directory, create a new virtual environment with <code>venv</code> and run the installation with <code>pip</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p>This completes the Python environment setup.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A quick tutorial on <code>venv</code> is provided in <a href="#venv_quick_guide">Section 14.7</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_setting_aws_access_key">4.4.2. Setting AWS access key</h4>
<div class="paragraph">
<p>To use the AWS CLI and AWS CDK, you need to have an AWS access key set up.
Refer to <a href="#aws_secrets">Section 14.2</a> for issuing a access key.
After issuing the access key, refer to <a href="#aws_cli_install">Section 14.3</a> to configure the command line settings.</p>
</div>
<div class="paragraph">
<p>To summarize the procedure shortly, the first method is to set environment variables such as <code>AWS_ACCESS_KEY_ID</code>.
The second method is to store the authentication information in <code>~/.aws/credentials</code>.
Setting an access key is a common step in using the AWS CLI/CDK, so make sure you understand it well.</p>
</div>
</div>
<div class="sect3">
<h4 id="_generating_a_ssh_key_pair">4.4.3. Generating a SSH key pair</h4>
<div class="paragraph">
<p>We login to the EC2 instance using SSH.
Before creating an EC2 instance, you need to prepare an SSH public/private key pair to be used exclusively in this hands-on exercise.</p>
</div>
<div class="paragraph">
<p>Using the following AWS CLI command, let&#8217;s generate a key named <code>OpenSesame</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">export </span><span class="nv">KEY_NAME</span><span class="o">=</span><span class="s2">"OpenSesame"</span>
<span class="nv">$ </span>aws ec2 create-key-pair <span class="nt">--key-name</span> <span class="k">${</span><span class="nv">KEY_NAME</span><span class="k">}</span> <span class="nt">--query</span> <span class="s1">'KeyMaterial'</span> <span class="nt">--output</span> text <span class="o">&gt;</span> <span class="k">${</span><span class="nv">KEY_NAME</span><span class="k">}</span>.pem</code></pre>
</div>
</div>
<div class="paragraph">
<p>When you execute this command, a file named <code>OpenSesame.pem</code> will be created in the current directory.
This is the private key to access the server.
To use this key with SSH, move the key to the directory <code>~/.ssh/</code>.
To prevent the private key from being overwritten or viewed by a third party, you must set the access permission of the file to <code>400</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">mv </span>OpenSesame.pem ~/.ssh/
<span class="nv">$ </span><span class="nb">chmod </span>400 ~/.ssh/OpenSesame.pem</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_deploy">4.4.4. Deploy</h4>
<div class="paragraph">
<p>We are now ready to deploy our EC2 instance!
Use the following command to deploy the application on AWS.
The option <code>-c key_name="OpenSesame"</code> specifies to use the key named <code>OpenSesame</code> that we generated earlier.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk deploy <span class="nt">-c</span> <span class="nv">key_name</span><span class="o">=</span><span class="s2">"OpenSesame"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>When this command is executed, the VPC, EC2, and other resources will be deployed on AWS.
At the end of the command output, you should get an output like <a href="#handson_01_cdk_output">Figure 11</a>.
<strong>In the output, the digits following <code>InstancePublicIp</code> is the public IP address of the launched instance</strong>.
The IP address is randomly assigned for each deployment.</p>
</div>
<div id="handson_01_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 11. Output of CDK deploy</div>
</div>
</div>
<div class="sect3">
<h4 id="_log_in_with_ssh">4.4.5. Log in with SSH</h4>
<div class="paragraph">
<p>Let us log in to the instance using SSH.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/OpenSesame.pem ec2-user@&lt;IP address&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the <code>-i</code> option specifies the private key that was generated earlier.
Since the EC2 instance by default has a user named <code>ec2-user</code>, use this as a login user name.
Lastly, replace <code>&lt;IP address&gt;</code> with the IP address of the EC2 instance you created (e.g., <code>12.345.678.9</code>).</p>
</div>
<div class="paragraph">
<p>If the login is successful, you will be taken to a terminal window like <a href="#fig_handson_01_ssh_login">Figure 12</a>.
Since you are logging in to a remote server, make sure the prompt looks like <code>[ec2-user@ip-10-10-1-217 ~]$</code>.</p>
</div>
<div id="fig_handson_01_ssh_login" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/ssh_login.png" alt="ssh_login" width="700">
</div>
<div class="title">Figure 12. Log in to the EC2 instance using SSH</div>
</div>
<div class="paragraph">
<p><strong>Congratulations!
You have successfully launched an EC2 virtual instance on AWS, and you can access it remotely!</strong></p>
</div>
</div>
<div class="sect3">
<h4 id="_exploring_the_launched_ec2_instance">4.4.6. Exploring the launched EC2 instance</h4>
<div class="paragraph">
<p>Now that we have a new instance up and running, let&#8217;s play with it.</p>
</div>
<div class="paragraph">
<p>Inside the EC2 instance you logged into, run the following command.
The command will output the CPU information.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">cat</span> /proc/cpuinfo

processor	: 0
vendor_id	: GenuineIntel
cpu family	: 6
model		: 63
model name	: Intel<span class="o">(</span>R<span class="o">)</span> Xeon<span class="o">(</span>R<span class="o">)</span> CPU E5-2676 v3 @ 2.40GHz
stepping	: 2
microcode	: 0x43
cpu MHz		: 2400.096
cache size	: 30720 KB</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s use <code>top</code> command and show the running processes and memory usage.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span> top <span class="nt">-n</span> 1

top - 09:29:19 up 43 min,  1 user,  load average: 0.00, 0.00, 0.00
Tasks:  76 total,   1 running,  51 sleeping,   0 stopped,   0 zombie
Cpu<span class="o">(</span>s<span class="o">)</span>:  0.3%us,  0.3%sy,  0.1%ni, 98.9%id,  0.2%wa,  0.0%hi,  0.0%si,  0.2%st
Mem:   1009140k total,   270760k used,   738380k free,    14340k buffers
Swap:        0k total,        0k used,        0k free,   185856k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
    1 root      20   0 19696 2596 2268 S  0.0  0.3   0:01.21 init
    2 root      20   0     0    0    0 S  0.0  0.0   0:00.00 kthreadd
    3 root      20   0     0    0    0 I  0.0  0.0   0:00.00 kworker/0:0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Since we are using <code>t2.micro</code> instance, we have 1009140k = 1GB memory in the virtual instance.</p>
</div>
<div class="paragraph">
<p>The instance we started has Python 2 installed, but not Python 3.
Let&#8217;s install Python 3.6.
The installation is easy.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">sudo </span>yum update <span class="nt">-y</span>
<span class="nv">$ </span><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> python36</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s start Python 3 interpreter.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python3
Python 3.6.10 <span class="o">(</span>default, Feb 10 2020, 19:55:14<span class="o">)</span>
<span class="o">[</span>GCC 4.8.5 20150623 <span class="o">(</span>Red Hat 4.8.5-28<span class="o">)]</span> on linux
Type <span class="s2">"help"</span>, <span class="s2">"copyright"</span>, <span class="s2">"credits"</span> or <span class="s2">"license"</span> <span class="k">for </span>more information.
<span class="o">&gt;&gt;&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To exit from the interpreter, use <code>Ctrl + D</code> or type <code>exit()</code>.</p>
</div>
<div class="paragraph">
<p>So, that&#8217;s it for playing around on the server (if you&#8217;re interested, you can try different things!).
Log out from the instance with the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">exit</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_observing_the_resources_from_aws_console">4.4.7. Observing the resources from AWS console</h4>
<div class="paragraph">
<p>So far we have performed all EC2-related operations from the command line.
Operations such as checking the status of an EC2 instance or shutting down a server can also be performed from the AWS console.
Let&#8217;s take a quick look at this.</p>
</div>
<div class="paragraph">
<p>First, open a web browser and log in to the AWS console.
Once you are logged in, search <code>EC2</code> from <code>Services</code> and go to the EC2 dashboard.
Next, navigate to <code>Instances</code> in the left sidebar.
You should get a screen like <a href="#aws_ec2_console">Figure 13</a>.
On this screen, you can check the instances under your account.
Similarly, you can also check the VPC and SG from the console.</p>
</div>
<div id="aws_ec2_console" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/ec2_console.png" alt="ec2_console" width="700">
</div>
<div class="title">Figure 13. EC2 dashboard</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Make sure that the correct region (in this case, <code>ap-northeast-1</code>) is selected in the AWS console!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As mentioned in the previous chapter, the application deployed here is managed as a CloudFormation stack.
A <strong>stack</strong> refers to a group of AWS resources.
In this case, VPC, SG, and EC2 are included in the same stack.
From the AWS console, let&#8217;s go to the <code>CloudFormation</code> dashboard (<a href="#aws_cloudformation_console">Figure 14</a>).</p>
</div>
<div id="aws_cloudformation_console" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/cloudformation_console.png" alt="cloudformation console" width="700">
</div>
<div class="title">Figure 14. CloudFormation dashboard</div>
</div>
<div class="paragraph">
<p>You should be able find a stack named "MyFirstEc2".
If you click on it and look at the contents, you will see that EC2, VPC, and other resources are associated to this stack.</p>
</div>
</div>
<div class="sect3">
<h4 id="handson_01_delete_stack">4.4.8. Deleting the stack</h4>
<div class="paragraph">
<p>We have explained everything that was to be covered in the first hands-on session.
Finally, we must delete the stack that is no longer in use.
There are two ways to delete a stack.</p>
</div>
<div class="paragraph">
<p>The first method is to press the "Delete" button on the Cloudformation dashboard (<a href="#cloudformation_delete">Figure 15</a>).
Then, the status of the stack will change to <code>"DELETE_IN_PROGRESS"</code>, and when the deletion is completed, the stack will disappear from the list of CloudFormation stacks.</p>
</div>
<div id="cloudformation_delete" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/cloudformation_delete.png" alt="cloudformation delete" width="700">
</div>
<div class="title">Figure 15. Deleting a stack from CloudFormation dashboard</div>
</div>
<div class="paragraph">
<p>The second method is to use the command line.
Let&#8217;s go back to the command line where we ran the deployment.
Then, execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
<div class="paragraph">
<p>When you execute this command, the stack will be deleted.
After deleting the stack, make sure for yourself that all the VPCs, EC2s, etc. have disappeared without a trace.
Using CloudFormation is very convenient because it allows you to manage and delete all related AWS resources at once.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Make sure you delete your own stack!</strong>
If you do not do so, you will continue to be charged for the EC2 instance!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Also, delete the SSH key pair created for this hands-on, as it is no longer needed.
First, delete the public key registered on the EC2 side.
This can be done in two ways: from the console or from the command line.</p>
</div>
<div class="paragraph">
<p>To do this from the console, go to the <code>EC2</code> dashboard and select <code>Key Pairs</code> from the left sidebar.
When a list of keys is displayed, check the key labeled <code>OpenSesame</code> and execute <code>Delete</code> from <code>Actions</code> in the upper right corner of the screen (<a href="#delete_ec2_key_pair">Figure 16</a>).</p>
</div>
<div id="delete_ec2_key_pair" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-01/ec2_keypair_console.png" alt="ec2_keypair_console" width="700">
</div>
<div class="title">Figure 16. Deleting a SSH key pair on EC2 dashboard</div>
</div>
<div class="paragraph">
<p>To do the same operation from the command line, use the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws ec2 delete-key-pair <span class="nt">--key-name</span> <span class="s2">"OpenSesame"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Lastly, delete the key from your local machine.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-f</span> ~/.ssh/OpenSesame.pem</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, we&#8217;re all done cleaning up the cloud.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you frequently start EC2 instances, you do not need to delete the SSH key every time.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary">4.5. Summary</h3>
<div class="paragraph">
<p>This is the end of the first part of the book.
We hope you have been able to follow the contents without much trouble.</p>
</div>
<div class="paragraph">
<p>In <a href="#chap_cloud_basics">Section 2</a>, the definition of cloud and important terminology were explained, and then the reasons for using cloud were discussed.
Then, in <a href="#sec_aws_general_introduction">Section 3</a>, AWS was introduced as a platform to learn about cloud computing, and the minimum knowledge and terminology required to use AWS were explained.
In the hands-on session in <a href="#sec_first_ec2">Section 4</a>, we used AWS CLI and AWS CDK to set up our own private server on AWS.</p>
</div>
<div class="paragraph">
<p>You can now experience how easy it is to start up and remove virtual servers (with just a few commands!).
We mentioned in <a href="#chap_cloud_basics">Section 2</a> that the most important aspect of the cloud is the ability to dynamically expand and shrink computational resources.
We hope that the meaning of this phrase has become clearer through the hands-on experience.
Using this simple tutorial as a template, you can customize the code for your own appplications, such as creating a virtual server to host your web pages, prepare an EC2 instance with a large number of cores to run scientific computations, and many more.</p>
</div>
<div class="paragraph">
<p>In the next chapter, you will experience solving more realistic problems based on the cloud technology you have learned.
Stay tuned!</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_scientific_computing">5. Scientific computing and machine learning in the cloud</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the modern age of computing, computational simulation and big data analysis are the major driving force of scientific and engineering research.
The cloud is the best place to perform these large-scale computations.
In Part II, which starts with this section, you will experience how to run scientific computation on the cloud through several hands-on experiences.
As a specific subject of scientific computing, here we will focus on machine learning (deep learning).</p>
</div>
<div class="paragraph">
<p>In this book, we will use the
<a href="https://pytorch.org/">PyTorch</a>
library to implement deep learning algorithms, but no knowledge of deep learning or PyTorch is required.
The lecture focuses on <strong>why and how to run deep learning in the cloud</strong>, so we will not go into the details of the deep learning algorithm itself.
Interested readers are refered to other books for the theory and implementation of deep neural network (column below).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Deep learning textbooks</div>
<div class="paragraph">
<p>For those who want to study deep learning theory and implementation, we would like to recommend the following textbooks.
Although the basic concepts and theories of deep learning are universal, this field is constantly evolving, so be sure to keep up to date with the latest information.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.deeplearningbook.org/">Deep Learning (Ian Goodfellow, Yoshua Bengio and Aaron Courville)</a></p>
<div class="paragraph">
<p>This is a good introductory book if you want to learn the theoretical aspects of deep learning (although, it was published several years ago and does not cover the latest topics).
You can read it for free on the web.
This is a book for theoreticians, as it hardly discusses implementation.</p>
</div>
</li>
<li>
<p><a href="https://www.oreilly.co.jp/books/9784873117584/">Deep Learning from Scratch (Koki Saito)</a></p>
<div class="paragraph">
<p>A series of three books in total, published in Japanese and several other languages.
This is the definitive introductory book on deep learning, with a good balance of theory and implementation.</p>
</div>
</li>
<li>
<p><a href="https://d2l.ai/">Dive into Deep Learning (Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola)</a></p>
<div class="paragraph">
<p>A book that teaches the basics of deep learning to the latest algorithms through implementation.
This is a huge book with over 1000 pages, which is freely available on the web.
If you can read through this book, you will have no trouble in implementing deep learning algorithms.</p>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_why_use_the_cloud_for_machine_learning">5.1. Why use the cloud for machine learning?</h3>
<div class="paragraph">
<p>The third AI boom started around 2010, and consequently machine learning is attracting a lot of attention not only in academic research but also in social and business contexts.
In particular, algorithms based on multi-layered neural networks, known as <strong>deep learning</strong>, have revolutionized image recognition and natural language processing by achieving remarkably higher performance than previous algorithms.</p>
</div>
<div class="paragraph">
<p>The core feature of deep learning is its large number of parameters.
As the layers become deeper, the number of weight parameters connecting the neurons between the layers increases.
For example, the latest language model,
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
contains as many as <strong>175 billion</strong> parameters.
With such a vast number of parameters, deep learning can achieve high expressive power and generalization performance.</p>
</div>
<div class="paragraph">
<p>Not only GPT-3, but also recent neural networks that achieve SOTA (State-of-the-Art) performance frequently contain parameters in the order of millions or billions.
Naturally, training such a huge neural network is computationally expensive.
As a result, it is not uncommon to see cases where the training takes more than a full day with a single workstation.
With the rapid development of deep learning, the key to maximize research and business productivity is how to optimize the neural network with high throughput.
The cloud is a very effective means to solve such problems!
As we have seen in <a href="#sec_first_ec2">Section 4</a>, the cloud can be used to dynamically launch a large number of instances, and execute computations in parallel.
In addition, there are specially designed chips (e.g. GPUs) optimized for deep learning operations to accelerate the computation.
By using the cloud, you gain access to inexhaustible supply of such specialized computing chips.
In fact, it was reported that the training of GPT-3 was performed using Microsoft&#8217;s cloud, although the details have not been disclosed.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The details of the computational resources used in GPT-3 project are not disclosed in the paper, but there is an interesting discussion at
<a href="https://lambdalabs.com/blog/demystifying-gpt-3/">Lambda&#8217;s blog</a>
(Lambda is a cloud service specializing in machine learning).</p>
</div>
<div class="paragraph">
<p>According to the article, it would take 342 years and $4.6 million in cloud fees to train 175 billion parameters if a single GPU (NVIDIA V100) was used.
The GPT-3 team was able to complete the training in a realistic amount of time by distributing the processing across multiple GPUs, but it is clear that this level of modeling can only be achieved by pushing the limits of cloud technology.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_accelerating_deep_learning_by_gpu">5.2. Accelerating deep learning by GPU</h3>
<div class="paragraph">
<p>Here we will briefly talk about <strong>Graphics Processing Unit</strong> or <strong>GPU</strong>, which serves as an indispensable technology for deep learning.</p>
</div>
<div class="paragraph">
<p>As the name suggests, a GPU is originally a dedicated computing chip for producing computer graphics.
In contrast to a <strong>CPU (Central Processing Unit)</strong> which is capable of general computation, a GPU is designed specifically for graphics operations.
It can be found in familiar game consoles such as XBox and PS5, as well as in high-end notebook and desktop computers.
In computer graphics, millions of pixels arranged on a screen need to be updated at video rates (30 fps) or higher.
To handle this task, a single GPU chip contain hundreds to thousands of cores, each with relatively small computing power (<a href="#gpu_architecture">Figure 17</a>), and processes the pixels on the screen in parallel to achieve real-time rendering.</p>
</div>
<div id="gpu_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/gpu_architecture.jpg" alt="cdk output" width="500">
</div>
<div class="title">Figure 17. GPU architecture (Image source: <a href="https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/" class="bare">https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/</a>)</div>
</div>
<div class="paragraph">
<p>Although GPUs were originally developed for the purpose of computer graphics, since around 2010, some advanced programmers and engineers started to use GPU&#8217;s high parallel computing power for calculations other than graphics, such as scientific computations.
This idea is called <strong>General-purpose computing on GPU</strong> or <strong>GPGPU</strong>.
Due to its chip design, GPGPU is suitable for simple and regular operations such as matrix operations, and can achieve much higher speed than CPUs.
Currently, GPGPU is employed in many fields such as molecular dynamics, weather simulation, and machine learning.</p>
</div>
<div class="paragraph">
<p>The operation that occurs most frequently in deep learning is the <strong>convolution</strong> operation, which transfers the output of neurons to the neurons in the next layer (<a href="#fig:convolution">Figure 18</a>).
Convolution is exactly the kind of operations that GPUs are good at, and by using GPUs instead of CPUs, learning can be dramatically accelerated, up to several hundred times.</p>
</div>
<div id="fig:convolution" class="imageblock text-center">
<div class="content">
<img src="imgs/cnn.png" alt="cnn" width="400">
</div>
<div class="title">Figure 18. Convolution in neural network</div>
</div>
<div class="paragraph">
<p>Thus, GPUs are indispensable for machine learning calculations.
However, they are quite expensive.
For example, NVIDIA&#8217;s Tesla V100 chip, designed specifically for scientific computing and machine learning, is priced at about one million yen (ten thousand dollars).
One million yen is quite a large investment just to start a machine learning project.
The good news is, if you use the cloud, you can use GPUs with zero initial cost!</p>
</div>
<div class="paragraph">
<p>To use GPUs in AWS, you need to select an EC2 instance type equipped with GPUs, such as <code>P2</code>, <code>P3</code>, <code>G3</code>, and <code>G4</code> instance family.
<a href="#table_gpu_instances">Table 3</a> lists representative GPU-equipped instance types as of this writing.</p>
</div>
<table id="table_gpu_instances" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. EC2 GPU instances</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Instance</th>
<th class="tableblock halign-left valign-top">GPUs</th>
<th class="tableblock halign-left valign-top">GPU model</th>
<th class="tableblock halign-left valign-top">GPU Mem (GiB)</th>
<th class="tableblock halign-left valign-top">vCPU</th>
<th class="tableblock halign-left valign-top">Mem (GiB)</th>
<th class="tableblock halign-left valign-top">Price per hour ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p3.2xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NVIDIA V100</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">61</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.06</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p3n.16xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NVIDIA V100</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">488</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">24.48</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p2.xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NVIDIA K80</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">61</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">g4dn.xlarge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NVIDIA T4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.526</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>As you can see from <a href="#table_gpu_instances">Table 3</a>, the price of GPU instances is higher than the CPU-only instances.
Also note that older generation GPUs (K80 compared to V100) are offered at a lower price.
The number of GPUs per instance can be selected from one to a maximum of eight.</p>
</div>
<div class="paragraph">
<p>The cheapest GPU instance type is <code>g4dn.xlarge</code>, which is equipped with a low-cost and energy-efficient NVIDIA T4 chip.
In the hands-on session in the later chapters, we will use this instance to perform deep learning calculations.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The prices in <a href="#table_gpu_instances">Table 3</a> are for <code>us-east-1</code>.
The pricing differs slightly depending on the region.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The cost for <code>p3.2xlarge</code> instance with a single V100 chip is $3.06 per hour.
Considering that a V100 chip is sold for about 1 million yen, if you use it for more than 3000 hours (= 124 days), then it becomes more economical to buy a V100 by yourself than to use the cloud.
(Actually, if you prepare the V100 on your own, you need not only the V100 but also the CPU, RAM, network equipment, and electricity, so the total cost would be even higher than 1 million yen.)</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_jupyter_and_deep_learning">6. Hands-on #2: Running Deep Learning on AWS</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="sec:jupyter_and_deep_learning_setup">6.1. Preparation</h3>
<div class="paragraph">
<p>In the second hands-on session, we will launch an EC2 instance equipped with a GPU and practice training and inference of a deep learning model.</p>
</div>
<div class="paragraph">
<p>The source code for the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/mnist">handson/mnist</a>.</p>
</div>
<div class="paragraph">
<p>To run this hands-on, it is assumed that the preparations described in the first hands-on (<a href="#handson_01_prep">Section 4.1</a>) have been completed.
There are no other preparations required.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the initial state of your AWS account, the launch limit for G-type instances may be set to 0.
To check this, open the EC2 dashbord from the AWS console, and select <code>Limits</code> from the menu on the left.
The number <code>Running On-Demand All G instances</code> in the list indicates the maximum number of G instances that can be started.</p>
</div>
<div class="paragraph">
<p>If it is set to 0, you need to send a request to increase the limit via the request form.
For details, see
<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html">official documentation "Amazon EC2 service quotas"</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This hands-on uses a <code>g4dn.xlarge</code> type EC2 instance, so it costs 0.71 $/hour in the Tokyo (<code>ap-northeast-1</code>) region.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_reading_the_application_source_code_2">6.2. Reading the application source code</h3>
<div class="paragraph">
<p><a href="#handson_02_architecture">Figure 19</a> shows an overview of the application we will be deploying in this hands-on.</p>
</div>
<div id="handson_02_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/handson-02-architecture.png" alt="hands-on 01 architecture" width="600">
</div>
<div class="title">Figure 19. Application architecture</div>
</div>
<div class="paragraph">
<p>You will notice that many parts of the figure are the same as the application we created in the first hands-on session (<a href="#handson_01_architecture">Figure 10</a>).
With a few changes, we can easily build an environment to run deep learning!
The three main changes are as follows.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use a <code>g4dn.xlarge</code> instance type equipped with a GPU.</p>
</li>
<li>
<p>Use a DLAMI (see below) with the programs for deep learning pre-installed.</p>
</li>
<li>
<p>Connect to the server using SSH with port forwarding option, and write and execute codes using Jupyter Notebook (see below) running on the server.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Let&#8217;s have a look at the source code
(<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/mnist/app.py">handson/mnist/app.py</a>).
The code is almost the same as in the first hands-on.
We will explain only the parts where changes were made.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">Ec2ForDl</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">key_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"Ec2ForDl-Vpc"</span><span class="p">,</span>
            <span class="n">max_azs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">cidr</span><span class="o">=</span><span class="s">"10.10.0.0/23"</span><span class="p">,</span>
            <span class="n">subnet_configuration</span><span class="o">=</span><span class="p">[</span>
                <span class="n">ec2</span><span class="o">.</span><span class="n">SubnetConfiguration</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="s">"public"</span><span class="p">,</span>
                    <span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
            <span class="n">nat_gateways</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">sg</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">SecurityGroup</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"Ec2ForDl-Sg"</span><span class="p">,</span>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
            <span class="n">allow_all_outbound</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">sg</span><span class="o">.</span><span class="n">add_ingress_rule</span><span class="p">(</span>
            <span class="n">peer</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Peer</span><span class="o">.</span><span class="n">any_ipv4</span><span class="p">(),</span>
            <span class="n">connection</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">Port</span><span class="o">.</span><span class="n">tcp</span><span class="p">(</span><span class="mi">22</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">host</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Instance</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"Ec2ForDl-Instance"</span><span class="p">,</span>
            <span class="n">instance_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">InstanceType</span><span class="p">(</span><span class="s">"g4dn.xlarge"</span><span class="p">),</span> <i class="conum" data-value="1"></i><b>(1)</b>
            <span class="n">machine_image</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">MachineImage</span><span class="o">.</span><span class="n">generic_linux</span><span class="p">({</span>
                <span class="s">"us-east-1"</span><span class="p">:</span> <span class="s">"ami-060f07284bb6f9faf"</span><span class="p">,</span>
                <span class="s">"ap-northeast-1"</span><span class="p">:</span> <span class="s">"ami-09c0c16fc46a29ed9"</span>
            <span class="p">}),</span> <i class="conum" data-value="2"></i><b>(2)</b>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
            <span class="n">vpc_subnets</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetSelection</span><span class="p">(</span><span class="n">subnet_type</span><span class="o">=</span><span class="n">ec2</span><span class="o">.</span><span class="n">SubnetType</span><span class="o">.</span><span class="n">PUBLIC</span><span class="p">),</span>
            <span class="n">security_group</span><span class="o">=</span><span class="n">sg</span><span class="p">,</span>
            <span class="n">key_name</span><span class="o">=</span><span class="n">key_name</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here, we have selected the <code>g4dn.xlarge</code> instance type (in the first hands-on, it was <code>t2.micro</code>).
As already mentioned in <a href="#sec_scientific_computing">Section 5</a>, the <code>g4dn.xlarge</code> is an instance with a low-cost model GPU called <code>NVIDIA T4</code>.
It has 4 CPU cores and 16GB of main memory.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Here, we are using
<a href="https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html">Deep Learning Amazon Machine Image; DLAMI</a>,
an AMI with varisous programs for deep learning pre-installed.
Note that in the first hands-on, we used an AMI called Amazon Linux.
The ID of the AMI must be specified for each region, and here we are supplying IDs for <code>us-east-1</code> and <code>ap-northeast-1</code>.</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the code above, the AMI IDs are only defined in <code>us-east-1</code> and <code>ap-northeast-1</code>.
If you want to use other regions, you need to search for the AMI ID yourself and write it in the code.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_dlami_deep_learning_amazon_machine_image">6.2.1. DLAMI (Deep Learning Amazon Machine Image)</h4>
<div class="paragraph">
<p><strong>AMI (Amazon Machine Image)</strong> is a concept that roughly corresponds to an OS (Operating System).
Naturally, a computer cannot do anything without an OS, so it is necessary to "install" some kind of OS whenever you start an EC2 instance.
The equivalent of the OS that is loaded in EC2 instance is the AMI.
For example, you can choose <a href="https://ubuntu.com/">Ubuntu</a> AMI to launch your EC2 instance.
As alternative options, you can select Windows Server AMI or
<a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux</a> AMI,
which is optimized for use with EC2.</p>
</div>
<div class="paragraph">
<p>However, it is an oversimplification to understand AMI as just an OS.
AMI can be the base (empty) OS, but AMI can also be an OS with custom programs already installed.
If you can find an AMI that has the necessary programs installed, you can save a lot of time and effort in installing and configuring the environment yourself.
To give a concrete example, in the first hands-on session, we showed an example of installing Python 3.6 on an EC2 instance, but doing such an operation every time the instance is launched is tedious!</p>
</div>
<div class="paragraph">
<p>In addition to the official AWS AMIs, there are also AMIs provided by third parties.
It is also possible to create and register your own AMI
(see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami-instance-store.html">official documentation</a>).
You can search for AMIs from the EC2 dashboard.
Alternatively, you can use the AWS CLI to obtain a list with the following command (also see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">official documentation</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws ec2 describe-images <span class="nt">--owners</span> amazon</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html">DLAMI (Deep Learning AMI)</a>
is an AMI pre-packaged with deep learning tools and programs.
DLAMI comes with popular deep learning frameworks and libraries such as <code>TensorFlow</code> and <code>PyTorch</code>, so you can run deep learning applications immediately after launching an EC2 instance.</p>
</div>
<div class="paragraph">
<p>In this hands-on, we will use a DLAMI based on Amazon Linux 2 (AMI ID = ami-09c0c16fc46a29ed9).
Let&#8217;s use the AWS CLI to get the details of this AMI.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws ec2 describe-images <span class="nt">--owners</span> amazon <span class="nt">--image-ids</span> <span class="s2">"ami-09c0c16fc46a29ed9"</span></code></pre>
</div>
</div>
<div id="handson_02_ami-info" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/ami-info.png" alt="ami-info" width="700">
</div>
<div class="title">Figure 20. Details of the AMI (ID = ami-09c0c16fc46a29ed9)</div>
</div>
<div class="paragraph">
<p>You should get an output like <a href="#handson_02_ami-info">Figure 20</a>.
From the output, we can see that the DLAMI has PyTorch versions 1.4.0 and 1.5.0 installed.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>What exactly is installed in DLAMI?
For the interested readers, here is a brief explanation
(Reference: <a href="https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html">official documentation "What Is the AWS Deep Learning AMI?"</a>).</p>
</div>
<div class="paragraph">
<p>At the lowest level, the GPU driver is installed.
Without the GPU driver, the OS cannot exchange commands with the GPU.
The next layer is
<a href="https://developer.nvidia.com/about-cuda">CUDA</a>
and
<a href="https://developer.nvidia.com/cudnn">cuDNN</a>.
CUDA is a language developed by NVIDIA for general-purpose computing on GPUs, and has a syntax that extends the C++ language.
cuDNN is a deep learning library written in CUDA, which implements operations such as n-dimensional convolution.
This is the content of the "Base" DLAMI.</p>
</div>
<div class="paragraph">
<p>The "Conda" DLAMI has libraries such as <code>TensorFlow</code> and <code>PyTorch</code> installed on top of the "Base" environment.
In addition, by using the virtual Python environment tool called
<a href="https://docs.conda.io/projects/conda/en/latest/index.html">Anaconda</a>,
users can easily switch between the environments for <code>TensorFlow</code>, <code>PyTorch</code>, <code>MxNet</code>, and so on
(we will use this feature later in the hands-on session).
Jupyter Notebook is also already installed.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_deploying_the_application">6.3. Deploying the application</h3>
<div class="paragraph">
<p>Now that we understand the application source code, let&#8217;s deploy it.</p>
</div>
<div class="paragraph">
<p>The deployment procedure is almost the same as the first hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>handson/mnist

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Generate SSH key</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">KEY_NAME</span><span class="o">=</span><span class="s2">"OpenSesame"</span>
<span class="nv">$ </span>aws ec2 create-key-pair <span class="nt">--key-name</span> <span class="k">${</span><span class="nv">KEY_NAME</span><span class="k">}</span> <span class="nt">--query</span> <span class="s1">'KeyMaterial'</span> <span class="nt">--output</span> text <span class="o">&gt;</span> <span class="k">${</span><span class="nv">KEY_NAME</span><span class="k">}</span>.pem
<span class="nv">$ </span><span class="nb">mv </span>OpenSesame.pem ~/.ssh/
<span class="nv">$ </span><span class="nb">chmod </span>400 ~/.ssh/OpenSesame.pem

<span class="c"># Deploy!</span>
<span class="nv">$ </span>cdk deploy <span class="nt">-c</span> <span class="nv">key_name</span><span class="o">=</span><span class="s2">"OpenSesame"</span></code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you did not delete the SSH key you created in the first hands-on, you do not need to create another SSH key.
Conversely, if an SSH with the same name already exists, the key generation command will output an error.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If the deployment is executed successfully, you should get an output like <a href="#handson_02_cdk_output">Figure 21</a>.
Note the IP address of your instance (the string following <code>InstancePublicIp</code>).</p>
</div>
<div id="handson_02_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 21. Output of <code>cdk deploy</code></div>
</div>
</div>
<div class="sect2">
<h3 id="_log_in_to_the_instance">6.4. Log in to the instance</h3>
<div class="paragraph">
<p>Let&#8217;s log in to the deployed instance using SSH.
To connect to Jupyter Notebook, which we will be using later, we must log in with the <strong>port forwarding</strong> option (<code>-L</code>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/OpenSesame.pem <span class="nt">-L</span> localhost:8931:localhost:8888 ec2-user@&lt;IP address&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Port forwarding means that the connection to a specific address on the client machine is forwarded to a specific address on the remote machine via SSH encrypted communication.
The option <code>-L localhost:8931:localhost:8888</code> means to forward the access to <code>localhost:8931</code> of your local machine to the address of <code>localhost:8888</code> of the remote server
(The number following <code>:</code> specifies the TCP/IP port number).
On port 8888 of the remote server, Jupyter Notebook (described below) is running.
Therefore, you can access Jupyter Notebook on the remote server by accessing <code>localhost:8931</code> on the local machine (<a href="#fig:ssh_port_forwarding">Figure 22</a>).
This type of SSH connection is called a <strong>tunnel connection</strong>.</p>
</div>
<div id="fig:ssh_port_forwarding" class="imageblock text-center">
<div class="content">
<img src="imgs/ssh_port_forwarding.png" alt="ssh_port_forwarding" width="700">
</div>
<div class="title">Figure 22. Accessing Jupyter Notebook with SSH port forwarding</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the port forwarding options, the port number (<code>:8931</code>, <code>:8888</code>, etc.) can be any integer between 1 and 65535.
Note, however, that some port numbers are already in use, such as port 22 (SSH) and port 80 (HTTP).</p>
</div>
<div class="paragraph">
<p>Jupyter Notebook uses port 8888 by default.
Therefore, it is recommended to use port 8888 for the remote side.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Don&#8217;t forget to assign the IP address of your instance to the <code>&lt;IP address&gt;</code> part of the SSH login command.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>For those who have done deployment using Docker:</strong></p>
</div>
<div class="paragraph">
<p>SSH login must be done from <strong>outside of Docker</strong>.
This is because the web browser that opens Jupyter is outside of Docker.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After logging in via SSH, let&#8217;s check the status of the GPU.
Run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>nvidia-smi</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should get output like <a href="#handson_02_nvidia-smi">Figure 23</a>.
The output shows that one Tesla T4 GPU is installed.
Other information such as the GPU driver, CUDA version, GPU load, and memory usage can be checked.</p>
</div>
<div id="handson_02_nvidia-smi" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/nvidia-smi.png" alt="nvidia-smi" width="700">
</div>
<div class="title">Figure 23. Output of <code>nvidia-smi</code></div>
</div>
</div>
<div class="sect2">
<h3 id="_launching_jupyter_notebook">6.5. Launching Jupyter Notebook</h3>
<div class="paragraph">
<p><a href="https://jupyter.org/">Jupyter Notebook</a>
is a tool for writing and running Python programs interactively.
Jupyter is accessed via a web browser, and can display plots and table data beautifully as if you were writing a notebook (<a href="#handson_02_welcome_jupyter">Figure 24</a>).
If you are familiar with Python, you have probably used it at least once.</p>
</div>
<div id="handson_02_welcome_jupyter" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/welcome_to_jupyter.png" alt="welcome to jupyter" width="700">
</div>
<div class="title">Figure 24. Jupyter Notebook GUI</div>
</div>
<div class="paragraph">
<p>In this hands-on session, we will run a deep learning program interactively using Jupyter Notebook.
Jupyter is already installed on DLAMI, so you can start using it without any configuration.</p>
</div>
<div class="paragraph">
<p>Now, let&#8217;s start Jupyter Notebook server.
On the EC2 instance where you logged in via SSH, run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">cd</span> ~ <span class="c"># go to home directory</span>
<span class="nv">$ </span>jupyter notebook</code></pre>
</div>
</div>
<div class="paragraph">
<p>When you run this command, you will see output like <a href="#handson_02_jupyter_launch">Figure 25</a>.
From this output, we can see that the Jupyter server is launched at the address <code>localhost:8888</code> of the EC2 instance.
The string <code>?token=XXXX</code> following <code>localhost:8888</code> is a temporary token used for accessing Jupyter.</p>
</div>
<div id="handson_02_jupyter_launch" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/jupyter_launch.png" alt="jupyter launch" width="700">
</div>
<div class="title">Figure 25. Launching Jupyter Notebook server</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When you start Jupyter Notebook for the first time, it may take a few minutes to start up.
Other operations are also slow immediately after startup, but after running a few commands, the system becomes agile and responsive.
This phenomenon is thought to be caused by the way the AWS operates the virtual machines with GPUs.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Since the port forwarding option was added to the SSH connection, you can access <code>localhost:8888</code>, where Jupyter is running, from <code>localhost:8931</code> on your local machine.
Therefore, to access Jupyter from the local machine, you can access the following address from a web browser (Chrome, FireFox, etc.).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>http://localhost:8931/?token=XXXX</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to replace <code>?token=XXXX</code> with the actual token that was issued when Jupyter server was started above.</p>
</div>
<div class="paragraph">
<p>If you access the above address, the Jupyter home screen should be loaded (<a href="#handson_02_jupyter_home">Figure 26</a>).
Now, Jupyter is ready!</p>
</div>
<div id="handson_02_jupyter_home" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/jupyter_home.png" alt="jupyter home" width="700">
</div>
<div class="title">Figure 26. Jupyter home screen</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Minimalistic guide to Jupyter Notebook</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Shift</code> + <code>Enter</code>: execute a cell</p>
</li>
<li>
<p><code>Esc</code>: Switch to <strong>Command mode</strong>.</p>
</li>
<li>
<p>Click "+" button on the menu bar or press <code>A</code> while in command mode &#8658; Add a new cell</p>
</li>
<li>
<p>Click "Scissors" button on the menu bar or press <code>X</code> while in command mode &#8658; delete a cell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For a list of shortcuts, see the
<a href="https://towardsdatascience.com/jypyter-notebook-shortcuts-bf0101a98330">blog by Ventsislav Yordanov</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_introduction_to_pytorch">6.6. Introduction to PyTorch</h3>
<div class="paragraph">
<p><a href="https://pytorch.org/">PyTorch</a> is an open source deep learning library that is being developed by the Facebook AI Research LAB (FAIR).
PyTorch is one of the most popular deep learning libraries at the time of writing, and is being used by Tesla in their self-driving project, to name a few.
In this hands-on session, we will use PyTorch to practice deep learning.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A Brief History of PyTorch</p>
</div>
<div class="paragraph">
<p>In addition to PyTorch, Facebook has been developing a deep learning framework called Caffe2
(The original Caffe was created by Yangqing Jia, a PhD student at UC Berkley).
Caffe2 was merged into the PyTorch project in 2018.</p>
</div>
<div class="paragraph">
<p>In December 2019, it was also announced that <a href="https://chainer.org/">Chainer</a>, which was developed by Preferred Networks in Japan, will also end its development and collaborate with the PyTorch development team.
(For more information, see <a href="https://chainer.org/announcement/2019/12/05/released-v7-ja.html">press release</a>).
PyTorch has a number of APIs that were inspired by Chainer even before the integration, and the DNA of Chainer is still being carried over to PyTorch&#8230;&#8203;!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Before we move on to some serious deep learning calculations, let&#8217;s use the PyTorch library to get a feel for what it is like to run computations on the GPU.</p>
</div>
<div class="paragraph">
<p>First, we&#8217;ll create a new notebook.
Click "New" in the upper right corner of the Jupyter home screen, select the environment "conda_pytorch_p36", and create a new notebook (<a href="#handson_02_jupyeter_new">Figure 27</a>).
In the "conda_pytorch_p36" virtual environment, PyTorch is already installed.</p>
</div>
<div id="handson_02_jupyeter_new" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/jupyter_new.png" alt="jupyter_new" width="700">
</div>
<div class="title">Figure 27. Creating a new notebook. Be sure to select "conda_pytorch_p36" environment.</div>
</div>
<div class="paragraph">
<p>Here, we will write and execute the following program (<a href="#handson_02_jupyeter_pytorch">Figure 28</a>).</p>
</div>
<div id="handson_02_jupyeter_pytorch" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/jupyter_pytorch.png" alt="jupyter_pytorch" width="700">
</div>
<div class="title">Figure 28. Introduction to PyTorch</div>
</div>
<div class="paragraph">
<p>First, we import PyTorch.
In addition, we check that the GPU is available.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Is CUDA ready?"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>Is CUDA ready? True</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s create a random 3x3 matrix <code>x</code> on <strong>CPU</strong>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>tensor([[0.6896, 0.2428, 0.3269],
        [0.0533, 0.3594, 0.9499],
        [0.9764, 0.5881, 0.0203]])</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, we create another matrix <code>y</code> on <strong>GPU</strong>.
We also move the matrix <code>x</code> on <strong>GPU</strong>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">"cuda"</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s">"cuda"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, we perform the addition of the matrix <code>x</code> and <code>y</code> on <strong>GPU</strong>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="k">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>tensor([[1.6896, 1.2428, 1.3269],
        [1.0533, 1.3594, 1.9499],
        [1.9764, 1.5881, 1.0203]], device='cuda:0')</code></pre>
</div>
</div>
<div class="paragraph">
<p>Lastly, we bring the matrix on GPU back on CPU.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s">"cpu"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>tensor([[1.6896, 1.2428, 1.3269],
        [1.0533, 1.3594, 1.9499],
        [1.9764, 1.5881, 1.0203]])</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above examples are just the rudiments of GPU-based computation, but we hope you get the idea.
The key is to explicitly exchange data between the CPU and GPU.
This example demonstrated an operation on 3x3 matrix, so the benefit of using GPU is almost negligible.
However, when the size of the matrix is in the thousands or tens of thousands, the GPU becomes much more powerful.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The finished Jupyter Notebook is available at
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/mnist/pytorch/pytorch_get_started.ipynb">/handson/mnist/pytorch/ pytorch_get_started.ipynb</a>.
You can upload this file by clicking "Upload" in the upper right corner of the Jupyter window, and run the code.</p>
</div>
<div class="paragraph">
<p>However, it is more effective to write all the code by yourself when you study.
That way the code and concepts will stick in your memory better.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let&#8217;s benchmark the speed of the GPU and the CPU and compare the performance.
We will use Jupyter&#8217;s
<a href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">%time</a>
magic command to measure the execution time.</p>
</div>
<div class="paragraph">
<p>First, using the CPU, let&#8217;s measure the speed of computing the matrix product of a 10000x10000 matrix.
Continuing from the notebook we were just workin with, paste the following code and run it.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="n">s</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">"cpu"</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="o">%</span><span class="n">time</span> <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The output should look something like shown below.
This means that it took 5.8 seconds to compute the matrix product (note that the measured time varies with each run).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>CPU times: user 11.5 s, sys: 140 ms, total: 11.6 s
Wall time: 5.8 s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s measure the speed of the same operation performed on the GPU.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="n">s</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">"cuda"</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

<span class="o">%</span><span class="n">time</span> <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">);</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The output should look something like shown below.
This time, the computation was completed in 553 milliseconds!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>CPU times: user 334 ms, sys: 220 ms, total: 554 ms
Wall time: 553 ms</code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In PyTorch, operations on the GPU are performed <strong>asynchronously</strong>.
For this reason, the benchmark code above embeds the statement <code>torch.cuda.synchronize()</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>From this benchmark, we were able to observe <strong>about 10 times speedup</strong> by using the GPU.
The speed-up performance depends on the type of operation and the size of the matrix.
The matrix product is one of the operations where the speedup is expected to be highest.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec_mnist_using_jupyter">6.7. MNIST Handwritten Digit Recognition Task</h3>
<div class="paragraph">
<p>Now that we have covered the concepts and prerequisites for deep learning computations on AWS, it&#8217;s time to run a real deep learning application.</p>
</div>
<div class="paragraph">
<p>In this section, we will deal with one of the most elementary and famous machine learning tasks, <strong>handwritten digit recognition using the MNIST dataset</strong> (<a href="#handson_02_mnist_examples">Figure 29</a>).
This is a simple task where we are given images of handwritten numbers from 0 to 9 and try to guess what the numbers are.</p>
</div>
<div id="handson_02_mnist_examples" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/mnist_examples.png" alt="mnist_examples" width="400">
</div>
<div class="title">Figure 29. MNIST handwritten digit dataset</div>
</div>
<div class="paragraph">
<p>Here, we will use <strong>Convolutional Neural Network (CNN)</strong> to solve the MNIST task.
The source code is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding-source-code/tree/main/handson/mnist/pytorch">/handson/minist/pytorch/</a>.
The relevant files are <code>mnist.ipynb</code> and <code>simple_mnist.py</code> in this directory.
This program is based on
<a href="https://github.com/pytorch/examples/tree/master/mnist">PyTorch&#8217;s official example project collection</a>,
with some modifications.</p>
</div>
<div class="paragraph">
<p>First, let&#8217;s upload <code>simple_mnist.py</code>, which contains custom classes and functions (<a href="#handson_02_jupyter_upload">Figure 30</a>).
Go to the home of the Jupyter, click on the "Upload" button in the upper right corner of the screen, and select the file to upload.
Inside this Python program, we defined the CNN model and the parameter optimization method.
We won&#8217;t explain the contents of the program, but readers interested in the subject can read the source code and learn for themselves.</p>
</div>
<div id="handson_02_jupyter_upload" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/jupyter_upload.png" alt="jupyter upload" width="600">
</div>
<div class="title">Figure 30. Uploading <code>simple_mnist.py</code></div>
</div>
<div class="paragraph">
<p>Once you have uploaded <code>simple_mnist.py</code>, you can create a new notebook.
Be sure to select the "conda_pytorch_p36" environment.</p>
</div>
<div class="paragraph">
<p>Once the new notebook is up and running, let&#8217;s import the necessary libraries first.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># custom functions and classes
</span><span class="kn">from</span> <span class="nn">simple_mnist</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">evaluate</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The
<a href="https://pytorch.org/docs/stable/torchvision/index.html">torchvision</a>
package contains some useful functions, such as loading MNIST datasets.
The above code also imports custom classes and functions (<code>Model</code>, <code>train</code>, <code>evaluate</code>) from <code>simple_mnist.py</code> that we will use later.</p>
</div>
<div class="paragraph">
<p>Next, we download the MNIST dataset.
At the same time, we are normalizing the intensity of the images.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="n">transf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                             <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))])</span>

<span class="n">trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transf</span><span class="p">)</span>
<span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">testset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transf</span><span class="p">)</span>
<span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The MNIST dataset consists of 28x28 pixel monochrome square images and corresponding labels (numbers 0-9).
Let&#8217;s extract some of the data and visualize them.
You should get an output like <a href="#handson_02_mnist_ground_truth">Figure 31</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td class="code"><pre><span class="n">examples</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">testloader</span><span class="p">)</span>
<span class="n">example_data</span><span class="p">,</span> <span class="n">example_targets</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="nb">next</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Example data size:"</span><span class="p">,</span> <span class="n">example_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">example_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Ground Truth: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">example_targets</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div id="handson_02_mnist_ground_truth" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/mnist_ground_truth.png" alt="mnist_ground_truth" width="700">
</div>
<div class="title">Figure 31. Examples of MNIST dataset</div>
</div>
<div class="paragraph">
<p>Next, we define the CNN model.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s">"cuda"</span><span class="p">)</span> <span class="c1"># load to GPU</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Model</code> class is defined in <code>simple_mnist.py</code>.
We will use a network with two convolutional layers and two fully connected layers, as shown in <a href="#handson_02_cnn_architecture">Figure 32</a>.
The output layer is the Softmax function, and the loss function is the negative log likelihood function (NLL).</p>
</div>
<div id="handson_02_cnn_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/cnn_architecture.png" alt="cnn architecture" width="700">
</div>
<div class="title">Figure 32. Architecture of the CNN we will be using in this hands-on</div>
</div>
<div class="paragraph">
<p>Next, we define an optimization algorithm to update the parameters of the CNN.
We use the <strong>Stochastic Gradient Descent (SGD)</strong> method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, we are ready to go.
Let&#8217;s start the CNN training loop!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
</pre></td><td class="code"><pre><span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">trainloader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="n">train_losses</span> <span class="o">+</span> <span class="n">losses</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">testloader</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Test set: Average loss: {test_loss:.4f}, Accuracy: {test_accuracy:.1f}</span><span class="si">%</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Iterations"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Train loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In this example, we are training for 5 epochs.
Using a GPU, computation like this can be completed in about a minute.</p>
</div>
<div class="paragraph">
<p>The output should be a plot similar to <a href="#handson_02_train_loss">Figure 33</a>.
You can see that the value of the loss function is decreasing (i.e. the accuracy is improving) as the iteration proceeds.</p>
</div>
<div id="handson_02_train_loss" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/train_loss.png" alt="train_loss" width="500">
</div>
<div class="title">Figure 33. Change of the train loss as learning proceeds</div>
</div>
<div class="paragraph">
<p>Let&#8217;s visualize the inference results of the learned CNN.
By running the following code, you should get an output like <a href="#handson_02_mnist_mnist_prediction">Figure 34</a>.
If you closely look at this figure, the second one from the right in the bottom row looks almost like a "1", but it is correctly inferred as a "9".
It looks like we have managed to create a pretty smart CNN!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td class="code"><pre><span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">example_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s">"cuda"</span><span class="p">))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">example_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Prediction: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div id="handson_02_mnist_mnist_prediction" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-jupyter/mnist_prediction.png" alt="mnist_prediction" width="700">
</div>
<div class="title">Figure 34. Inference results of the learned CNN</div>
</div>
<div class="paragraph">
<p>Finally, we save the parameters of the trained neural network as a file named <code>mnist_cnn.pt</code>.
This way, you can reproduce the learned model and use it for another experiment anytime in the future.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">"mnist_cnn.pt"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>That&#8217;s it!
We have experienced all the steps to set up a virtual server in the AWS cloud and perform the deep learning computation.
Using the GPU instance in the cloud, we were able to train a neural network to solve the MNIST digit recognition task.
Interested readers can use this hands-on as a template to run their own deep learning applications.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deleting_the_stack">6.8. Deleting the stack</h3>
<div class="paragraph">
<p>Now we are done with the GPU instance.
Before the EC2 cost builds up, we should delete the instance we no longer use.</p>
</div>
<div class="paragraph">
<p>As in the first hands-on session, we can delete the instance using the AWS CloudFormation console, or using the AWS CLI (see <a href="#handson_01_delete_stack">Section 4.4.8</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Make sure you delete your stack after the exercise!</strong>
If you do not do so, you will continue to be charged for the EC2 instance!
<code>g4dn.xlarge</code> is priced at $0.71 / hour, so if you keep it running for a day, you&#8217;ll be charged about $17!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>AWS budget alert</strong></p>
</div>
<div class="paragraph">
<p>One of the most common mistakes that AWS beginners (and even experienced users) make is to forget to stop an instance, leaving unattended resources in the cloud, and receiving a huge bill at the end of the month.
Especially during development, these error often occur and you should be prepared for this kind of situation to happen.
In order to prevent such a situation, a function called <strong>AWS Budgets</strong> is provided free of charge.
By using AWS Budgets, you can set up alerts such as sending an email to users when their monthly usage exceeds a certain threshold.
For detailed instructions, please refer to the
<a href="https://aws.amazon.com/blogs/aws-cost-management/getting-started-with-aws-budgets/">official AWS blog "Getting Started with AWS Budgets"</a>.
Now is a good oportunity for you to set up alerts on your account.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_docker_introduction">7. Introduction to Docker</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the hands-on exercises described in the previous chapters, we have set up <em>a single server</em>, logged in to it via SSH, and performed calculations by typing commands.
In other words, we have been using the cloud as <em>an extension of our personal computers</em>.
This kind of use of the cloud as a personal computer is, of course, convenient and has many potential applications.
However, the true value of the cloud is not fully demonstrated by this alone.
As described in <a href="#chap_cloud_basics">Section 2</a>, the greatest strength of the modern cloud is the ability to freely expand the scale of computing.
That is to say, the true potential of the cloud can only be demonstrated by processing large amounts of data by running many servers simultaneously and executing multiple jobs in a distributed parallel fashion.</p>
</div>
<div class="paragraph">
<p>Using the three sections starting from this chapter (<a href="#sec_docker_introduction">Section 7</a>, <a href="#sec_fargate_qabot">Section 8</a>, <a href="#sec_aws_batch">Section 9</a>), we would like to show you a glimpse of how to build a large-scale computing system using the cloud to tackle challenges like the big data analysis.
In particular, we would like to focus our discussion on how to apply the deep learning to big data.
As a prelude to this, this chapter introduces a virtualization software called <a href="https://www.docker.com/">Docker</a>.
It would not be an exaggeration to say that modern cloud computing would not be possible without Docker.
Docker is very useful not only for cloud computing, but also for local computation.
This is a bit of a departure from AWS, but it&#8217;s important to understand Docker well enough to move forward.</p>
</div>
<div class="sect2">
<h3 id="_scaling_up_machine_learning">7.1. Scaling up machine learning</h3>
<div class="paragraph">
<p>We have been repeatedly calling for "large-scale computing systems," but what exactly does that mean?
Let&#8217;s take machine learning as an example, and talk about a computer system for processing large data.</p>
</div>
<div class="paragraph">
<p>Suppose we want to train a deep learning model with a very large number of parameters, such as <a href="https://github.com/openai/gpt-3">GPT-3</a> introduced in <a href="#sec_scientific_computing">Section 5</a>.
If you want to perform such a computation, a single server will not have enough computing power.
Therefore, the typical design of a computing system would be a model shown in <a href="#big_dnn_training">Figure 35</a>.
Namely, a large amount of training data is distributed in small chunks across multiple machines, and the parameters of the neural network are optimized in parallel.</p>
</div>
<div id="big_dnn_training" class="imageblock text-center">
<div class="content">
<img src="imgs/big_dnn_training.png" alt="big_dnn_training" width="700">
</div>
<div class="title">Figure 35. Training large-scale deep learning models using multiple computers.</div>
</div>
<div class="paragraph">
<p>Or, let&#8217;s say you want to apply a trained model to a large amount of data for analysis.
For example, you have a SNS platform and you are given a large number of images, and you want to label what is in each photo.
In such a case, an architecture such as the one shown in <a href="#big_dnn_inference">Figure 36</a> can be considered, in which a large amount of data is divided among multiple machines, and each machine performs inference computation.</p>
</div>
<div id="big_dnn_inference" class="imageblock text-center">
<div class="content">
<img src="imgs/big_dnn_inference.png" alt="big_dnn_inference" width="700">
</div>
<div class="title">Figure 36. Parallel inference using deep learning models</div>
</div>
<div class="paragraph">
<p>How can such applications that run multiple computers simultaneously be implemented in the cloud?</p>
</div>
<div class="paragraph">
<p>One important point is that the multiple machines running <a href="#big_dnn_training">Figure 35</a> and <a href="#big_dnn_inference">Figure 36</a> have <strong>basically the same OS and computing environment</strong>.
Here, it is possible to perform the same installation operations on each machine as one would do on an individual computer, but this would be very time-consuming and cumbersome to maintain.
In other words, in order to build a large-scale computing system, it is necessary to have a <strong>mechanism that allows to easily replicate the computing environment</strong>.</p>
</div>
<div class="paragraph">
<p>To achieve this goal, a software called <a href="https://www.docker.com/">Docker</a> is used.</p>
</div>
</div>
<div class="sect2">
<h3 id="_what_is_docker">7.2. What is Docker?</h3>
<div id="fig:docker_logo" class="imageblock text-center">
<div class="content">
<img src="imgs/docker_log.png" alt="docker" width="500">
</div>
<div class="title">Figure 37. Docker ã®ã‚¢ã‚¤ã‚³ãƒ³</div>
</div>
<div class="paragraph">
<p>Docker is software for running a separate computing environment independent of the host OS in a virtual environment called a <strong>container</strong>.
Docker makes it possible to package all programs, including the OS, in a compact package (a packaged computing environment is called an <strong>image</strong>).
Docker makes it possible to instantly replicate a computing environment on a cloud server, and to create a system for running multiple computers simultaneously, as seen in <a href="#big_dnn_inference">Figure 36</a>.</p>
</div>
<div class="paragraph">
<p>Docker was developed by Solomon Hykes and his fellows in 2013, and since then it has exploded in popularity, becoming core software not only for cloud computing but also in the context of machine learning and scientific computing.
Docker is available free of charge, except for enterprise products, and its core is available as an
<a href="https://github.com/moby/moby">open source</a>
project.
Docker is available for Linux, Windows, and Mac operating systems.
Conceptually, Docker is very similar to a virtual machine (VM).
Comparing Docker with VM is a very useful way to understand what Docker is, so here we take this approach.</p>
</div>
<div class="paragraph">
<p>A virtual machine (VM) is a technology that allows to run virtualized operating systems on top of a host machine (<a href="#docker_vs_vm">Figure 38</a>).
A VM has a layer called a <strong>hypervisor</strong>.
The hypervisor first divides the physical computing resources (CPU, RAM, network, etc.) and virtualizes them.
For example, if the host machine has four physical CPU cores, the hypervisor can virtually divide them into (2,2) pairs.
The OS running on the VM is allocated virtualized hardware by the hypervisor.
OSes running on VM are completely independent.
For example, OS-A cannot access the CPU or memory space allocated to OS-B (this is called <strong>isolation</strong>).
Famous software for creating VMs includes
<a href="https://www.vmware.com/">VMware</a>,
<a href="https://www.virtualbox.org/">VirtualBox</a>,
and
<a href="https://xenproject.org/">Xen</a>.
EC2, which we have used earlier, basically uses VM technology to present the user with a virtual machine with the desired specifications.</p>
</div>
<div class="paragraph">
<p>Docker, like VM, is a technology for running a virtualized OS on a host OS.
In contrast to VMs, Docker does not rely on hardware-level virtualization; all virtualization is done at the <strong>software level</strong> (<a href="#docker_vs_vm">Figure 38</a>).
The virtual OS running on Docker relies on the host OS for much of its functionality, and as a result is very compact.
Consequently, the time required to boot a virtual OS with Docker is much faster than with a VM.
It is also important to note that the size of the packaged environment (i.e., image) is much smaller than that of a full OS, which greatly speeds up communication over the network.
In addition, some implementations of VMs are known to have lower performance than metal (metal means OS running directly on physical hardware) due to the overhead at the hypervisor layer.
Docker is designed to be able to achieve almost the same performance as metal.</p>
</div>
<div class="paragraph">
<p>There are many other differences between Docker and VM, but we will not go into details here.
The important point is that <strong>Docker is a tool for creating a very compact and high-performance virtual computing environment</strong>.
Because of its ease of use and lightness, Docker has been adopted in many cloud systems since its introduction in 2013, and it has become an essential core technology in the modern cloud.</p>
</div>
<div id="docker_vs_vm" class="imageblock text-center">
<div class="content">
<img src="imgs/docker_vs_vm.png" alt="docker_vs_vm" width="700">
</div>
<div class="title">Figure 38. Comparison of Docker (left) and VM (right) (image source: <a href="https://www.docker.com/blog/containers-replacing-virtual-machines/" class="bare">https://www.docker.com/blog/containers-replacing-virtual-machines/</a>)</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Column: The three sacred treasures of programmers</div>
<div class="paragraph">
<p>What are the "three sacred treasures" for professional programmers?
There should be many different opinions, but I would like to mention <strong>Git</strong>, <strong>Vim</strong>, and <strong>Docker</strong>.</p>
</div>
<div class="paragraph">
<p>Git, as many of you know, is a system for tracking code changes.
It was created in 2005 by Linus Torvalds, the creator of Linux.
It is an indispensable tool for team development.</p>
</div>
<div class="paragraph">
<p>Vim is a text editor that has been a favorite of programmers for more than 30 years.
According to
<a href="https://insights.stackoverflow.com/survey/2019#technology-development-environments-and-tools-all-respondents">2019 survey conducted by Stackoverflow</a>,
it is the fifth most popular development environment.
It provides a lot of shortcuts and a variety of custom settings.
Vim can be quite challenging for beginners, but once mastered, it can provide a development experience that is as good as or better than other modern editors and integrated development environments.</p>
</div>
<div class="paragraph">
<p>Along with these decade-old tools, I would like to mention Docker as the third of the big three.
Docker has revolutionized the development workflow of programmers.
For example, by creating a Docker image for each project, you can now develop and test on the exact same environment on any OS and any computer.
In addition, the modern concepts like
<a href="https://en.wikipedia.org/wiki/DevOps">DevOps</a>
and
<a href="https://en.wikipedia.org/wiki/Continuous_integration">CI</a> / <a href="https://en.wikipedia.org/wiki/Continuous_delivery">CD</a>
(Continuous Integration / Continuous Deployment)
are based on the existence of container technologies such as Docker.</p>
</div>
<div class="paragraph">
<p>What are the three sacred treasures for you?
And what new tools will revolutionize programmers' workflows in the future?</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_docker_tutorial">7.3. Docker tutorial</h3>
<div class="paragraph">
<p>The most effective way to understand what Docker is is to actually try it out.
In this section, I will give a brief tutorial on Docker.</p>
</div>
<div class="paragraph">
<p>For Docker installation, please refer to <a href="#sec:install_docker">Section 14.6</a> and <a href="https://docs.docker.com/engine/install/">official documentation</a>.
The following assumes that you have already installed Docker.</p>
</div>
<div class="sect3">
<h4 id="_docker_terminology">7.3.1. Docker terminology</h4>
<div class="paragraph">
<p>To get you started with Docker, let us first define some key terms.</p>
</div>
<div class="paragraph">
<p><a href="#fig:docker_image_container">Figure 39</a> shows the general steps to start Docker.
A packaged computing environment is called an <strong>image</strong>.
Images can be downloaded from repositories such as Docker Hub, or you can create your own custom images.
The file that describes the "recipe" for creating an image is called <strong>Dockerfile</strong>.
The operation to create an image from a Dockerfile is called <strong>build</strong>.
When an image is loaded in to the host machine&#8217;s memory, the virtual environment is ready, which is called a <strong>container</strong>.
The command used to start the container is <strong>run</strong>.</p>
</div>
<div id="fig:docker_image_container" class="imageblock text-center">
<div class="content">
<img src="imgs/docker_image_container.png" alt="docker_image_container" width="700">
</div>
<div class="title">Figure 39. Docker image and container</div>
</div>
</div>
<div class="sect3">
<h4 id="_downloading_an_image">7.3.2. Downloading an image</h4>
<div class="paragraph">
<p>The packaged Docker virtual environment (=<strong>image</strong>) can be downloaded from <a href="https://hub.docker.com/">Docker Hub</a>.
Docker Hub hosts Docker images created by individuals, companies, and organizations, and is open to the public just like GitHub.</p>
</div>
<div class="paragraph">
<p>For example, Ubuntu images are available at
<a href="https://hub.docker.com/_/ubuntu" class="bare">https://hub.docker.com/_/ubuntu</a> [the official Ubuntu repository],
and can be downloaded to the local machine by using the <code>pull</code> command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker pull ubuntu:18.04</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, the string following the <code>:</code> (colon) in the image name is called a <strong>tag</strong> and is mainly used to specify the version.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <code>pull</code> command by default searches for images on Docker Hub.
On the other hand, there are many other databases to host Docker images (called registries).
For example, GitLab and GitHub provide their own image registries, and it is also possible to set up a registry on your own server.
To pull from a registry other than Docker Hub, specify the address (and optionally the port number) of the registry by prefixing the image name with the registry address.
For instance, <code>myregistry.local:5000/testing/test-image</code>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_launching_a_container">7.3.3. Launching a container</h4>
<div class="paragraph">
<p>To launch a container from the image, use the <code>run</code> command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">-it</span> ubuntu:18.04</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, <code>-it</code> is an option required to start an interactive shell session.</p>
</div>
<div class="paragraph">
<p>When this command is executed, the virtualized Ubuntu will be launched and commands can be typed from the command line (<a href="#docker_shell">Figure 40</a>).
A computational environment (runtime) in running state is called a <strong>container</strong>.</p>
</div>
<div id="docker_shell" class="imageblock text-center">
<div class="content">
<img src="imgs/docker_shell.png" alt="docker_shell" width="600">
</div>
<div class="title">Figure 40. Launching ubuntu:18.04 container</div>
</div>
<div class="paragraph">
<p>The <code>ubuntu:18.04</code> image used here is an empty Ubuntu OS, but there are other images available with some programs already installed.
This is similar to the concept of DLAMI as we saw in <a href="#sec_jupyter_and_deep_learning">Section 6</a>.
For example, an image with PyTorch already installed is available at
<a href="https://hub.docker.com/r/pytorch/pytorch">PyTorch&#8217;s official Docker Hub repository</a>.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s launch this image.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ docker run -it pytorch/pytorch</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When you run <code>docker run</code>, if the corresponding image is not found locally, it will be downloaded from Docker Hub automatically.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once the PyTorch container is up and running, lanch a Python shell and test importing pytorch.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python3
Python 3.7.7 <span class="o">(</span>default, May  7 2020, 21:25:33<span class="o">)</span>
<span class="o">[</span>GCC 7.3.0] :: Anaconda, Inc. on linux
Type <span class="s2">"help"</span>, <span class="s2">"copyright"</span>, <span class="s2">"credits"</span> or <span class="s2">"license"</span> <span class="k">for </span>more information.
<span class="o">&gt;&gt;&gt;</span> import torch
<span class="o">&gt;&gt;&gt;</span> torch.cuda.is_available<span class="o">()</span>
False</code></pre>
</div>
</div>
<div class="paragraph">
<p>As we saw in these examples, Docker makes it possible to easily reproduce a computing environment with a specific OS and program.</p>
</div>
</div>
<div class="sect3">
<h4 id="_making_your_own_image">7.3.4. Making your own image</h4>
<div class="paragraph">
<p>It is also possible to create your own image which includes any softwares your application may require.</p>
</div>
<div class="paragraph">
<p>For example,
<a href="https://hub.docker.com/repository/docker/tomomano/labc">the docker image provided for the hands-on exercises in this book</a>
comes with Python, Node.js, AWS CLI, and AWS CDK already installed, so you can run the hands-on program immediately after pulling the image.</p>
</div>
<div class="paragraph">
<p>To create a custom docker image, all you need to do is to prepare a file named <code>Dockerfile</code> and describe what programs you want to install in it.</p>
</div>
<div class="paragraph">
<p>As an example, let&#8217;s take a look at the Docker image recipe provided in this book
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/docker/Dockerfile">docker/Dockerfile</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="docker"><span class="k">FROM</span><span class="s"> node:12</span>
<span class="k">LABEL</span><span class="s"> maintainer="Tomoyuki Mano"</span>

<span class="k">RUN </span>apt-get update <span class="se">\
</span>    <span class="o">&amp;&amp;</span> apt-get <span class="nb">install </span>nano

<i class="conum" data-value="1"></i><b>(1)</b>
<span class="k">RUN </span><span class="nb">cd</span> /opt <span class="se">\
</span>    <span class="o">&amp;&amp;</span> curl <span class="nt">-q</span> <span class="s2">"https://www.python.org/ftp/python/3.7.6/Python-3.7.6.tgz"</span> <span class="nt">-o</span> Python-3.7.6.tgz <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">tar</span> <span class="nt">-xzf</span> Python-3.7.6.tgz <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">cd </span>Python-3.7.6 <span class="se">\
</span>    <span class="o">&amp;&amp;</span> ./configure <span class="nt">--enable-optimizations</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> make <span class="nb">install</span>

<span class="k">RUN </span><span class="nb">cd</span> /opt <span class="se">\
</span>    <span class="o">&amp;&amp;</span> curl <span class="s2">"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"</span> <span class="nt">-o</span> <span class="s2">"awscliv2.zip"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> unzip awscliv2.zip <span class="se">\
</span>    <span class="o">&amp;&amp;</span> ./aws/install

<i class="conum" data-value="2"></i><b>(2)</b>
<span class="k">RUN </span>npm <span class="nb">install</span> <span class="nt">-g</span> aws-cdk@1.100

<span class="c"># clean up unnecessary files</span>
<span class="k">RUN </span><span class="nb">rm</span> <span class="nt">-rf</span> /opt/<span class="k">*</span>

<span class="c"># copy hands-on source code in /root/</span>
<span class="k">COPY</span><span class="s"> handson/ /root/handson</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We won&#8217;t go into detail about <code>Dockerfile</code>.
But, for example, in the code above, &lt;1&gt; installs Python 3.7, and &lt;2&gt; installs the AWS CDK.
You can create your own Docker image by describing the installation commands one by one in the same way as you would do for a real OS.
Once the image is created, it can be distributed to others so that they can easily reproduce the same computing environment.</p>
</div>
<div class="paragraph">
<p>"That program runs in my computer&#8230;&#8203;" is a common phrase among novice programmers.
With Docker, you say goodbye to those concerns.
In this sense, Docker&#8217;s usefulness and versatility is extremely high even in the contexts other than cloud computing.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Column: Is Docker alone?</div>
<div class="paragraph">
<p>We introduced Docker as a virtual computing tool using containers, but are there any other options?
Well, you asked me!
Since Docker&#8217;s inception several container-based virtual environment tools have been developed, all of which share many of the same concepts and APIs as Docker, but offer unique features not found in Docker.
Here, I will introduce some of the most famous ones.</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/hpcng/singularity">Singularity</a>
is a popular container platform in scientific computing and HPC (High Performance Computing) community.
Singularity is designed to work well in HPC clusters at universities and research institutions.
For example, while Docker is basically run with root privileges, Singularity is run with user privileges.
The root privilege is not a problem for servers operated by individuals or companies for specific services such as web servers, but it is a problem for HPC clusters where many users execute computations for various purposes.
Singularity has its own image creation method and ecosystem, but it also offers a function to convert Docker images into Singularity images.</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/containers/podman">podman</a>
is another container platform developed by Red Hat.
podman uses basically the same commands as Docker, but the implementation was done from scratch by Red Hat.
Like Singularity, podman allows programs to be executed with user privileges, and was designed to be a container platform for both cloud and HPC environments.
As its name suggests, it introduces a unique concept called pod.</p>
</div>
<div class="paragraph">
<p>The author&#8217;s personal opinion is that mastering Docker is sufficient for the time being, but readers who are interested should definitely try these tools as well.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_elastic_container_service_ecs">7.4. Elastic Container Service (ECS)</h3>
<div id="fig:logo_ecs" class="imageblock">
<div class="content">
<img src="imgs/aws_logos/ECS.png" alt="ECS" width="100">
</div>
<div class="title">Figure 41. ECS icon</div>
</div>
<div class="paragraph">
<p>As we have explained so far, Docker is a highly versatile and powerful tool to replicate and launch a virtual computing environment.
As the last topic of this section, we will talk about how to build a computing system using Docker on AWS.</p>
</div>
<div class="paragraph">
<p><strong>Elastic Container Service (ECS)</strong> is a tool for creating Docker-based compute clusters on AWS (<a href="#fig:logo_ecs">Figure 41</a>).
Using ECS, you can define tasks using Docker images, create a compute cluster, and add or remove instances in the compute cluster.</p>
</div>
<div class="paragraph">
<p><a href="#ecs_overview">Figure 42</a> shows an overview of ECS.
The ECS accepts computation jobs managed in units called <strong>tasks</strong>.
When a task is submitted to the system, ECS first downloads the Docker image specified by the task from an external registry.
The external registry can be Docker Hub or AWS' own image registry, <strong>ECR (Elastic Container Registry)</strong>.</p>
</div>
<div class="paragraph">
<p>The next important role of ECS is task placement.
By selecting a virtual instance with low computational load in a predefined cluster, ECS places a Docker image on it, and the task is started.
When we say "select a virtual instance with low computational load," the specific strategy and policy for this selection depends on the parameters specified by the user.</p>
</div>
<div class="paragraph">
<p>Scaling of clusters is another important role of ECS.
Scaling refers to the operation of monitoring the computational load of the instances in a cluster, and starting and stopping the instances according to the total load on the cluster.
When the computational load of the entire cluster exceeds a specified threshold (e.g., 80% utilization), a new virtual instance is launched (an operation called scale-out).
When the computational load is below a certain threshold, unnecessary instances are stoped (an operation called scale-in).
The scaling of a cluster is achieved by the ECS cooperating with other AWS services.
Specifically, ECS is most commonly paired with <strong>Auto scaling group (ASG)</strong> or <strong>Fargate</strong>.
ASG and Fargate, respectively will be covered in <a href="#sec_aws_batch">Section 9</a> and <a href="#sec_fargate_qabot">Section 8</a>.</p>
</div>
<div class="paragraph">
<p>ECS automatically manages the above explained operations for you.
Once the parameters for cluster scaling and task placement are specified, the user can submit a large number of tasks, almost without thinking about behind the scenes.
ECS will launch just enough instances for the amount of tasks, and after the tasks are completed, all unnecessary instances will be stopped, eliminating idling instances completely.</p>
</div>
<div class="paragraph">
<p>The theory and knowledge stuffs are over now!
From the next section, let&#8217;s start building a large-scale parallel computing system using Docker and ECS!</p>
</div>
<div id="ecs_overview" class="imageblock text-center">
<div class="content">
<img src="imgs/ecs.png" alt="ecs" width="500">
</div>
<div class="title">Figure 42. ECS overview</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_fargate_qabot">8. Hands-on #3: Deploying a question-answering bot on AWS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the third hands-on session, we will implement a machine learning application using Docker and ECS.
Specifically, we will create an automatic question-answering bot that generates answers to questions given by the client by performing natural language processing.
By using ECS, we will build a system that dynamically controls the number of instances according to the number of jobs, and executes tasks in parallel.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In a typical machine learning workflow, the normal workflow is model training followed by inference (application to data).
However, training models using EC2 clusters with GPUs is a little advanced, so it will be covered in the next sectopm (<a href="#sec_aws_batch">Section 9</a>).
This section introduces the parallelization of the inference using Fargate clusters, which can be implemented in a simpler program.
This way you can familiarize yourself with the concepts of building clusters and managing tasks in the cloud.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_fargate">8.1. Fargate</h3>
<div class="paragraph">
<p>Before getting into the hands-on exercuse, we need to learn about <strong>Fargate</strong>(<a href="#fig:fargate_logo">Figure 43</a>).</p>
</div>
<div id="fig:fargate_logo" class="imageblock">
<div class="content">
<img src="imgs/aws_logos/Fargate.png" alt="Fargate" width="100">
</div>
<div class="title">Figure 43. Fargate icon</div>
</div>
<div class="paragraph">
<p>Let&#8217;s look again at <a href="#ecs_overview">Figure 42</a>, which gives an overview of ECS.
This figure shows a cluster under the control of ECS, and there are two choices which carry out the computation in the cluster: either EC2 or Fargate.
In the case of using EC2, the instance is launched in the same way as described in the previous sections (<a href="#sec_first_ec2">Section 4</a>, <a href="#sec_jupyter_and_deep_learning">Section 6</a>).
However, the technical difficulty of creating and managing a compute cluster using EC2 is rather high, so we will explain it in the next section (<a href="#sec_aws_batch">Section 9</a>).</p>
</div>
<div class="paragraph">
<p>Fargate is a mechanism for running <strong>container-based computational tasks</strong>, designed specifically for use in <strong>ECS</strong>.
In terms of running computation, its role is similar to that of EC2, but Fargate does not have a physical entity like an EC2 instance.
It means that, for example, logging in via SSH is basically not expected in Fargate, and there is no operations like "installing software".
In Fargate, all computation is executed via Docker containers.
Namely, to use Fargate, the user first prepares the Docker image, and then Fargate executes the computational task by using the <code>docker run</code> command.
When Fargate is specified as an ECS cluster, operations such as scaling can be built with a simple configuration and program.</p>
</div>
<div class="paragraph">
<p>Similar to EC2, Fargate allows you to specify the size of the CPU and memory as needed.
At the time of writing, you can choose between 0.25 and 4 cores for vCPU power, and 0.5 and 30 GB for RAM (for details, see
<a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate.html">Official Documentation "Amazon ECS on AWS Fargate"</a>]).
Despite the ease of scaling clusters, Fargate does not allow for a large vCPU counts or RAM capacity, nor does it allow for the use of GPUs.  as in EC2 instances.</p>
</div>
<div class="paragraph">
<p>So that was an overview of Fargate, but it may not be easy to understand it all in words.
From here on, let us learn how to work with ECS and Fargate by writing a real program to deploy parallel computing system.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Strictly speaking, it is also possible to use a hybrid of EC2 and Fargate for the clusters attached to the ECS.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_preparations">8.2. Preparations</h3>
<div class="paragraph">
<p>The source code of the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/qa-bot">handson/qa-bot</a>.</p>
</div>
<div class="paragraph">
<p>To run this hands-on, it is assumed that the preparations described in the first hands-on (<a href="#handson_01_prep">Section 4.1</a>) have been completed.
It is also assumed that Docker is already installed on your local machine.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For this hands-on, we will use a 1CPU/4GB RAM Fargate instance.
Note that this will cost 0.025 $/hour to run the computation.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_a_question_answering_bot_using_transformer">8.3. A question-answering bot using Transformer</h3>
<div class="paragraph">
<p>Let&#8217;s define more concretely the automatic question answering system that we will develop in this hands-on session.
Assume that we are given the following context and question.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>context: Albert Einstein (14 March 1879 â€“ 18 April 1955) was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science. He is best known to the general public for his massâ€“energy equivalence formula E = mc2, which has been dubbed \"the world's most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory.

question: In what year did Einstein win the Nobel prize?</pre>
</div>
</div>
<div class="paragraph">
<p>The automatic answering system we are going to create will be able to find the correct answer to such a question, given the context.
To make the problem a bit easier, the answer is selected from the string contained in the context.
For example, for the above question, the system should return the following answer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>answer: 1921</pre>
</div>
</div>
<div class="paragraph">
<p>While it is trivial for humans to understand such sentences, it is easy to imagine how difficult it would be for a computer to solve them.
However, recent progress in natural language processing using deep learning has made remarkable progress, and it is possible to create models that can solve this problem with an extremely high accuracy.</p>
</div>
<div class="paragraph">
<p>In this hands-on, we will use the pre-trained language model provided by
<a href="https://github.com/huggingface/transformers">huggingface/transformers</a>.
This model is supported by a natural language processing model called
<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer</a>
We packaged this model in a Docker image, and the image is available at the author&#8217;s
<a href="https://hub.docker.com/repository/docker/tomomano/qabot">Docker Hub repository</a>.
Before we start designing the cloud system, let&#8217;s test this Docker image on the local machine.</p>
</div>
<div id="transformer_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/transformer.png" alt="transformer" width="400">
</div>
<div class="title">Figure 44. Transformer (image source: <a href="https://arxiv.org/abs/1706.03762">Vaswani+ 2017</a>)</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Since we are using a pre-trained model, all we need to do is to feed the given input into the model and make a prediction (inference).
Since the inference operations can be done quickly enough on a CPU alone, we will not use a GPU in this hands-on session to reduce the cost and simplify the implementation.
In general, training is much more computationally expensive for neural nets, and the GPU is more powerful in such cases.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Use the following command to download (pull) the Docker image to your local machine.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker pull tomomano/qabot:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, let&#8217;s submit a question to this Docker image.
First, define the context and question as command line variables.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ context</span><span class="o">=</span><span class="s2">"Albert Einstein (14 March 1879 â€“ 18 April 1955) was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science. He is best known to the general public for his massâ€“energy equivalence formula E = mc2, which has been dubbed the world's most famous equation. He received the 1921 Nobel Prize in Physics for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect, a pivotal step in the development of quantum theory."</span>
<span class="nv">$ question</span><span class="o">=</span><span class="s2">"In what year did Einstein win the Nobel prize ?"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, use the following command to run the container.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run tomomano/qabot <span class="s2">"</span><span class="k">${</span><span class="nv">context</span><span class="k">}</span><span class="s2">"</span> <span class="s2">"</span><span class="k">${</span><span class="nv">question</span><span class="k">}</span><span class="s2">"</span> foo <span class="nt">--no_save</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The Docker image we prepared accepts the context as the first argument and the question as the second argument.
The third and fourth arguments are for implementation purposes when deploying to the cloud, so don&#8217;t worry about them for now.</p>
</div>
<div class="paragraph">
<p>When you execute this command, you should get the following output.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{'score': 0.9881729286683587, 'start': 437, 'end': 441, 'answer': '1921'}</pre>
</div>
</div>
<div class="paragraph">
<p>"score" is a number that indicates the confidence level of the answer, in the range [0,1].
"start" and "end" indicate the starting and ending position in the context where the answer is, and "answer" is the string predicted as the answer.
Notice that the correct answer, "1921", was returned.</p>
</div>
<div class="paragraph">
<p>Let us ask a more difficult question.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ question</span><span class="o">=</span><span class="s2">"Why did Einstein win the Nobel prize ?"</span>
<span class="nv">$ </span>docker run tomomano/qabot <span class="s2">"</span><span class="k">${</span><span class="nv">context</span><span class="k">}</span><span class="s2">"</span> <span class="s2">"</span><span class="k">${</span><span class="nv">question</span><span class="k">}</span><span class="s2">"</span> foo <span class="nt">--no_save</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{'score': 0.5235594527494207, 'start': 470, 'end': 506, 'answer': 'his services to theoretical physics,'}</pre>
</div>
</div>
<div class="paragraph">
<p>This time, the score is 0.52, indicating that the bot is a little unsure of the answer, but it still got the right answer.</p>
</div>
<div class="paragraph">
<p>As you can see, by using a language model supported by deep learning, we have been able to create a Q&amp;A bot that can be useful in practical applications.
In the following sections, we will design a system that can automatically respond to a large number of questions by deploying this program in the cloud.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The question &amp; answering system used in this project uses a Transformer-based language model called DistilBERT.
Interested readers can refer to
<a href="https://arxiv.org/abs/1910.01108">original paper</a>.
For documentation of the DistilBert implementation by huggingface/transformers, see
<a href="https://huggingface.co/transformers/model_doc/distilbert.html">official documentation</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The source code for the Q-A bot Docker image is available at
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/qa-bot/docker/Dockerfile">GitHub</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_reading_the_application_source_code_3">8.4. Reading the application source code</h3>
<div class="paragraph">
<p><a href="#handson_03_architecture">Figure 45</a> shows an overview of the application we are creating in this hands-on.</p>
</div>
<div id="handson_03_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/handson-03-architecture.png" alt="hands-on 03 architecture" width="600">
</div>
<div class="title">Figure 45. Application architecture</div>
</div>
<div class="paragraph">
<p>The summary of the system design is as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client sends a question to the application on AWS.</p>
</li>
<li>
<p>The task to solve the submitted question is handled by ECS.</p>
</li>
<li>
<p>ECS downloads an image from Docker Hub.</p>
</li>
<li>
<p>ECS then launches a new Fargate instance in the cluster and places the downloaded Docker image in this new instance</p>
<div class="ulist">
<ul>
<li>
<p>One Fargate instance is launched for each question so that multiple questions can be processed in parallel.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The job is executed. The results of the job (the answers to the questions) are written to the DynamoDB database.</p>
</li>
<li>
<p>Finally, the client reads the answers to the questions from DynamoDB.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now let us take a look at the main application code
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/qa-bot/app.py">handson/qa-bot/app.py</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">EcsClusterQaBot</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <i class="conum" data-value="1"></i><b>(1)</b>
        <span class="c1"># dynamoDB table to store questions and answers
</span>        <span class="n">table</span> <span class="o">=</span> <span class="n">dynamodb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-Table"</span><span class="p">,</span>
            <span class="n">partition_key</span><span class="o">=</span><span class="n">dynamodb</span><span class="o">.</span><span class="n">Attribute</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s">"item_id"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">dynamodb</span><span class="o">.</span><span class="n">AttributeType</span><span class="o">.</span><span class="n">STRING</span>
            <span class="p">),</span>
            <span class="n">billing_mode</span><span class="o">=</span><span class="n">dynamodb</span><span class="o">.</span><span class="n">BillingMode</span><span class="o">.</span><span class="n">PAY_PER_REQUEST</span><span class="p">,</span>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span>
        <span class="p">)</span>

        <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-Vpc"</span><span class="p">,</span>
            <span class="n">max_azs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="n">cluster</span> <span class="o">=</span> <span class="n">ecs</span><span class="o">.</span><span class="n">Cluster</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-Cluster"</span><span class="p">,</span>
            <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
        <span class="p">)</span>

        <i class="conum" data-value="4"></i><b>(4)</b>
        <span class="n">taskdef</span> <span class="o">=</span> <span class="n">ecs</span><span class="o">.</span><span class="n">FargateTaskDefinition</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-TaskDef"</span><span class="p">,</span>
            <span class="n">cpu</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="c1"># 1 CPU
</span>            <span class="n">memory_limit_mib</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="c1"># 4GB RAM
</span>        <span class="p">)</span>

        <span class="c1"># grant permissions
</span>        <span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">taskdef</span><span class="o">.</span><span class="n">task_role</span><span class="p">)</span>
        <span class="n">taskdef</span><span class="o">.</span><span class="n">add_to_task_role_policy</span><span class="p">(</span>
            <span class="n">iam</span><span class="o">.</span><span class="n">PolicyStatement</span><span class="p">(</span>
                <span class="n">effect</span><span class="o">=</span><span class="n">iam</span><span class="o">.</span><span class="n">Effect</span><span class="o">.</span><span class="n">ALLOW</span><span class="p">,</span>
                <span class="n">resources</span><span class="o">=</span><span class="p">[</span><span class="s">"*"</span><span class="p">],</span>
                <span class="n">actions</span><span class="o">=</span><span class="p">[</span><span class="s">"ssm:GetParameter"</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <i class="conum" data-value="5"></i><b>(5)</b>
        <span class="n">container</span> <span class="o">=</span> <span class="n">taskdef</span><span class="o">.</span><span class="n">add_container</span><span class="p">(</span>
            <span class="s">"EcsClusterQaBot-Container"</span><span class="p">,</span>
            <span class="n">image</span><span class="o">=</span><span class="n">ecs</span><span class="o">.</span><span class="n">ContainerImage</span><span class="o">.</span><span class="n">from_registry</span><span class="p">(</span>
                <span class="s">"tomomano/qabot:latest"</span>
            <span class="p">),</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here, we are preparing a database to write the results of the answers.
DynamoDB will be covered in the sections on the serverless architecture (<a href="#sec_serverless">Section 11</a> and <a href="#sec_intro_serverless">Section 12</a>), so don&#8217;t worry about it for now.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Here, we define a VPC, as we did in Hands-on #1 and #2.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Here, we define ECS clusters.
A cluster is a pool of virtual servers, and multiple virtual instances are placed in a cluster.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Here, we define the tasks to be executed (<strong>task definition</strong>).</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Here, we define the Docker image to be used for executing the task.</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_ecs_and_fargate">8.4.1. ECS and Fargate</h4>
<div class="paragraph">
<p>Let&#8217;s take a closer look at the code for ECS and Fargate.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre><span class="n">cluster</span> <span class="o">=</span> <span class="n">ecs</span><span class="o">.</span><span class="n">Cluster</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-Cluster"</span><span class="p">,</span>
    <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">taskdef</span> <span class="o">=</span> <span class="n">ecs</span><span class="o">.</span><span class="n">FargateTaskDefinition</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"EcsClusterQaBot-TaskDef"</span><span class="p">,</span>
    <span class="n">cpu</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="c1"># 1 CPU
</span>    <span class="n">memory_limit_mib</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="c1"># 4GB RAM
</span><span class="p">)</span>

<span class="n">container</span> <span class="o">=</span> <span class="n">taskdef</span><span class="o">.</span><span class="n">add_container</span><span class="p">(</span>
    <span class="s">"EcsClusterQaBot-Container"</span><span class="p">,</span>
    <span class="n">image</span><span class="o">=</span><span class="n">ecs</span><span class="o">.</span><span class="n">ContainerImage</span><span class="o">.</span><span class="n">from_registry</span><span class="p">(</span>
        <span class="s">"tomomano/qabot:latest"</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In the line starting with <code>cluster =</code>, a empty ECS cluster is created.
Then, <code>taskdef=ecs.FargateTaskDefinition</code> creates a new task definition.
Task definition specifies all necessary information to run the task, including the CPU and RAM size.
Here, we will use 1 CPU and 4GB RAM to execute the task.
Also, note that the task defined this way uses one instance per task.</p>
</div>
<div class="paragraph">
<p>Lastly, in the line starting with <code>container =</code>, we are supplying the link to the Docker image to the task definition.
Here, we specify to download an image called <code>tomomano/qabot</code> from Docker Hub.</p>
</div>
<div class="paragraph">
<p>With this just a few lines of code, we can create an ECS cluster which automatically executes the task scheduling and cluster scaling.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the above code, notice the line which says <code>cpu=1024</code>.
This number is called CPU units, to which a virtual CPU (vCPU) is assigned according to the conversion table (<a href="#tab:cpu_unit">Table 4</a>).
1024 CPU unit is equivalent to 1 CPU.
Numbers such as 0.25 and 0.5 vCPU mean that 1/4 and 1/2 of the CPU time is effectively allocated, respectively.
The amount of memory that can be used also depends on the CPU unit.
For example, if you select 1024 CPU units, you can only specify the amount of memory in the range of 2 to 8 GB.
For the latest information, see
<a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate.html">official documentation "Amazon ECS on AWS Fargate"</a>.</p>
</div>
<table id="tab:cpu_unit" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. CPUã€€unit conversion table</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU unit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Available memory size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">256 (.25 vCPU)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.5 GB, 1 GB, 2 GB</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">512 (.5 vCPU)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 GB, 2 GB, 3 GB, 4 GB</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024 (1 vCPU)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2 GB, 3 GB, 4 GB, 5 GB, 6 GB, 7 GB, 8 GB</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048 (2 vCPU)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Between 4 GB and 16 GB in 1-GB increments</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4096 (4 vCPU)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Between 8 GB and 30 GB in 1-GB increments</p></td>
</tr>
</tbody>
</table>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_deploying_the_application_2">8.5. Deploying the application</h3>
<div class="paragraph">
<p>Now that we understand the application source code, let&#8217;s deploy it.</p>
</div>
<div class="paragraph">
<p>The deployment procedure is almost the same as the previous hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>handson/qa-bot

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Deploy!</span>
<span class="nv">$ </span>cdk deploy</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the deployment is successful, you should see an output like <a href="#handson_03_cdk_output">Figure 46</a>.</p>
</div>
<div id="handson_03_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 46. Output of <code>cdk deploy</code></div>
</div>
<div class="paragraph">
<p>Let&#8217;s log in to the AWS console and check the contents of the deployed stack.
From the console, go to the ECS page, and you should see a screen like <a href="#handson_03_ecs_console">Figure 47</a>.
Find the cluster named <code>EcsClusterQaBot-XXXX</code>.</p>
</div>
<div class="paragraph">
<p>Cluster is a unit that binds multiple virtual instances together, as explained earlier.
In the <a href="#handson_03_ecs_console">Figure 47</a>, check that under the word FARGATE it says <code>0 Running tasks</code> and <code>0 Pending tasks</code>.
At this point, no tasks were submitted, so the numbers are all zero.</p>
</div>
<div id="handson_03_ecs_console" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ecs_console.png" alt="ecs_console" width="700">
</div>
<div class="title">Figure 47. ECS console</div>
</div>
<div class="paragraph">
<p>Next, find the item <code>Task Definitions</code> in the menu bar on the left of this screen, and click on it.
On the destination page, find the item <code>EcsClusterQaBotEcsClusterQaBotTaskDefXXXX</code> and open it.
Scroll down the page, and you will find the information shown in <a href="#handson_03_ecs_task_definition">Figure 48</a>.
You can check the amount of CPU and memory used, as well as the settings related to the execution of the Docker container.</p>
</div>
<div id="handson_03_ecs_task_definition" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ecs_task_definition.png" alt="task_definition" width="700">
</div>
<div class="title">Figure 48. Viewing the task definition</div>
</div>
</div>
<div class="sect2">
<h3 id="_executing_a_task">8.6. Executing a task</h3>
<div class="paragraph">
<p>Now, let&#8217;s submit a question to the cloud!</p>
</div>
<div class="paragraph">
<p>Submitting a task to ECS is rather complicated, so I prepared a program (<code>run_task.py</code>) to simplify the task submission.
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/qa-bot/run_task.py">handson/qa-bot/run_task.py</a>).</p>
</div>
<div class="paragraph">
<p>With the following command, you can submit a new question to the ECS cluster.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python run_task.py ask <span class="s2">"A giant peach was flowing in the river. She picked it up and brought it home. Later, a healthy baby was born from the peach. She named the baby Momotaro."</span> <span class="s2">"What is the name of the baby?"</span></code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In order to run <code>run_task.py</code>, make sure that your AWS credentials have been set on the command line.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Following "ask" parameter, we supply context and questsions, in this order, as the arguments.</p>
</div>
<div class="paragraph">
<p>When you run this command, you will see the output "Waiting for the task to finish&#8230;&#8203;", and you will have to wait for a while to get an answer.
During this time, ECS accepts the task, launches a new Fargate instance, and places the Docker image on the instance.
Let&#8217;s monitor this sequence of events from the AWS console.</p>
</div>
<div class="paragraph">
<p>Go back to the ECS console screen, and click on the name of the cluster (<code>EcsClusterQaBot-XXXX</code>).
Next, open the tab named "Tasks" (<a href="#ecs_task_monitoring">Figure 49</a>).
You will see a list of running tasks.</p>
</div>
<div id="ecs_task_monitoring" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ecs_task_monitoring.png" alt="ecs_task_monitoring" width="700">
</div>
<div class="title">Figure 49. Monitor the execution status of ECS tasks</div>
</div>
<div class="paragraph">
<p>As you can see in <a href="#ecs_task_monitoring">Figure 49</a>, the "Last status = Pending" indicates that the task is being prepared for execution at this point.
It takes about 1-2 minutes to launch the Fargate instance and deploy the Docker image.</p>
</div>
<div class="paragraph">
<p>After waiting for a while, the status will change to "RUNNING" and the computation will start.
When the computation is finished, the status changes to "STOPPED" and the Fargate instance is automatically shut down by ECS.</p>
</div>
<div class="paragraph">
<p>From the <a href="#ecs_task_monitoring">Figure 49</a> screen, click on the task ID in the "Task" column to open the task detail screen (<a href="#ecs_task_detail">Figure 50</a>).
The task information such as "Last status" and "Platform version" is displayed.
You can also view the execution log of the container by opening the "Logs" tab.</p>
</div>
<div id="ecs_task_detail" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ecs_task_detail.png" alt="ecs_task_detail" width="700">
</div>
<div class="title">Figure 50. ECS task detail</div>
</div>
<div class="paragraph">
<p>Now, coming back to the command line where you ran <code>run_task.py</code>, you should see an output like <a href="#ask_question_output">Figure 51</a>.
The correct answer, "Momotaro", has been returned!</p>
</div>
<div id="ask_question_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ask_question_output.png" alt="ask_question_output" width="700">
</div>
<div class="title">Figure 51. Answer returned by the bot</div>
</div>
</div>
<div class="sect2">
<h3 id="_executing_tasks_in_parallel">8.7. Executing tasks in parallel</h3>
<div class="paragraph">
<p>The application we have designed here can handle many questions at the same time by using ECS and Fargate.
Now, let&#8217;s submit many questions at once, and observe the behavior of ECS cluster.
By adding the option <code>ask_many</code> to <code>run_task.py</code>, you can send multiple questions at once.
The questions are defined in
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/qa-bot/problems.json">handson/qa-bot/problems.json</a>.</p>
</div>
<div class="paragraph">
<p>Run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python run_task.py ask_many</code></pre>
</div>
</div>
<div class="paragraph">
<p>After executing this command, go to the ECS console and look at the list of tasks (<a href="#ecs_many_tasks">Figure 52</a>).
You can see that multiple Fargate instances have been launched and tasks are being executed in parallel.</p>
</div>
<div id="ecs_many_tasks" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ecs_many_tasks.png" alt="ecs_many_tasks" width="700">
</div>
<div class="title">Figure 52. Submitting parallel tasks to ECS</div>
</div>
<div class="paragraph">
<p>Make sure that the status of all tasks is "STOPPED", and then get the answer to the question.
To do so, execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python run_task.py list_answers</code></pre>
</div>
</div>
<div class="paragraph">
<p>As a result, you will get an output like <a href="#ask_many_output">Figure 53</a>.
You can see that the bot was able to answer complex text questions with a suprisingly high accuracy.</p>
</div>
<div id="ask_many_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-03/ask_many_output.png" alt="ask_many_output" width="700">
</div>
<div class="title">Figure 53. Output of <code>$ python run_task.py list_answers</code></div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you keep submitting questions with <code>run_task.py</code>, more and more entries will accumulate in the database that records the answers.
To clear all these entries, use the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python run_task.py clear</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Congratulations!
You have managed to create a system that can automatically generate answers to questions using deep learning language models!
Importantly, it is a highly scalable system that can handle hundreds of questions simultaneously.
We didn&#8217;t prepare a GUI (Graphical User Interface) this time, but if we add a simple GUI to this system, it could be operated as a very nice web service.
We didn&#8217;t add GUI to this cloud system, but with such a tweaking, this system is already useful enough for various purposes.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deleting_the_stack_2">8.8. Deleting the stack</h3>
<div class="paragraph">
<p>This concludes the third hands-on session.
Finally, we must delete the stack.</p>
</div>
<div class="paragraph">
<p>To delete the stack, login to the AWS console and click the DELETE button on the CloudFormation screen.
Alternatively, you can execute the following command from the command line.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_aws_batch">9. Hands-on #4: Using AWS Batch to Parallelize Hyperparameter Search for Machine Learning</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the third hands-on session, we built an automatic question answering system using ECS and Fargate.
Despite its simplicity, we were able to build a system where jobs are executed in parallel when multiple questions are sent.
There, we built the application using a pre-tained language model.
Generally speaking, though, the first step in a machine learning workflow should be to train your own models.
Therefore, in the fourth hands-on session, we will consider parallelizing and accelerating the training of machine learning models using the cloud.</p>
</div>
<div class="paragraph">
<p>In particular, we will focus on hyperparameter optimization in deep learning.
Hyperparameters are parameters outside the weights of the neural network that are optimized by gradient descent, including those related to the architecture of the network such as the width and depth of the layers, and those related to the parameter optimization method such as the learning rate and momentum.
Tuning the hyperparameters is a very important task in deep learning.
However, it requires a lot of computation time because the neural network needs to be trained many times while changing the conditions little by little.
In research and development, exploring a large number of possible models is an important factor in determining productivity, and the problem of solving hyperparameter search quickly is of great interest.
In this hands-on, we will learn how to solve this problem by training neural networks in parallel using the powerful computing resources of the cloud.</p>
</div>
<div class="sect2">
<h3 id="_auto_scaling_groups_asg">9.1. Auto scaling groups (ASG)</h3>
<div class="paragraph">
<p>Before we get into the hands-on, you need to be familiar with the technique of EC2, called <strong>Auto scaling groups (ASG)</strong>.</p>
</div>
<div class="paragraph">
<p>Please take a look back at <a href="#ecs_overview">Figure 42</a>, which gives an overview of ECS.
As explained in the previous chapter (<a href="#sec_fargate_qabot">Section 8</a>), EC2 and Fargate can be selected as the computational resource in ECS clusters.
Fargate was described in the previous chapter.
Using Fargate, we were able to build a highly scalable computing environment with a simple setup.
However, there were some limitations, such as not being able to use GPUs.
By defining a computing environment that is based on EC2, although the programming complexity increases, we can build clusters with GPUs and other more advanced and complex configurations.</p>
</div>
<div class="paragraph">
<p>A service called <strong>ASG</strong> is deployed in an EC2 cluster.
An ASG constitutes a cluster by grouping multiple EC2 instances into logical units.
ASGs are responsible for scaling, such as launching new instances in the cluster or stopping instances that are no longer needed.
An important concept in ASG is the parameters callled <strong>desired capacity</strong>, <strong>minimum capacity</strong>, and <strong>maximum capacity</strong>.
The <strong>minimum capacity</strong> and <strong>maximum capacity</strong> are parameters that specify the minimum and maximum number of instances that can be placed in a cluster, respectively.
The former keeps the instances idle even when the cluster is not under load, so it can act as a buffer when the load suddenly increases.
The latter prevents an excessive number of instances from being launched when the load increases unexpectedly, and serves to set an upper limit on the economic cost.</p>
</div>
<div class="paragraph">
<p>The desired capacity specifies the number of instances required by the system at a given time.
The desired capacity can be set based on a fixed schedule, such as increasing or decreasing the number of instances according to a 24-hour rhythm (e.g., more during the day and less at night).
Alternatively, the desired capacity can be dynamically controlled according to the load on the entire cluster.
The rules that define the criteria for scaling the cluster are called <strong>scaling policies</strong>.
For example, we can assume a scaling policy which maintains the utilization (load) of the entire cluster at 80% at all times.
In this case, the ASG automatically removes instances from the cluster when the load of the entire cluster falls below 80%, and adds instances when the load exceeds 80%s.</p>
</div>
<div class="paragraph">
<p>After considering the above parameters, the user creates an ASG.
Once ASG is created, one needs to write a program to link ASG with the ECS, which defines EC2-based ECS cluster.</p>
</div>
</div>
<div class="sect2">
<h3 id="_aws_batch">9.2. AWS Batch</h3>
<div class="imageblock">
<div class="content">
<img src="imgs/aws_logos/Batch.png" alt="Batch" width="100">
</div>
<div class="title">Figure 54. AWS Batch icon</div>
</div>
<div class="paragraph">
<p>As explained earlier, it is possible to construct a desired computation cluster by combining ECS and ASG.
However, ECS and ASG require complicated settings, which makes programming quite tedious for both beginners and experienced users.
To solve this problem, there is a service that automates the design of clusters using ECS and ASG.
That service is <strong>AWS Batch</strong>.</p>
</div>
<div class="paragraph">
<p>AWS Batch, as the name implies, is designed for batch jobs (i.e., independent operations with different input data that are executed repeatedly).
Many scientific calculations and machine learning can be considered as batch calculations.
For example, you can run multiple simulations with different initial parameters.
The advantage of using AWS Batch is that the scaling of the cluster and the allocation of jobs are all done automatically, giving the users a system where they can submit a large number of jobs without worrying about the implementation details of the cloud.
However, it is important to know that the ECS/ASG/EC2 triad is working in concert behind the scenes.</p>
</div>
<div class="paragraph">
<p>In AWS Batch, the following concept is defined to facilitate job submission and management (<a href="#fig_batch_concept">Figure 55</a>).
First, a <strong>job</strong> is a unit of computation executed by AWS Batch.
<strong>Job definitions</strong> define the specification of a job, including the address of the Docker image to be executed, the amount of CPU and RAM to be allocated, and environment variables.
Each job is executed based on the job definition.
When a job is executed, it is placed in <strong>job queues</strong>.
Job queue is a queue of jobs waiting to be executed, and the first job in the queue is executed first.
In addition, multiple queues can be arranged, and each queue can be assigned a priority value, so that jobs in the queue with the highest priority are executed first.
<strong>Compute environment</strong> is a concept that is almost synonymous with the cluster, and refers to the location where computations are executed (i.e. group of EC2 or Fargate instances).
In the compute environment, one needs to specify the EC2 instance types to use, and a simple scaling policy, such as the upper and lower limit on the number of instances.
Job queues monitor the availability of the compute environment and place jobs to the compute environment according to the availability.</p>
</div>
<div class="paragraph">
<p>These are the concepts that you need to understand when using AWS Batch.
To make a better sense of these concepts, let us actually construct an application using AWS Batch.</p>
</div>
<div id="fig_batch_concept" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_concepts.png" alt="batch concepts" width="700">
</div>
<div class="title">Figure 55. AWS Batch concepts</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>EC2 or Fargate?</strong></p>
</div>
<div class="paragraph">
<p>When configuring a cluster in ECS, we explained that there are two options for performing calculations: EC2 and Fargate.
Each has its own advantages and disadvantages, but which one should be used in which case?
To examine this, let&#8217;s first look at <a href="#tab:ec2_vs_fargate">Table 5</a>.
This is a summary of the characteristics of EC2 and Fargate.
Please note that it is heavily coarse-grained for the sake of explanation.</p>
</div>
<table id="tab:ec2_vs_fargate" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. EC2 vs Fargate</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"></th>
<th class="tableblock halign-left valign-top">EC2</th>
<th class="tableblock halign-left valign-top">Fargate</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Compute capacity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Medium to large</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Small to medium</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPU</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Launch speed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fast</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Task placement flexibility</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Low</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">High</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Programming complexity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">High</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Low</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>As we have seen so far, EC2 has high computing power in a single instance, with a large maximum number of CPUs and memory size, and the ability to use GPUs.
In contrast, the maximum number of CPUs for a single instance of Fargate is capped at four cores.
On the other hand, the time required to launch an instance is much faster in Fargate, which allows for more agile scaling of the cluster.
Fargate also has higher flexibility when submitting tasks to the cluster.
Flexibility refers to the situation where, for example, two or more containers can be run on a single instance.
Such a design is often used to maximize the number of tasks per unit CPU.
In terms of programming complexity, Fargate is generally simpler to implement.</p>
</div>
<div class="paragraph">
<p>As described above, EC2 and Fargate have complementary characteristics, and the optimal computing environment must be considered carefully depending on the use cases.
It is also possible to define a hybrid cluster that uses both EC2 and Fargate, and such an option is often used.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_preparations_2">9.3. Preparations</h3>
<div class="paragraph">
<p>The hands-on source code is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/aws-batch">handson/aws-batch</a>.</p>
</div>
<div class="paragraph">
<p>To run this hands-on, it is assumed that the preparations described in the first hands-on (<a href="#handson_01_prep">Section 4.1</a>) have been completed.
It is also assumed that Docker is already installed on your local machine.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Since this hands-on uses <code>g4dn.xlarge</code> EC2 instance, it will cost 0.526 $/hour in Virginia (<code>us-east-1</code>) region.
If you choose Tokyo (<code>ap-northeast-1</code>), the cost will be 0.71 $/hour.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>As noted in <a href="#sec:jupyter_and_deep_learning_setup">Section 6.1</a>, before starting this hands-on, check the launch limit of G-type instances from the EC2 dashboard of the AWS console.
If the limit is 0, you need to apply for increase of the limit.
Also refer to <a href="#sec:aws_batch_code">Section 9.5</a> for related information.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="sec_run_mnist_docker_local">9.4. Revisiting MNIST handwritten digit recognition task</h3>
<div class="paragraph">
<p>At the beginning of this hands-on, we mentioned that we would be covering hyperparameter tuning in machine learning.
As the simplest example, let&#8217;s take the MNIST digit recognition problem again, which was covered in <a href="#sec_mnist_using_jupyter">Section 6.7</a>.
In <a href="#sec_mnist_using_jupyter">Section 6.7</a>, we trained the model using arbitrarily chosen hyperparameters.
The hyperparameters used in the program include learning rate and momentum in stochastic gradient descent (SGD) algorithm.
In the code, the following lines correspond to them.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The learning rate (<code>lr=0.01</code>) and momentum (<code>momentum=0.5</code>) used here are arbitrarily chosen values, and we do not know if these are the best values.
This choice may happen to be the best, or there may be other hyperparameter pairs that give higher accuracy.
To answer this question, let&#8217;s perform a hyperparameter search.
In this article, we will take the simplest approach: hyperparameter search by <strong>grid search</strong>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">On the hyperparameter tuning</div>
<div class="paragraph">
<p>There are mainly three approaches to optimize hyperparameters in machine learning.
These are grid search, random search, and Bayesian optimization.</p>
</div>
<div class="paragraph">
<p>Grid search is a method to find the optimal set of parameters by computing all possible combinations of hyperparameters within a certain range.
It is the simplest and most reliable method, but the computational cost is high because all possible combinations are tested.</p>
</div>
<div class="paragraph">
<p>The random search method is a method that randomly extracts pairs of hyperparameters within a certain range, and finds the optimal pair of parameters among a large number of random pairs that have been tested.
Although it does not exhaustively search all possibilities, it can cover a large search space more efficiently than grid search when there are a large number of parameters to be adjusted.</p>
</div>
<div class="paragraph">
<p>In the method using Bayesian optimization, the parameters to be searched next are determined by calculating an index based on past search results.
The index essentially points the most uncertain and promising area within the parameter space.
This method can theoretically reach the optimal parameters in a smaller number of trials than the grid search or random search methods.</p>
</div>
<div class="paragraph">
<p>In terms of parallelization, grid search and random search can be easily parallelized because the computation of each hyperparameter pair can be performed independently.
Such problems that can be divided and parallelized as independent jobs are called embarrassingly parallel problems.
Embarrassingly parallel problems can be solved with a very simple implementation by using the powerful computing resources of the cloud.
In this chapter, we will focus on this type of parallel computation.</p>
</div>
<div class="paragraph">
<p>On the other hand, Bayesian optimization methods are not so simple to parallelize because the next search is determined based on past results.
Recently, libraries for hyperparameter search, such as <a href="https://optuna.org/">optuna</a>, have been developed, and they are useful because they automatically perform the mathematical process of Bayesian optimization.
Using these libraries, if there are multiple GPUs in a single computer (node), the computations can be performed in parallel.
However, parallelization across multiple nodes not only requires advanced programming techniques, but is also heavily dependent on the architecture of the cloud, such as the network connection between nodes.
In this book, we will not go into the usage of cloud computing at this level of sophistication.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>First, let&#8217;s run the Docker image used in this hands-on session locally.</p>
</div>
<div class="paragraph">
<p>The source code of the Docker image can be found on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/aws-batch/docker">handson/aws-batch/docker</a>.
It is based on the program we introduced in <a href="#sec_mnist_using_jupyter">Section 6.7</a>, with some minor changes made for this handson.
Interested readers are encouraged to read the source code as well.</p>
</div>
<div class="paragraph">
<p>As an exercise, let&#8217;s start by building this Docker image on your local machine.
Go to the directory where the <code>Dockerfile</code> is stored, and build the image with the tag <code>mymnist</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">cd </span>handson/aws-batch/docker
<span class="nv">$ </span>docker build <span class="nt">-t</span> mymnist .</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you get an error with <code>docker build</code> command, please suspect the following possibility.
In the build process, the MNIST image dataset is downloaded from <a href="http://yann.lecun.com/exdb/mnist/" class="bare">http://yann.lecun.com/exdb/mnist/</a>, and this server is sometimes down due to the heavy access from machine learning users across the world.
When the server is down, the build also fails.
If you see something like this in the error message, suspect this possibility.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Instead of building the image yourself, you can pull it from Docker Hub.
In this case, execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker pull tomomano/mymnist:latest</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When the image is ready, start the container with the following command and run MNIST training.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run mymnist <span class="nt">--lr</span> 0.1 <span class="nt">--momentum</span> 0.5 <span class="nt">--epochs</span> 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will start optimizing the neural network using the specified hyperparameters (learning rate given by <code>--lr</code> and momentum given by <code>--momentum</code>).
The maximum number of epochs to train is specified by <code>--epochs</code> parameter.
You will see decrease of loss values on the command line, just as we saw in <a href="#sec_jupyter_and_deep_learning">Section 6</a> (<a href="#fig_mnist_log_output">Figure 56</a>).</p>
</div>
<div id="fig_mnist_log_output" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/mnist_log_output.png" alt="mnist log" width="600">
</div>
<div class="title">Figure 56. Output of Docker container</div>
</div>
<div class="paragraph">
<p>If you use the above command, the computation will be performed using the CPU.
If your local computer is equipped with a GPU and you have configured <a href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>, you can use the following command to run the computation using the GPU.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">--gpus</span> all mymnist <span class="nt">--lr</span> 0.1 <span class="nt">--momentum</span> 0.5 <span class="nt">--epochs</span> 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this command, the parameter <code>--gpus all</code> has been added.</p>
</div>
<div class="paragraph">
<p>You can see that the loss of the training data monotonically decreases as the number of epochs increases, regardless of whether it is run on CPU or GPU.
On the other hand, you will notice that <strong>loss and accuracy of the validation data do not improve further</strong> after decreasing to a certain level.
The actual plot of this behaviour should look like <a href="#fig_loss_epoch_profile">Figure 57</a>.</p>
</div>
<div id="fig_loss_epoch_profile" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/loss_epoch_profile.png" alt="loss epochs" width="600">
</div>
<div class="title">Figure 57. (Left) Change in loss for each epoch of train and validation data. (Right) Epoch-by-epoch change in accuracy of validation data.</div>
</div>
<div class="paragraph">
<p>This is a phenomenon called <strong>overfitting</strong>, which indicates that the neural network is over-fitted to the training data and the accuracy (generalization performance) for data outside the training data is not improved.
To deal with such cases, a technique called <strong>early stopping</strong> is known.
In early stopping, we track the loss of the validation data, and stop learning at the epoch when it turns from decreasing to increasing.
Then we adopt the weight parameters at that epoch.
In this hands-on session, we will use early stopping technique to determine the end of training and evaluate the performance of the model.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the MNIST handwriting dataset, 60,000 images are given as training data and 10,000 images as test data.
In the code used in this hands-on session, 48,000 images (80% of the training data) are used as training data, and the remaining 12,000 images are used as validation data.
For details, please refer to the source code.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="sec:aws_batch_code">9.5. Reading the application source code</h3>
<div class="paragraph">
<p><a href="#fig_batch_architecture">Figure 58</a> shows an overview of the application we are creating in this hands-on.</p>
</div>
<div id="fig_batch_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/architecture.png" alt="architecture" width="600">
</div>
<div class="title">Figure 58. Application architecture</div>
</div>
<div class="paragraph">
<p>The summary of the system design is as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client submits a job to AWS Batch with a given set of hyperparameters.</p>
</li>
<li>
<p>When Batch receives the job, it performs the computation on a cluster consisting of EC2</p>
</li>
<li>
<p>A <code>g4dn.xlarge</code> instance is launched in the cluster.</p>
</li>
<li>
<p>Docker images are retrieved from the Elastic Container Registry (ECR) in AWS.</p>
</li>
<li>
<p>When multiple jobs are submitted, enough number of instances are launched and jobs are executed in parallel.</p>
</li>
<li>
<p>The results of the computation by each job are stored in S3.</p>
</li>
<li>
<p>Finally, the client downloads the results from S3 and decides the best set of hyperparameters.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Let us take a look at the application source code
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/aws-batch/app.py">handson/aws-batch/app.py</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">SimpleBatch</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <i class="conum" data-value="1"></i><b>(1)</b>
        <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"bucket"</span><span class="p">,</span>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span><span class="p">,</span>
            <span class="n">auto_delete_objects</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">vpc</span> <span class="o">=</span> <span class="n">ec2</span><span class="o">.</span><span class="n">Vpc</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"vpc"</span><span class="p">,</span>
            <span class="c1"># other parameters...
</span>        <span class="p">)</span>

        <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="n">managed_env</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">ComputeEnvironment</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"managed-env"</span><span class="p">,</span>
            <span class="n">compute_resources</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">ComputeResources</span><span class="p">(</span>
                <span class="n">vpc</span><span class="o">=</span><span class="n">vpc</span><span class="p">,</span>
                <span class="n">allocation_strategy</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">AllocationStrategy</span><span class="o">.</span><span class="n">BEST_FIT</span><span class="p">,</span>
                <span class="n">desiredv_cpus</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">maxv_cpus</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="n">minv_cpus</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">instance_types</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">ec2</span><span class="o">.</span><span class="n">InstanceType</span><span class="p">(</span><span class="s">"g4dn.xlarge"</span><span class="p">)</span>
                <span class="p">],</span>
            <span class="p">),</span>
            <span class="n">managed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">compute_environment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_name</span> <span class="o">+</span> <span class="s">"compute-env"</span>
        <span class="p">)</span>

        <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="n">job_queue</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">JobQueue</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"job-queue"</span><span class="p">,</span>
            <span class="n">compute_environments</span><span class="o">=</span><span class="p">[</span>
                <span class="n">batch</span><span class="o">.</span><span class="n">JobQueueComputeEnvironment</span><span class="p">(</span>
                    <span class="n">compute_environment</span><span class="o">=</span><span class="n">managed_env</span><span class="p">,</span>
                    <span class="n">order</span><span class="o">=</span><span class="mi">100</span>
                <span class="p">)</span>
            <span class="p">],</span>
            <span class="n">job_queue_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_name</span> <span class="o">+</span> <span class="s">"job-queue"</span>
        <span class="p">)</span>

        <i class="conum" data-value="4"></i><b>(4)</b>
        <span class="n">job_role</span> <span class="o">=</span> <span class="n">iam</span><span class="o">.</span><span class="n">Role</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"job-role"</span><span class="p">,</span>
            <span class="n">assumed_by</span><span class="o">=</span><span class="n">iam</span><span class="o">.</span><span class="n">CompositePrincipal</span><span class="p">(</span>
                <span class="n">iam</span><span class="o">.</span><span class="n">ServicePrincipal</span><span class="p">(</span><span class="s">"ecs-tasks.amazonaws.com"</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># allow read and write access to S3 bucket
</span>        <span class="n">bucket</span><span class="o">.</span><span class="n">grant_read_write</span><span class="p">(</span><span class="n">job_role</span><span class="p">)</span>

        <i class="conum" data-value="5"></i><b>(5)</b>
        <span class="n">repo</span> <span class="o">=</span> <span class="n">ecr</span><span class="o">.</span><span class="n">Repository</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"repository"</span><span class="p">,</span>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span><span class="p">,</span>
        <span class="p">)</span>

        <i class="conum" data-value="6"></i><b>(6)</b>
        <span class="n">job_def</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">JobDefinition</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"job-definition"</span><span class="p">,</span>
            <span class="n">container</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">JobDefinitionContainer</span><span class="p">(</span>
                <span class="n">image</span><span class="o">=</span><span class="n">ecs</span><span class="o">.</span><span class="n">ContainerImage</span><span class="o">.</span><span class="n">from_ecr_repository</span><span class="p">(</span><span class="n">repo</span><span class="p">),</span>
                <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s">"python3"</span><span class="p">,</span> <span class="s">"main.py"</span><span class="p">],</span>
                <span class="n">vcpus</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                <span class="n">gpu_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">memory_limit_mib</span><span class="o">=</span><span class="mi">12000</span><span class="p">,</span>
                <span class="n">job_role</span><span class="o">=</span><span class="n">job_role</span><span class="p">,</span>
                <span class="n">environment</span><span class="o">=</span><span class="p">{</span>
                    <span class="s">"BUCKET_NAME"</span><span class="p">:</span> <span class="n">bucket</span><span class="o">.</span><span class="n">bucket_name</span>
                <span class="p">}</span>
            <span class="p">),</span>
            <span class="n">job_definition_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_name</span> <span class="o">+</span> <span class="s">"job-definition"</span><span class="p">,</span>
            <span class="n">timeout</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">Duration</span><span class="o">.</span><span class="n">hours</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here, we prepare an S3 bucket to store the results of the jobs.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Here, we define the compute environment.
The <code>g4dn.xlarge</code> instance is used, and the maximum number of vCPU usage is specified as 64.
The minimum vCPU is 0.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>This part defines the job queue associated with the compute environment created in &lt;2&gt;.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Here we define the IAM role so that the job can write results to S3
(IAM is a mechanism to manage the permissions of resources. See <a href="#sec:bashoutter_iam">Section 13.2.5</a> for details).</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>This line defines the ECR for deploying the Docker image.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Here we create the job definition.
In the code, we specify each job to consume 4 vCPU and 12000 MB (=12GB).
It also sets the environment variables (<code>BUCKET_NAME</code>) that will be used by the Docker container.
In addition, the IAM created in &lt;4&gt; has been attatched.</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Each <code>g4dn.xlarge</code> instance is allocated 4 vCPUs.
In the above code, the maximum vCPUs of the compute environment is set to 64, which means that a maximum of 16 instances can be launched simultaneously.
The reason for limiting the maximum vCPUs to 64 is to avoid incurring high AWS usage fees in the event that a large number of unintended jobs are submitted to the cluster due to some mistake.
You can set the number of maximum vCPUs larger than 64 at your own risk if you judge that it is necessary for your application.</p>
</div>
<div class="paragraph">
<p>There is one point to note here.
AWS sets an upper limit for the number of instances that can be launched in EC2 for each account.
You can check this limit by logging into the AWS console and clicking <code>Limits</code> on the left side menu bar of the EC2 console (<a href="#fig_ec2_limits">Figure 59</a>).
To check the limits for <code>g4dn.xlarge</code> (which belongs to the G family in the EC2 classification), look at the item named <code>Running On-Demand All G instances</code>.
The number here is the account limit imposed by AWS, and you cannot run instances that exceed this limit.
If the limit is too low for your purpose, you can request to increase the limit.
For more information, please refer to <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html">Official documentation "Amazon EC2 service quotas"</a>.</p>
</div>
<div id="fig_ec2_limits" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/ec2_limits.png" alt="EC2 limits" width="700">
</div>
<div class="title">Figure 59. Checking the limits from EC2 console</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_deploying_the_stack">9.6. Deploying the stack</h3>
<div class="paragraph">
<p>Now that we understand the application source code, let&#8217;s deploy it.</p>
</div>
<div class="paragraph">
<p>The deployment procedure is almost the same as the previous hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>handson/aws-batch

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Deploy!</span>
<span class="nv">$ </span>cdk deploy</code></pre>
</div>
</div>
<div class="paragraph">
<p>After confirming that the deployment has been done successfully, let&#8217;s log in to the AWS console and check the deployed stack.
Type <code>batch</code> in the search bar to open the AWS Batch management console (<a href="#fig_batch_console">Figure 60</a>).</p>
</div>
<div id="fig_batch_console" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_console.png" alt="batch console" width="700">
</div>
<div class="title">Figure 60. AWS Batch management console</div>
</div>
<div class="paragraph">
<p>The first thing you should look at is the item named <code>SimpleBatchcompute-env</code> in the "compute environment overview" at the bottom of the screen.
Compute environment is the environment (or cluster) in which computations will be executed, as described earlier.
As specified in the program, <code>g4dn.xlarge</code> is shown as the instance type to be used.
You can also see that <code>Minimum vCPUs</code> is set to 0 and <code>Maximum vCPUs</code> is set to 64.
In addition, <code>Desired vCPUs</code> is set to 0 because no job is running at this time.
If you want to see more detailed information about the compute environment, click on the name to open the detail screen.</p>
</div>
<div class="paragraph">
<p>Next, pay attention to the item <code>SimpleBatch-queue</code> in the "job queue overview".
Here, you can see a list of jobs waiting for execution, jobs in progress, and jobs that have completed execution.
You can see that there are columns such as <code>PENDING</code>, <code>RUNNING</code>, <code>SUCCEEDED</code>, <code>FAILED</code> and so on.
As the job progresses, the state of the job transitions according to these columns.
We&#8217;ll come back to this later when we actually submit the job.</p>
</div>
<div class="paragraph">
<p>Finally, let&#8217;s check the job definition.
Select <code>Job definitions</code> from the menu on the left side of the screen, and find and open the <code>SimpleBatchjob-definition</code> on the next screen.
From here, you can see the details of the job definition (<a href="#fig:batch_job_definition">Figure 61</a>).
Among the most important information, <code>vCPUs</code>, <code>Memory</code>, and <code>CPU</code> define the amount of vCPU, memory, and GPU allocated to Docker, respectively.
In addition, <code>Image</code> specifies the Docker image to be used for the job.
Here, it refers to the ECR repository.
Currently, this ECR is empty.
The next step is to deploy the image to this ECR.</p>
</div>
<div id="fig:batch_job_definition" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_job_definition.png" alt="batch_job_definition" width="700">
</div>
<div class="title">Figure 61. Viewing the job definition from AWS Batch console</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:aws_batch_deploy_docker_on_ecr">9.7. Deploying Docker image on ECR</h3>
<div class="paragraph">
<p>In order for Batch to execute a job, it needs to download (pull) a Docker image from a specified location.
In the previous hands-on (<a href="#sec_fargate_qabot">Section 8</a>), we pulled the image from Docker Hub, which is set to public.
In this hands-on, we will adopt the design of deploying images in <strong>ECR (Elastic Container Registry)</strong>, a image registry provided by AWS.
The advantage of using ECR is that you can prepare a private space for images that only you can access.
Batch executes its tasks by pulling images from the ECR (<a href="#fig_batch_architecture">Figure 58</a>).</p>
</div>
<div class="paragraph">
<p>In the source code, the following part defines the ECR.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><i class="conum" data-value="1"></i><b>(1)</b>
<span class="n">repo</span> <span class="o">=</span> <span class="n">ecr</span><span class="o">.</span><span class="n">Repository</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"repository"</span><span class="p">,</span>
    <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">job_def</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">JobDefinition</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"job-definition"</span><span class="p">,</span>
    <span class="n">container</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">JobDefinitionContainer</span><span class="p">(</span>
        <span class="n">image</span><span class="o">=</span><span class="n">ecs</span><span class="o">.</span><span class="n">ContainerImage</span><span class="o">.</span><span class="n">from_ecr_repository</span><span class="p">(</span><span class="n">repo</span><span class="p">),</span> <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="o">...</span>
    <span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>This creates a new ECR.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>In the job definition, we specify that the image should be retrieved from the ECR created in &lt;1&gt;.
At the same time, the job definition is automatically granted access rights to the ECR through IAM.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After the first deployment, the ECR is empty.
You need to push the Docker image that you use for your application to ECR.</p>
</div>
<div class="paragraph">
<p>To do so, first open the ECR screen from the AWS console (type <code>Elastic Container Registry</code> in the search bar).
Select the <code>Private</code> tab and you will find a repository named <code>simplebatch-repositoryXXXX</code> (<a href="#fig_ecr_console1">Figure 62</a>).</p>
</div>
<div id="fig_ecr_console1" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/ecr_console1.png" alt="ecr console" width="700">
</div>
<div class="title">Figure 62. ECR console</div>
</div>
<div class="paragraph">
<p>Next, click on the name of the repository to go to the repository details page.
Then, click the <code>View push commands</code> button on the upper right corner of the screen.
This will bring up a pop-up window like <a href="#fig_ecr_push_command">Figure 63</a>.</p>
</div>
<div id="fig_ecr_push_command" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/ecr_push_command.png" alt="ecr push command" width="700">
</div>
<div class="title">Figure 63. Command to push images to ECR</div>
</div>
<div class="paragraph">
<p>You can push your Docker image to ECR by executing the four commands shown in this pop-up window in order.
<strong>Before pushing, make sure your AWS credentials are set</strong>.
Then, navigate to the directory <strong>named <code>docker/</code> in the hands-on source code</strong>.
Then, execute the commands displayed in the pop-up window in order from the top.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you look at the second command that pops up, you will see <code>docker build -t XXXXX .</code>.
The last <code>.</code> is important, because it means <em>build the image using the Dockerfile in the current directory</em>.
For this reason, you need to move to the directory where the <code>Dockerfile</code> is located.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The fourth command may take a few minutes as it uploads several gigabytes of images to ECR, but when it completes, the image has been successfully placed in ECR.
If you look at the ECR console again, you can see that the image has indeed been placed (<a href="#fig_ecr_console2">Figure 64</a>).
This completes the final preparations for executing a job using AWS Batch.</p>
</div>
<div id="fig_ecr_console2" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/ecr_console2.png" alt="ecr console 2" width="700">
</div>
<div class="title">Figure 64. Docker image has been placed in ECR</div>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_a_single_job">9.8. Submitting a single job</h3>
<div class="paragraph">
<p>Now, we demonstrate how to submit a job to AWS Batch.</p>
</div>
<div class="paragraph">
<p>In the <code>notebook/</code> directory of the hands-on source code, there is a file named
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/aws-batch/notebook/run_single.ipynb">run_single.ipynb</a>
(<code>.ipynb</code> is the file extension of Jupyter notebook).
We will open this file from Jupyter notebook.</p>
</div>
<div class="paragraph">
<p>In this hands-on, Jupyter Notebook server is already installed in the virtual environment by <code>venv</code>.
We can launch Jupyter Notebook server from the local machine by the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># Make sure that you are in a virtual environment</span>
<span class="o">(</span>.env<span class="o">)</span> <span class="nv">$ </span><span class="nb">cd </span>notebook
<span class="o">(</span>.env<span class="o">)</span> <span class="nv">$ </span>jupyter notebook</code></pre>
</div>
</div>
<div class="paragraph">
<p>After Jupyter Notebook server is started, open <code>run_single.ipynb</code>.</p>
</div>
<div class="paragraph">
<p>The first cell [1], [2], [3] defines a function to submit a job to AWS Batch (<code>submit_job()</code>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre></td><td class="code"><pre><span class="c1"># [1]
</span><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="c1"># [2]
# AWS èªè¨¼ãƒ˜ãƒ«ãƒ‘ãƒ¼ ...çœç•¥...
</span>
<span class="c1"># [3]
</span><span class="k">def</span> <span class="nf">submit_job</span><span class="p">(</span><span class="n">lr</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">momentum</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">profile_name</span><span class="o">=</span><span class="s">"default"</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">profile_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">profile_name</span><span class="o">=</span><span class="n">profile_name</span><span class="p">)</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s">"batch"</span><span class="p">)</span>

    <span class="n">title</span> <span class="o">=</span> <span class="s">"lr"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"."</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span> <span class="o">+</span> <span class="s">"_m"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">momentum</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"."</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit_job</span><span class="p">(</span>
        <span class="n">jobName</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
        <span class="n">jobQueue</span><span class="o">=</span><span class="s">"SimpleBatchjob-queue"</span><span class="p">,</span>
        <span class="n">jobDefinition</span><span class="o">=</span><span class="s">"SimpleBatchjob-definition"</span><span class="p">,</span>
        <span class="n">containerOverrides</span><span class="o">=</span><span class="p">{</span>
            <span class="s">"command"</span><span class="p">:</span> <span class="p">[</span><span class="s">"--lr"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">lr</span><span class="p">),</span>
                        <span class="s">"--momentum"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">momentum</span><span class="p">),</span>
                        <span class="s">"--epochs"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span>
                        <span class="s">"--uploadS3"</span><span class="p">,</span> <span class="s">"true"</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Job submitted!"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"job name"</span><span class="p">,</span> <span class="n">resp</span><span class="p">[</span><span class="s">"jobName"</span><span class="p">],</span> <span class="s">"job ID"</span><span class="p">,</span> <span class="n">resp</span><span class="p">[</span><span class="s">"jobId"</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Let us briefly explain the <code>submit_job()</code> function.
In <a href="#sec_run_mnist_docker_local">Section 9.4</a>, when we ran the MNIST Docker container locally, we used the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">-it</span> mymnist <span class="nt">--lr</span> 0.1 <span class="nt">--momentum</span> 0.5 <span class="nt">--epochs</span> 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here, <code>--lr 0.1 --momentum 0.5 --epochs 10</code> is the argument passed to the container.</p>
</div>
<div class="paragraph">
<p>When you run a job with AWS Batch, you can also specify the command to be passed to the container by using the argument <code>ContainerOverrides</code> within <code>commands</code> parameter.
The following part of the code corresponds to this.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="n">containerOverrides</span><span class="o">=</span><span class="p">{</span>
    <span class="s">"command"</span><span class="p">:</span> <span class="p">[</span><span class="s">"--lr"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">lr</span><span class="p">),</span>
                <span class="s">"--momentum"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">momentum</span><span class="p">),</span>
                <span class="s">"--epochs"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span>
                <span class="s">"--uploadS3"</span><span class="p">,</span> <span class="s">"true"</span><span class="p">]</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s move to cell [4].
Here, we submit a job with learning rate = 0.01, momentum = 0.1, and epochs = 100 using the <code>submit_job()</code> function.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="c1"># [4]
</span><span class="n">submit_job</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span></code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The AWS credentials need to be redefined from within the Jupyter Notebook.
To help with this, we have prepared cell [2] of the notebook (which is all commented out by default).
To use it, simply uncomment it.
When you run this cell, you will be prompted to enter your AWS credentials interactively.
By following the prompts and entering the aws secret key, the AWS credentials will be recorded in the environment variables (specific to the Jupyter session).</p>
</div>
<div class="paragraph">
<p>As another authentication method, the <code>profile_name</code> parameter is provided to the <code>submit_job()</code> function.
If your credentials are stored in <code>~/.aws/credentials</code> (see <a href="#aws_cli_install">Section 14.3</a> for details), you can authenticate by simply passing the name of the profile you want to use to <code>profile_name</code>.
Familiar readers may find the latter approach more convenient.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After executing the cell [4], let&#8217;s check whether the job is actually submitted from the AWS console.
If you open the AWS Batch management console, you will see a screen like <a href="#fig_batch_running_job">Figure 65</a>.</p>
</div>
<div id="fig_batch_running_job" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_running_job.png" alt="batch running job" width="700">
</div>
<div class="title">Figure 65. Monitoring the jobs in AWS Batch console</div>
</div>
<div class="paragraph">
<p>Pay attention to the part circled in red in <a href="#fig_batch_running_job">Figure 65</a>.
When a job is submitted, it goes through the state of <code>SUBMITTED</code> and then to the state of <code>RUNNABLE</code>.
<code>RUNNABLE</code> corresponds to the state of waiting for a new instance to be launched because there is not available instances in the compute environment to run the job.
When the instance is ready, the status of the job goes through <code>STARTING</code> to <code>RUNNING</code>.</p>
</div>
<div class="paragraph">
<p>Next, let&#8217;s look at the <code>Desired vCPU</code> of the compute environment when the status of the job is <code>RUNNING</code> (the part circled in purple in <a href="#fig_batch_running_job">Figure 65</a>).
The number 4 is the number of vCPU for one instance of <code>g4dn.xlarge</code>.
You can see that the minimum number of EC2 instances required to run the job has been launched in response to the job submission.
(If you are interested, you can also take a look at the EC2 console at the same time).</p>
</div>
<div class="paragraph">
<p>After a while, the status of the job will change from <code>RUNNING</code> to <code>SUCCEEDED</code> (or <code>FAILED</code> if an error occurs for some reason).
The training of MNIST used in this hands-on should take about 10 minutes.
Let&#8217;s wait until the job status becomes <code>SUCCEEDED</code>.</p>
</div>
<div class="paragraph">
<p>When the job completes, the training results (a CSV file containing the loss and accuracy for each epoch) will be saved in S3.
You can check this from the AWS console.</p>
</div>
<div class="paragraph">
<p>If you go to the S3 console, you should find a bucket named <code>simplebatch-bucketXXXX</code> (the XXXX part depends on the user).
If you click on it and look at the contents, you will find a CSV file named <code>metrics_lr0.0100_m0.1000.csv</code> (<a href="#fig_s3_saved_file">Figure 66</a>).
This is the result of training with learning rate = 0.01 and momentum = 0.1.</p>
</div>
<div id="fig_s3_saved_file" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/s3_saved_file.png" alt="s3 saved file" width="700">
</div>
<div class="title">Figure 66. Viewing the job output saved in S3</div>
</div>
<div class="paragraph">
<p>Now, let&#8217;s come back to <code>run_single.ipynb</code>.
In cells [5] through [7], we are downloading the CSV file of the training results.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="code"><pre><span class="c1"># [5]
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># [6]
</span><span class="k">def</span> <span class="nf">read_table_from_s3</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">profile_name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">profile_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">profile_name</span><span class="o">=</span><span class="n">profile_name</span><span class="p">)</span>
    <span class="n">s3</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">"s3"</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">bucket</span><span class="o">.</span><span class="n">Object</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"Body"</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># [7]
</span><span class="n">bucket_name</span> <span class="o">=</span> <span class="s">"simplebatch-bucket43879c71-mbqaltx441fu"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">read_table_from_s3</span><span class="p">(</span>
    <span class="n">bucket_name</span><span class="p">,</span>
    <span class="s">"metrics_lr0.0100_m0.1000.csv"</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In [6], we define a function to download CSV data from S3 and load it as a pandas <code>DataFrame</code> object.
Note that when you run [7], you should replace the value of the <code>bucket_name</code> variable with <strong>the name of your own bucket</strong>.
(This is the <code>simplebatch-bucketXXXX</code> that we just checked from the S3 console).</p>
</div>
<div class="paragraph">
<p>Next, in cell [9], we plot the CSV data (<a href="#fig_loss_epoch_profile2">Figure 67</a>).
We have successfully trained the MNIST model using AWS Batch, just as we did when we ran it locally!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre><span class="c1"># [9]
</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"train_loss"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"Train"</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"Val"</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">])</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Best loss:"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best loss epoch:"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">]</span><span class="o">.</span><span class="n">argmin</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best accuracy:"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best accuracy epoch:"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div id="fig_loss_epoch_profile2" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/loss_epoch_profile2.png" alt="loss_epoch_profile2" width="600">
</div>
<div class="title">Figure 67. The result of the MNIST model training performed on AWS Batch</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:batch_parallel_jobs">9.9. Submitting parallel jobs</h3>
<div class="paragraph">
<p>Now, here comes the final part.
Let&#8217;s use the AWS Batch system that we have built to perform real hyperparameter search.</p>
</div>
<div class="paragraph">
<p>Open the file <code>run_sweep.ipynb</code> in the same directory as <code>run_single.ipynb</code> that we just ran.</p>
</div>
<div class="paragraph">
<p>Cells [1], [2] and [3] are identical to <code>run_single.ipynb</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td class="code"><pre><span class="c1"># [1]
</span><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="c1"># [2]
# AWS authentication helper. Skipping...
</span>
<span class="c1"># [3]
</span><span class="k">def</span> <span class="nf">submit_job</span><span class="p">(</span><span class="n">lr</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">momentum</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">profile_name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># ...skip...</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>A for loop in cell [4] is used to prepare a grid of hyperparameter combinations and submit the jobs to the batch.
In this case, 3x3=9 jobs are created.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
</pre></td><td class="code"><pre><span class="c1"># [4]
</span><span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]:</span>
        <span class="n">submit_job</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>After executing the cell [4], open the Batch console.
As before, you will see that the status of the jobs changes from <code>SUBMITTED</code> &gt; <code>RUNNABLE</code> &gt; <code>STARTING</code> &gt; <code>RUNNING</code>.
Finally, make sure that all 9 jobs are in the <code>RUNNING</code> state (<a href="#fig_batch_many_parallel_jobs">Figure 68</a>).
Also, make sure that the <code>Desired vCPUs</code> of the compute environment is 4x9=36 (<a href="#fig_batch_many_parallel_jobs">Figure 68</a>).</p>
</div>
<div id="fig_batch_many_parallel_jobs" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_many_parallel_jobs.png" alt="batch many parallel jobs" width="700">
</div>
<div class="title">Figure 68. Bacth console when multiple jobs were submitted</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s click <code>Jobs</code> from the left menu of the Batch console.
Here, you can see the list of running jobs (<a href="#fig_batch_parallel_job_list">Figure 69</a>).
It is also possible to filter jobs by their status.
You can see that all 9 jobs are in the <code>RUNNING</code> status.</p>
</div>
<div id="fig_batch_parallel_job_list" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/batch_parallel_job_list.png" alt="batch many parallel jobs" width="700">
</div>
<div class="title">Figure 69. The list of jobs</div>
</div>
<div class="paragraph">
<p>Now let&#8217;s take a look at the EC2 console.
Select <code>Instances</code> from the menu on the left, and you will see a list of running instances as shown in <a href="#fig_ec2_instances_list">Figure 70</a>.
You can see that 9 instances of <code>g4dn.xlarge</code> are running.
Batch has launched the necessary number of instances according to the job submission!</p>
</div>
<div id="fig_ec2_instances_list" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/ec2_instances_list.png" alt="ec2 instances list" width="700">
</div>
<div class="title">Figure 70. List of EC2 instances when multiple jobs were submitted</div>
</div>
<div class="paragraph">
<p>Once you have confirmed this, wait for a while until all jobs are finished (it takes about 10-15 minutes).
When all the jobs are finished, you should see the number of <code>SUCCEEDED</code> jobs on the dashboard is 9.
Also, make sure that the <code>Desired vCPUs</code> in the Compute environment has dropped to 0.
Finally, go to the EC2 console and check that all GPU instances are stopped.</p>
</div>
<div class="paragraph">
<p>In summary, by using AWS Batch, we were able to observe a sequence of events in which EC2 instances are automatically launched in response to job submissions, and the instances are immediately stopped upon completion of the job.
Since it takes about 10 minutes to complete a single job, it would take 90 minutes if 9 hyperparameter pairs were calculated sequentially.
By using AWS Batch to run these computations in parallel, we were able to complete all the computations in 10 minutes!</p>
</div>
<div class="paragraph">
<p>Let&#8217;s come back to <code>run_sweep.ipynb</code>.
In the cells after [5], the results of grid search are visualized.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="code"><pre><span class="c1"># [5]
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># [6]
</span><span class="k">def</span> <span class="nf">read_table_from_s3</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">profile_name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">profile_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">profile_name</span><span class="o">=</span><span class="n">profile_name</span><span class="p">)</span>
    <span class="n">s3</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">"s3"</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">bucket</span><span class="o">.</span><span class="n">Object</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"Body"</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># [7]
</span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]):</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">f</span><span class="s">"metrics_lr{lr:0.4f}_m{m:0.4f}.csv"</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">read_table_from_s3</span><span class="p">(</span><span class="s">"simplebatch-bucket43879c71-mbqaltx441fu"</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="n">grid</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>

<span class="c1"># [8]
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s">'w'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">f</span><span class="s">"{grid[i, j]:0.1f}"</span><span class="p">,</span>
                       <span class="n">ha</span><span class="o">=</span><span class="s">"center"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s">"center"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"w"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The resulting plot is <a href="#fig_grid_search_result">Figure 71</a>.</p>
</div>
<div id="fig_grid_search_result" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/grid_search_result.png" alt="grid_search_result" width="400">
</div>
<div class="title">Figure 71. Result of the hyper parameter grid search</div>
</div>
<div class="paragraph">
<p>From this plot, we can see that the accuracy is maximum when the learning rate is 0.1, although the difference is small.
It can also be seen that when the learning rate is 0.1, there is no significant performance gains between different momentum values.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>It should be noted that this parameter search is extremely simplified for learning purposes.</p>
</div>
<div class="paragraph">
<p>For example, in the experiment here the best learning rate turned out to be 0.1.
However, this may be because the number of training epochs is limited to 100.
The lower the learning rate, the more epochs are needed for training.
If the number of training epochs is increased, different results may be observed.</p>
</div>
<div class="paragraph">
<p>In this study, we used 48,000 of the 60,000 training data from MNIST as training data and the remaining 12,000 as validation data.
However, if you are concerned about the bias of the data due to the split, you may want to evaluate the model multiple times by changing the split (<strong>k-fold cross-validation</strong>) as a more sophisticated approach.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In this hands-on session, we experienced the steps to optimize the hyperparameters of the MNIST classification model.
By using AWS Batch, we were able to build a system that can dynamically control EC2 clusters and process jobs in parallel.
If you can master EC2 to this level, you will be able to solve many problems on our own!</p>
</div>
</div>
<div class="sect2">
<h3 id="sec:batch_destroy_app">9.10. Deleting the stack</h3>
<div class="paragraph">
<p>This concludes the hands-on session.
Finally, let&#8217;s delete the stack.
In order to delete the stack for this hands-on, the Docker images placed in the ECR must be deleted manually.
If you don&#8217;t do this, you&#8217;ll get an error when you run <code>cdk destroy</code>.
This is a CloudFormation specification that you have to follow.</p>
</div>
<div class="paragraph">
<p>To delete a Docker image in ECR, go to the ECR console and open the repository where the image is located.
Then, click the <code>DELETE</code> button on the upper right corner of the screen to delete it (<a href="#fig_delete_ecr">Figure 72</a>).</p>
</div>
<div id="fig_delete_ecr" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/delete_ecr.png" alt="delete_ecr" width="700">
</div>
<div class="title">Figure 72. Deleting Docker image from ECR</div>
</div>
<div class="paragraph">
<p>Alternatively, to perform the same operation from the AWS CLI, use the following command (replace <code>XXXX</code> with the name of your ECR repository).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws ecr batch-delete-image <span class="nt">--repository-name</span> XXXX <span class="nt">--image-ids</span> <span class="nv">imageTag</span><span class="o">=</span>latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the image has been deleted, use the following command to delete the stack.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="#sec:batch_development_and_debug">[sec:batch_development_and_debug]</a>
=== Development and debugging of machine learning applications using the cloud</p>
</div>
<div class="paragraph">
<p>In the hands-on session described in this chapter, we used AWS Batch to run parallel neural network trainings to accelerate the model development.
As the last topic in this chapter, we will discuss how to develop and debug machine learning applications using the cloud.</p>
</div>
<div class="paragraph">
<p>If you don&#8217;t have a powerful local machine with GPUs, and you have the budget to use the cloud, then a development scheme like <a href="#fig:cloud_development">Figure 73</a> would be ideal.
In the first stage, create an EC2 instance with GPUa using the method described in <a href="#sec_jupyter_and_deep_learning">Section 6</a>, and experiment with various models in an interactive environment such as Jupyter Notebook.
When the application is completed to some extent with Jupyter, package the application into a Docker image.
Then, run <code>docker run</code> on EC2 to check if the created image works without errors.
Next, we will perform tuning, such as hyperparameter optimization, using a computational system such as AWS Batch, which we learned in the <a href="#sec_aws_batch">Section 9</a>.
Once we have a good deep learning model, we will build a system to perform inference on large-scale data, using <a href="#sec_fargate_qabot">Section 8</a> as a reference.</p>
</div>
<div class="paragraph">
<p>In fact, the exercises in this book have been carried out along this workflow.
We first experimented with a model for solving the MNIST task using Jupyter Notebook, then packaged the code into Docker, and used AWS Batch to perform a hyperparameter search.
By repeating this cycle, we can proceed with the development of machine learning applications that take full advantage of the cloud.</p>
</div>
<div id="fig:cloud_development" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_batch/cloud_development.png" alt="cloud_development" width="700">
</div>
<div class="title">Figure 73. Development workflow of cloud-based machine learning applications</div>
</div>
</div>
<div class="sect2">
<h3 id="_short_summary">9.11. Short summary</h3>
<div class="paragraph">
<p>This concludes Part II of this book.
We hope you enjoyed the journey exploring the cloud technology.</p>
</div>
<div class="paragraph">
<p>In Part II, we first explained how to launch an EC2 instance with GPUs in order to run deep learning calculations in the cloud.
In the hands-on session, we trained a neural network to solve the MNIST digit recognition task using a virtual server launched in the cloud (<a href="#sec_jupyter_and_deep_learning">Section 6</a>).</p>
</div>
<div class="paragraph">
<p>We also explained the steps to create a cluster using Docker and ECS as a means to build large scale machine learning applications (<a href="#sec_docker_introduction">Section 7</a>).
As an exercise, we deployed a bot in the cloud that automatically generates answers to text questions given in English (<a href="#sec_fargate_qabot">Section 8</a>).
You should have been able to get some experience how computational resources are created and deleted dynamically in response to the submission of tasks.</p>
</div>
<div class="paragraph">
<p>Furthermore, in <a href="#sec_aws_batch">Section 9</a>, we introduced a method to train neural networks in parallel using AWS Batch.
Although the methods introduced here are minimal, they cover the essence of how to scale up a computer system.
We hope that these hands-on experiences have given you some idea of how to apply cloud technology to solve real-world problems.</p>
</div>
<div class="paragraph">
<p>In the third part of this book, we take it a step further and explain the latest cloud design method called serverless architecture.
In the hands-on session, we will implement a simple SNS service from scratch.
Let&#8217;s continue our journey to enjoy the cutting-edge frontiers of cloud computing!</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_to_create_web_services">10. How to create web services</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This is the third part of the book.
In the previous sections, we have explained how to start a virtual server in the cloud and run computations on it.
Using EC2, ECS, Fargate, and Batch, we have configured dynamically scaling clusters and implemented cloud systems that execute tasks in parallel.
In retrospect, you may notice that the techniques we have introduced so far have been focused on embracing the cloud to solve your own scientific or engineering problem.
On the other hand, another important role of the cloud is to provide computing services and databases <strong>that can be used by the general public</strong>.</p>
</div>
<div class="paragraph">
<p>In Part III, which begins with this section, we would like to take a slightly different direction from the previous lectures and discuss how to deploy applications on the cloud and make them widely available to the general public.
Through this lecture, we will learn how web services in the real world are created, and how to build such applications from scratch.
In the process, we will explain the latest cloud design method called serverless architecture.</p>
</div>
<div class="paragraph">
<p>As a prelude, this chapter provides an overview of the technology behind the web services and introduces some concepts and terminology.
Theyse are essential knowledge for the hands-on exercises that follow, so please take your time to understand them well.</p>
</div>
<div class="sect2">
<h3 id="_how_web_services_workusing_twitter_as_an_example">10.1. How Web Services Work&#8201;&#8212;&#8201;Using Twitter as an Example</h3>
<div class="paragraph">
<p>When you access Twitter, Facebook, YouTube, and other web services from your computer or smartphone, what is actually happening to render the contents in the page?</p>
</div>
<div class="paragraph">
<p>Many readers may already be familiar with the communication between servers and clients via HTTP, and since it would take up too much space to thoroughly explain everything, we will only cover the essentials here.
In the following, we will use
<a href="https://twitter.com">Twitter</a>
as a concrete example to outline the communication between the server and the client.
As a sketch, <a href="#fig:web_server">Figure 74</a> depicts the communication between the client and the server.</p>
</div>
<div id="fig:web_server" class="imageblock text-center">
<div class="content">
<img src="imgs/web_server.png" alt="web_server" width="700">
</div>
<div class="title">Figure 74. Sketch of communication between client and web server</div>
</div>
<div class="paragraph">
<p>As a premise, the client-server communication is done using <strong>HTTP (Hypertext Transfer Protocol)</strong>.
Recently, it has become a standard to use <strong>HTTPS (Hypertext Transfer Protocol Secure)</strong>, which is an encrypted HTTP.
In the first step, the client obtains static content from the server through HTTP(S) communication.
Static content includes the main body of a web page document written in <strong>HTML (Hypertext Markup Language)</strong>, page design and layout files written in <strong>CSS (Cascading Style Sheets)</strong>, and programs that define the dynamic behavior of the page written in <strong>JavaScript (JS)</strong>.
In the design of modern web applications, including Twitter, these static files only define the "frame" of the page, and the content (e.g., the list of tweets) must be retrieved using <strong>API (Application Programming Interface)</strong>.
Therefore, the client sends the API request to the server according to the program defined in the JavaScript, and obtains the tweet list.
<strong>JSON (JavaScript Object Notation)</strong> is often used to exchange text data.
Media content such as images and videos are also retrieved by the API in the same way.
The text and images retrieved in this way are embedded in the HTML document to create the final page presented to the user.
Also, when posting a new tweet, the client uses the API to write the data to the server&#8217;s database.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec_rest_api">10.2. REST API</h3>
<div class="paragraph">
<p>API (Application Programming Interface) is a term that has been frequently used in this book, but we will give a more formal definition here.
An API is a general term for an interface through which an application can exchange commands and data with external software.
Especially in the context of web services, it refers to the list of commands that a server exposes to the outside world.
The client obtains the desired data or sends data to the server by choosing the appropriate API commands.</p>
</div>
<div class="paragraph">
<p>Especially in the context of the web, APIs based on a design philosophy called <strong>REST (Representational State Transfer)</strong> are most commonly used.
An API that follows the REST design guidelines is called a <strong>REST API</strong> or <strong>RESTful API</strong>.</p>
</div>
<div class="paragraph">
<p>A REST API consists of a pair of <strong>Method</strong> and <strong>URI (Universal Resource Identifier)</strong>, as shown in <a href="#rest_api">Figure 75</a>.</p>
</div>
<div id="rest_api" class="imageblock text-center">
<div class="content">
<img src="imgs/rest_api.png" alt="rest_api" width="700">
</div>
<div class="title">Figure 75. REST API</div>
</div>
<div class="paragraph">
<p>A method can be thought of as a "verb" that abstractly expresses the kind of desired operation.
Methods can use any of the nine verbs defined in the HTTP standard.
Among them, the five most frequently used ones are <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>PATCH</code>, and <code>DELETE</code> (<a href="#tab:rest_api_methods">Table 6</a>).
The operations using these five methods are collectively called <strong>CRUD</strong> (create, read, update, and delete).</p>
</div>
<table id="tab:rest_api_methods" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 6. REST API Methods</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">Intended behaviour</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GET</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Obtaining items</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">POST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Creating a new item</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PUT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Replacing an existing item with a new one</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PATCH</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Updating a part of an existing item</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DELETE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Deleting an item</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>On the other hand, a URI represents the target of an operation, i.e., the "object".
In the context of the web, the target of an operation is often referred to as a <strong>resource</strong>.
The URI often begins with the address of the web server, starting with http or https, and the path to the desired resource is specified after the / (slash).
In the example of <a href="#rest_api">Figure 75</a>, it means to retrieve (GET) the resource <code>/1.1/status/home_timeline</code> with the address <code><a href="https://api.twitter.com" class="bare">https://api.twitter.com</a></code>.
(Note that the number <code>1.1</code> here indicates the API version.)
This API request retrieves the list of tweets in the user&#8217;s home timeline.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In addition to the methods listed in <a href="#tab:rest_api_methods">Table 6</a>, other methods defined in the HTTP protocol (OPTIONS, TRACE, etc.) can be used for the REST API methods, but they are not so common.</p>
</div>
<div class="paragraph">
<p>In some cases, these methods alone are not enough to express a verb, but the meaning may be made clearer by using explicit path in URI.
For example, the Twitter API for deleting tweets is defined as <code>POST statuses/destroy/:id</code>.
In the end, you need to read the API documentation carefully to find out what each API does.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The concept of REST was established in the early 2000s and has become the standard for API design today.
As web technology advances, on the other hand, the demand for new API design is growing.
One approach that has become particularly popular in recent years is
<a href="https://graphql.org/">GraphQL</a>.s
GraphQL was first created by Facebook, and is currently maintained and updated by the GraghQL Foundation.
GraphQL has several advantages over REST, including the ability for clients to query data with greater flexibility.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_twitter_api">10.3. Twitter API</h3>
<div class="paragraph">
<p>In order to have a more realistic feeling on the web APIs, let&#8217;s take a look at Twitter&#8217;s API.
A list of APIs provided by Twitter can be found at
<a href="https://developer.twitter.com/en/docs/api-reference-index">Twitter&#8217;s Developer Documentation</a>.
Some representative API endpoints are listed in <a href="#tab_twitter_api">Table 7</a>.</p>
</div>
<table id="tab_twitter_api" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 7. Twitter API</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Endpoint</th>
<th class="tableblock halign-left valign-top">Expected behaviour</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>GET statuses/home_timeline</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Get the list of tweets in the home timeline.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>GET statuses/show/:id</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Get the details of the tweet specified by <code>:id</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>GET search</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Search for tweets</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST statuses/update</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Post a new tweet</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST media/upload</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Upload images</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST statuses/destroy/:id</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Delete a tweet specified by <code>:id</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST statuses/retweet/:id</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Retweet a tweet specified by <code>:id</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST statuses/unretweet/:id</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Undo retweet of a tweet specified by <code>:id</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST favorites/create</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Like the selected tweet.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST favorites/destroy</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Undo like of the selected tweet.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Based on this list of APIs, let&#8217;s simulate the client-server communication that happens when you open a Twitter app or website.</p>
</div>
<div class="paragraph">
<p>When a user opens Twitter, the first API request sent to the server is <code>GET statuses/home_timeline</code>, which retrieves a list of tweets in the user&#8217;s home timeline.
Each tweet is in JSON format and contains attributes such as <code>id</code>, <code>text</code>, <code>user</code>, <code>coordinates</code>, and <code>entities</code>.
The <code>id</code> represents the unique ID of the tweet, and the <code>text</code> contains the body of the tweet.
The <code>user</code> is a JSON data containing the information of the user who posted the tweet, including the name and URL of the profile image.
The <code>coordinates</code> contains the geographic coordinates of where the tweet was posted.
<code>entities</code> contains the links to media files (images, etc.) related to the tweet.
From <code>GET statuses/home_timeline</code>, a list of the most recent tweets is retrieved (or a part of the list if the list is too long).
If you know the ID of the tweet, you can call <code>GET statuses/show/:id</code> to retrieve the specific tweet specified by the <code>:id</code> parameter.</p>
</div>
<div class="paragraph">
<p>The <code>GET search</code> API is used to search tweets.
The <code>GET search</code> API can be used to search for tweets by passing various query conditions, such as words in the tweet, hashtags, and the date, time, and location of the tweet.
The API will return the tweet data in JSON format, similar to <code>GET statuses/home_timeline</code>.</p>
</div>
<div class="paragraph">
<p>When a user posts a new tweet, the <code>POST statuses/update</code> endpoint is used.
The <code>POST statuses/update</code> endpoint receives the text of the tweet, and in the case of a reply, the ID of the tweet to which the user is replying.
If you want to attach images to the tweet, use <code>POST media/upload</code> as well.
To delete a tweet, <code>POST statuses/destroy/:id</code> is used.</p>
</div>
<div class="paragraph">
<p>Other frequently used operations are <code>POST statuses/retweet/:id</code> and <code>POST statuses/unretweet/:id</code>.
These APIs are used to retweet or unretweet the tweet specified by <code>:id</code>, respectively.
In addition, <code>POST favorites/create</code> and <code>POST favorites/destroy</code> can be used to add or remove a "like" to a selected tweet.</p>
</div>
<div class="paragraph">
<p>This is the sequence of operations that takes place behind Twitter applications.
If you want to create your own bot, you can do so by writing a custom program that combines these APIs.</p>
</div>
<div class="paragraph">
<p>As you can see, APIs are the most fundamental element in the construction of any web service.
In the following sections, the terms introduced in this section will appear many times, so please keep them in mind before reading on.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_serverless">11. Serverless architecture</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Serverless architecture or serverless computing is a way of designing cloud systems based on a completely different approach.
Historically, <a href="https://aws.amazon.com/lambda/">Lamba</a>, released by AWS in 2014, is considered as a pioneer of serverless architecture.
Since then, other cloud platforms such as Google and Microsoft have started to provide similar features.
The advantage of serverless architecture is that it enables the creation of scalable cloud systems inexpensively and easily, and it is rapidly being adopted by many cloud systems in recent years.</p>
</div>
<div class="paragraph">
<p>Serverless literally means computing without servers, but what does it actually mean?
In order to explain serverless, we must first explain the traditional "serverful" system.</p>
</div>
<div class="sect2">
<h3 id="chap_serverful_cloud">11.1. Serverful cloud (conventional cloud)</h3>
<div class="paragraph">
<p>A sketch of a traditional cloud system is shown in <a href="#serverful">Figure 76</a>.
The request sent from the client is first sent to the API server.
In the API server, tasks are executed according to the content of the request.
Some tasks can be completed by the API server alone, but in most cases, reading and writing of the database is required.
In general, an independent server machine dedicated to the database is used.
Large sized data, such as images and videos, are often stored on a separate storage server.
These API servers, database servers, and storage servers are all independent server machines.
In AWS terms, you can think of them as virtual instances of EC2.</p>
</div>
<div class="paragraph">
<p>Many web services are designed to have multiple server machines running in the cloud to handle requests from a large number of clients.
The operation of distributing requests from clients to servers with enough computing capacity is called <strong>load balancing</strong>, and the machine in charge of such operation is called <strong>load balancer</strong>.</p>
</div>
<div class="paragraph">
<p>Launching a large number of instances for the purpose of distributing the computational load is fine, but it is a waste of cost and power if the computational load is too small and the most of the cluster is kept idling.
Therefore, we need a mechanism that dynamically increases or decreases the number of virtual servers in a cluster according to the computational load so that all servers always maintain the certain load.
Such a mechanism is called <strong>cluster scaling</strong>, and the operation of adding a new virtual instance to the cluster in response to an increase in load is called <strong>scale-out</strong>, and the operation of shutting down an instance in response to a decrease in load is called <strong>scale-in</strong>.
Scaling of clusters is necessary not only for API servers, but also for database servers and storage servers.
In the storage server, for example, frequently accessed data is stored in the cache area, and multiple copies of the data are made across instances.
In the same way, database servers require distributed processing to prevent frequent data accesses from disrupting the system.
It is necessary to adjust the load so that it is evenly distributed throughout the cloud system, and developers must spend a lot of time tuning the system.
In addition, the scaling settings need to be constantly reviewed according to the number of users of the service, and continuous development is required.</p>
</div>
<div class="paragraph">
<p>What makes the matters worse,  the tasks processed by the API server are non-uniform.
Being non-uniform, means that, for example, task A consumes 3000 milliseconds of execution time and 512MB of memory, while another task B consumes 1000 milliseconds of execution time and 128MB of memory.
Scaling a cluster becomes complex when a single server machine handles multiple tasks with different computational loads.
In order to simplify this situation, it is possible to design the cluster so that only one type of task is executed by a single server, but there are many negative effects of adopting such design.</p>
</div>
<div id="serverful" class="imageblock text-center">
<div class="content">
<img src="imgs/serverful.png" alt="serverful" width="700">
</div>
<div class="title">Figure 76. Serverful cloud system</div>
</div>
</div>
<div class="sect2">
<h3 id="_to_the_serverless_cloud">11.2. To the serverless cloud</h3>
<div class="paragraph">
<p>As we discussed in <a href="#chap_serverful_cloud">Section 11.1</a>, scaling of clusters is an essential task to maximize the economic efficiency and system stability of cloud systems.
Reflecting this, a lot of developer&#8217;s time and efforts have been invested in it.</p>
</div>
<div class="paragraph">
<p>Scaling a cluster is a task that all developers have done over and over again, and if some aspects could be templated and made common, it would greatly reduce the cost of development.
In order to achieve this, one needs to rethink the design of cloud systems from a fundamental level.
<strong>Is there a cloud system design that is simpler and more efficient by considering scaling as a first and built-in priority</strong>?
Such was the motivation behind the birth of serverless architecture.</p>
</div>
<div class="paragraph">
<p>The biggest problem with conventional serverful systems is that users <strong>occupy the entire server</strong>.
Namely, when an EC2 instance is launched, it is available only to the user who launched it, and the computation resources (CPU and RAM) are allocated exclusively to that user.
Since a fixed allocation of computing resources has been made, the same cost will be incurred in proportion to the launch time, regardless of whether the instance&#8217;s computing load is 0% or 100%.</p>
</div>
<div class="paragraph">
<p>The starting point of serverless architecture is the complete elimination of such <strong>exclusively allocated computational resources</strong>.
In a serverless architecture, all computation resources are managed by the cloud provider.
Rather than renting an entire virtual instance, clients submit a program or commands to the cloud every time they need to perform a computational task.
The cloud provider tries to find free space from its own huge computational resources, executes the submitted program, and returns the execution result back to the client.
In other words, the cloud provider takes care of the scaling and allocation of computational resources, and the user focuses on submitting jobs.
This can be illustrated as <a href="#serverless">Figure 77</a>.</p>
</div>
<div id="serverless" class="imageblock text-center">
<div class="content">
<img src="imgs/serverless.png" alt="serverless" width="700">
</div>
<div class="title">Figure 77. Comparison of serverful cloud and serverless cloud</div>
</div>
<div class="paragraph">
<p>In a serverless cloud, scalability is guaranteed because all scaling is taken care of by the cloud provider.
Even if a client sends a large number of tasks at the same time, the cloud provider&#8217;s sophisticated system ensures that all tasks are executed without delay.
Also, by using a serverless cloud, <strong>the cost of the cloud is determined by the total amount of computation</strong>.
This is a big difference compared to conventional systems where the cost is determined by the launch time of the instance regardless of the total amount of computation performed.</p>
</div>
<div class="paragraph">
<p>Since serverless cloud is a fundamentally different approach from traditional cloud, the way to design the system and write code is very different.
To develop and operate a serverless cloud, it is necessary to be familiar with concepts and terminology specific to serverless technology.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Traditional cloud systems running many virtual instances may be analogous to renting a room.
When you rent a room, the monthly rent is constant, regardless of how much time you spend in the room.
Similarly, a virtual server incurs a fixed fee per hour, regardless of how much computation it is doing.</p>
</div>
<div class="paragraph">
<p>On the other hand, serverless clouds are similar to <strong>electricity, water, and gas bills</strong>.
In this case, the fee is determined in proportion to the amount actually used.
The serverless cloud is also a system where the fee is determined by the total amount of time the calculation is actually performed.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_components_that_make_up_a_serverless_cloud">11.3. Components that make up a serverless cloud</h3>
<div class="paragraph">
<p>Now that we have an overview of serverless architecture, let us introduce you to the components that make up a serverless cloud in AWS.
In particular, we will focus on <strong>Lambda</strong>, <strong>S3</strong>, and <strong>DynamoDB</strong> (<a href="#fig:serverless_logos">Figure 78</a>).
In a serverless cloud, a system is created by integrating these components.
In what follows, we will go through all the knowledge that must be kept in mind when using Lambda, S3, and DynamoDB, so it may be difficult to get a concrete image.
However, in the next section (<a href="#sec_intro_serverless">Section 12</a>), we will provide hands-on exercises for each of them, so you can deepen your understanding.</p>
</div>
<div id="fig:serverless_logos" class="imageblock">
<div class="content">
<img src="imgs/serverless_logos.png" alt="Lambda" width="500">
</div>
<div class="title">Figure 78. Icons for Lambda, S3, and DynamoDB</div>
</div>
<div class="sect3">
<h4 id="_lambda">11.3.1. Lambda</h4>
<div class="paragraph">
<p>The core of serverless computing in AWS is
<a href="https://aws.amazon.com/lambda/">Lambda</a>.
The summary of Lambda is illustrated in <a href="#lambda_workflow">Figure 79</a>.
The workflow with Lambda is simple.
First, users register the code of the program they want to execute.
Programs are supported in major languages such as Python, Node.js, and Ruby.
Each program registered with Lambda is referred to as a function.
When a function is to be executed, an invoke command is sent to Lambda.
As soon as Lambda receives the invoke request, it starts executing the program, within a few milliseconds to a few hundred milliseconds latency.
It then returns the execution results to the client or other programs.</p>
</div>
<div id="lambda_workflow" class="imageblock text-center">
<div class="content">
<img src="imgs/lambda_workflow.png" alt="lambda_workflow" width="500">
</div>
<div class="title">Figure 79. AWS Lambda</div>
</div>
<div class="paragraph">
<p>As you can see, in Lambda, there is no occupied virtual instance, only a program waiting to be executed.
In response to an invoke request, the program is placed somewhere in the huge AWS compute pool and executed.
Even if multiple requests come in at the same time, AWS allocates computing resources to execute them, and processes them in parallel.
In principle, Lambda is able to execute thousands or tens of thousands of requests at the same time.
This kind of service that dynamically executes functions without the existence of an occupied virtual server is collectively called <strong>FaaS (Function as a Service)</strong>.</p>
</div>
<div class="paragraph">
<p>Lambda can use 128MB to 10240MB of memory for each function (specifications at the time of writing).
The effective CPU power is allocated in proportion to the amount of memory.
In other words, the more memory allocated to a task, the more CPU resources will be allocated to it.
(However, AWS does not provide a specific conversion table for RAM and CPU power.)
The execution time is recorded in units of 100 milliseconds, and the price is proportional to the execution time.
<a href="#lambda_pricing">Table 8</a> is the Lambda pricing table (when <code>ap-north-east1</code> region is selected at the time of writing).</p>
</div>
<table id="lambda_pricing" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 8. Lambda pricing</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Memory (MB)</th>
<th class="tableblock halign-left valign-top">Price per 100ms</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.0000002083</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">512</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.0000008333</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.0000016667</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3008</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.0000048958</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>In addition to the fee proportional to the execution time, there is a fee for each request sent.
This is $0.2 per million requests.
For example, if a function that uses 128MB of memory is executed 200 milliseconds each, for a total of 1 million times, then the total cost would be 0.0000002083 * 2 * 10^6 + 0.2 = $0.6.
Since many functions can be executed in about 200 milliseconds for simple calculations such as updating the database, the cost is only $0.6 even if the database is updated one million times.
In addition, if the code is in a waiting state without being executed, the cost is zero.
In this way, cost will be chaged for only the time when meaningful processing is performed.</p>
</div>
<div class="paragraph">
<p>Lambda is most suitable for executing highly repetitive tasks that can be completed in a relatively short time.
Reading and writing databases is a typical example, but other possible uses include cropping the size of an image or performing periodic server-side maintenance.
It is also possible to connect multiple Lambdas in a relay fashion, and complex logic can be expressed by combining simple processes.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>It should be noted that the Lambda fee calculation described above omits some factors that contribute to the cost for the sake of explanation.
For example, it does not take into account the cost of reading and writing DynamoDB or the cost of network communication.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_serverless_storage_s3">11.3.2. Serverless storage: S3</h4>
<div class="paragraph">
<p>The concept of serverless has been extended to storage as well.</p>
</div>
<div class="paragraph">
<p>Conventional storage (file system) requires the presence of a host machine and an OS.
Therefore, a certain amount of CPU resources must be allocated, even if it does not require much power.
In addition, with conventional file systems, the size of the storage space must be determined when the disk is first initialized, and it is often difficult to increase the capacity later.
(Using a file system such as ZFS, it is possible to change the size of the file system freely to some extent.)
Therefore, in traditional cloud computing, you have to specify the size of the disk in advance when you rent a storage space, and you will be charged the same fee whether the disk is empty or full (<a href="#fig:s3_vs_filesystem">Figure 80</a>).</p>
</div>
<div class="paragraph">
<p><a href="https://aws.amazon.com/s3/">Simple Storage Service (S3)</a>
provides a serverless storage system (<a href="#fig:s3_vs_filesystem">Figure 80</a>).
Unlike conventional storage systems, S3 does not have the concept of being "mounted" on the OS.
Basically, data read/write operations are performed through APIs.
In addition, operations that normally require the intervention of the OS and CPU, such as data redundancy, encryption, and backup creation, can also be performed through the API.
With S3, there is no predetermined disk space size, and the total storage space increases as more data is stored in S3.
In principle, it is possible to store petabyte-scale data.
The price of storage is determined by the total amount of the data stored.</p>
</div>
<div id="fig:s3_vs_filesystem" class="imageblock text-center">
<div class="content">
<img src="imgs/s3_vs_filesystem.png" alt="s3_vs_filesystem" width="700">
</div>
<div class="title">Figure 80. Comparison between S3 and conventional file systems</div>
</div>
<div class="paragraph">
<p><a href="#tab:s3_pricing">Table 9</a> summarizes the main factors related to pricing when using S3.
(This is for the <code>us-east-1</code> region.
Only the major points are taken out for the sake of explanation.
For details, see
<a href="https://aws.amazon.com/s3/pricing/?nc=sn&amp;loc=4">Official Documentation "Amazon S3 pricing"</a>]).</p>
</div>
<table id="tab:s3_pricing" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 9. S3 pricing</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Item</th>
<th class="tableblock halign-left valign-top">Price</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data storage (First 50TB)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.023 per GB per month</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PUT, COPY, POST, LIST requests (per 1,000 requests)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.005</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GET, SELECT, and all other requests (per 1,000 requests)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.0004</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Transfer IN To Amazon S3 From Internet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Transfer OUT From Amazon S3 To Internet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.09 per GB</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>First, data storage costs $0.025 per GB per month.
Therefore, if you store 1000GB of data in S3 for a month, you will be charged $25.
In addition, requests such as <code>PUT</code>, <code>COPY</code>, and <code>POST</code> (i.e., operations to write data) incur a cost of $0.005 per 1000 requests, regardless of the amount of data.
Requests such as <code>GET</code> and <code>SELECT</code> (= operations to read data) incur a cost of $0.0004 per 1000 requests.
S3 also incurs a cost for communication when retrieving data out of S3.
At the time of writing, transferring data from S3 to the outside via the Internet (data-out) incurs a cost of $0.09 per GB.
Sending data into S3 via the Internet (data-in) is free of charge.
Transferring data to services in the same AWS region (Lambda, EC2, etc.) is also free.
There is a cost for transferring data across AWS regions.
In any case, in keeping with the serverless concept, all fees are determined on a pay-as-you-go basis.</p>
</div>
</div>
<div class="sect3">
<h4 id="_serverless_database_dynamodb">11.3.3. Serverless database: DynamoDB</h4>
<div class="paragraph">
<p>The concept of serverless can also be applied to databases.
A database here refers to a fast storage area for web services to record data such as user and product information.
Some of the popular databases include
<a href="https://www.mysql.com/">MySQL</a>,
<a href="https://www.postgresql.org/">PostgreSQL</a>,
<a href="https://www.mongodb.com/">MongoDB</a>.</p>
</div>
<div class="paragraph">
<p>The difference between a database and ordinary storage is in the data retrieval function.
In ordinary storage, data is simply written to disk.
In a database, data is arranged in a way that makes searching more efficient, and
frequently accessed data is cached in memory.
This makes it possible to retrieve the elements of interest from a huge amount of data rapidly.</p>
</div>
<div class="paragraph">
<p>Naturally, the involvement of a CPU is essential to realize such a search function.
Therefore, when constructing a conventional database, a machine with a large number of CPU cores is often used in addition to the large storage space.
Often, a distributed system consisted of multiple machines is designed to host a massive database.
In the case of a distributed system, it is necessary to scale appropriately according to the access load to the database, as discussed in <a href="#chap_serverful_cloud">Section 11.1</a>.</p>
</div>
<div class="paragraph">
<p><a href="https://aws.amazon.com/dynamodb/">DynamoDB</a>
is a serverless and distributed database provided by AWS.
Because it is serverless, there is no occupied virtual instance for the database, and operations such as writing, reading, and searching data are performed through APIs.
As with S3, there is no upper limit to the data storage space, and the storage space increases as more data is stored.
In addition, DynamoDB automatically handles scaling when the load on the database increases or decreases, eliminating complicated programming to control the database scaling.</p>
</div>
<div class="paragraph">
<p>The calculation of DynamoDB pricing is rather complicated, but <a href="#tab:dynamodb_pricing">Table 10</a> summarizes the main factors involved in pricing when using the "On-demand Capacity" mode.
(The table is for the <code>us-east-1</code> region.
For details, see
<a href="https://aws.amazon.com/dynamodb/pricing/on-demand/">Official Documentation "Pricing for On-Demand Capacity"</a>).</p>
</div>
<table id="tab:dynamodb_pricing" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 10. DynamoDB pricing</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Item</th>
<th class="tableblock halign-left valign-top">Price</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write request units</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$1.25 per million write request units</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Read request units</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.25 per million read request units</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$0.25 per GB-month</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>In DynamoDB, the unit for data write operations is called a write request unit, and the unit for data read operations is called a read request unit.
Basically, writing data of 1kB or less once consumes 1 write request unit, and reading data of 4kB or less once consumes 1 read request unit.
(For details, see
<a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html">Official Documentation "Read/Write Capacity Mode"</a>).
The cost of write request units is set at $1.25 per million requests, and the cost of read request units is set at $0.25 per million requests.
There is also a monthly cost of $0.25 per GB chaged for stored data.
Since DynamoDB is a database with a high-speed search function, the storage cost per GB is about 10 times higher than S3.
The cost of DynamoDB data transfer is zero for both data-in and data-out within the same region.
A separate cost is incurred for communication across regions.</p>
</div>
</div>
<div class="sect3">
<h4 id="_other_serverless_components_in_aws">11.3.4. Other serverless components in AWS</h4>
<div class="paragraph">
<p>Lambda, S3, and DynamoDB described above are the most frequently used services in serverless cloud.
Other components of serverless cloud are listed below.
Some of them will be explained during the hands-on sessions in the later sections.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://aws.amazon.com/api-gateway/">API Gateway</a>:
This is responsible for routing when building the REST API.
It will be covered in <a href="#sec_bashoutter">Section 13</a>.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/fargate/">Fargate</a>:
Fargate, which we used in <a href="#sec_fargate_qabot">Section 8</a>, is another element of the serverless cloud.
The difference between Fargate and Lambda is that Fargate can perform calculations that require a larger amount of memory and CPU than Lambda.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/sns/">Simple Notification Service (SNS)</a>:
A service for exchanging events between serverless services.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/step-functions/">Step Functions</a>:
Orchestration between serverless services.</p>
</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Is serverless architecture a solution for everything?</strong></p>
</div>
<div class="paragraph">
<p>We think the answer to this question is no.
Serveless is still a new technology, and it has several disadvantages or limitations compared to serverful system.</p>
</div>
<div class="paragraph">
<p>One major disadvantage is that serverless systems are specific to each cloud platform, so they can only be operated on a particular platform.
Migrating a serverless system created in AWS to Google&#8217;s cloud, for example, would require a rather large rewrite of the program.
On the other hand, for serverful systems, migration between platforms is relatively easy.
This is probably the cloud providers' buisiness strategy to increase the dependency on their own systems and keep their customers.</p>
</div>
<div class="paragraph">
<p>Other limitations and future challenges of serverless computing are discussed in detail in the following paper.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://arxiv.org/abs/1812.03651">Hellerstein et al., "Serverless Computing: One Step Forward, Two Steps Back" arXiv (2018)</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_intro_serverless">12. Hands-on #5: Introduction to serverless computing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the previous chapter, we gave an overview of serverless architecture.
In this chapter, let&#8217;s learn how to use serverless cloud through hands-on exercises.
In this hands-on session, we will go through three serverless cloud components: Lambda, S3, and DynamoDB.
A short tutorial is provided for each of them.</p>
</div>
<div class="sect2">
<h3 id="_lambda_hands_on">12.1. Lambda hands-on</h3>
<div class="paragraph">
<p>First, let&#8217;s learn how to use Lambda.
The source code for the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/serverless/lambda">handson/serverless/lambda</a>.</p>
</div>
<div class="paragraph">
<p>A sketch of the application used in this hands-on is shown in <a href="#fig:lambda_deploy">Figure 81</a>.
In STEP 1, code written in Python is registered to Lambda using AWS CDK.
Then, in STEP 2, we use the invoke API to launch multiple Lambdas simultaneously to perform parallel computations.
This is a minimal setup for the purpose of experiencing the Lambda workflow.</p>
</div>
<div id="fig:lambda_deploy" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/lambda_deploy.png" alt="lambda_deploy" width="700">
</div>
<div class="title">Figure 81. Overview on Lambda tutorial</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This hands-on exercise can be performed within the
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free Lambda tier</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The program to deploy is written in
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/lambda/app.py">app.py</a>.
Let&#8217;s take a look at the code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="code"><pre><i class="conum" data-value="1"></i><b>(1)</b>
<span class="n">FUNC</span> <span class="o">=</span> <span class="s">"""
import time
from random import choice, randint
def handler(event, context):
    time.sleep(randint(2,5))
    sushi = ["salmon", "tuna", "squid"]
    message = "Welcome to Cloud Sushi. Your order is " + choice(sushi)
    print(message)
    return message
"""</span>

<span class="k">class</span> <span class="nc">SimpleLambda</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="n">handler</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">'LambdaHandler'</span><span class="p">,</span>
            <span class="n">runtime</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Runtime</span><span class="o">.</span><span class="n">PYTHON_3_7</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_inline</span><span class="p">(</span><span class="n">FUNC</span><span class="p">),</span>
            <span class="n">handler</span><span class="o">=</span><span class="s">"index.handler"</span><span class="p">,</span>
            <span class="n">memory_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">timeout</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">Duration</span><span class="o">.</span><span class="n">seconds</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
            <span class="n">dead_letter_queue_enabled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here, we define a function that should be executed by Lambda.
This is a very simple function that sleeps for a random period of 2-5 seconds, then randomly selects one of the strings ["salmon", "tuna", "squid"], and returns a message "Welcome to Cloud Sushi. Your order is XXXX" (where XXXX is the chosen sushi item).</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Next, the function written in &lt;1&gt; is registered in Lambda.
The meanings of the parameters are quite obvious, but let us explin for the completeness.
<div class="ulist">
<ul>
<li>
<p><code>runtime=_lambda.Runtime.PYTHON_3_7</code>:
Here, we want to use Python 3.7 to execute the function defined above.
In addition to Python 3.7, other languages such as Node.js, Java, Ruby and Go are also available.</p>
</li>
<li>
<p><code>code=_lambda.Code.from_inline(FUNC)</code>
We specify the code to be executed by Lambda.
Here, the string defined in <code>FUNC=&#8230;&#8203;</code> is passed.
You can also pass the path of a file.</p>
</li>
<li>
<p><code>handler="index.handler"</code>:
This is a parameter to distinguish between the main and sub functions when the code contains several sub functions.
It means that the function named <code>handler</code> should be executed as the main function.</p>
</li>
<li>
<p><code>memory_size=128</code>:
Specifies that the maximum memory size is 128MB.</p>
</li>
<li>
<p><code>timeout=core.Duration.seconds(10)</code>.
The timeout period is set to 10 seconds.
If the function does not finish within 10 seconds, an error is returned.</p>
</li>
<li>
<p><code>dead_letter_queue_enabled=True</code>:
This is an advanced setting and is not explained here.</p>
</li>
</ul>
</div></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By running the above program, a Lambda function will be created in the cloud.
Now let&#8217;s deploy it.</p>
</div>
<div class="sect3">
<h4 id="_deploying_the_application_3">12.1.1. Deploying the application</h4>
<div class="paragraph">
<p>The deployment procedure is almost the same as the previous hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>handson/serverless/lambda

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># deploy!</span>
<span class="nv">$ </span>cdk deploy</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the deployment command is executed successfully, you should get an output like <a href="#handson_04_lambda_cdk_output">Figure 82</a>.
In the output you should see a message <code>FunctionName = SimpleLambda-XXXX</code> where <code>XXXX</code> is some random string.
We will use this <code>XXXX</code> string later, so make a note of it.</p>
</div>
<div id="handson_04_lambda_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/handson_04_lambda_cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 82. Output of <code>cdk deploy</code></div>
</div>
<div class="paragraph">
<p>Let&#8217;s log in to the AWS console and check the deployed stack.
If you go to the Lambda page from the console, you can see the list of Lambda functions (<a href="#handson_04_lambda_console_func_list">Figure 83</a>).</p>
</div>
<div id="handson_04_lambda_console_func_list" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/lambda_console_func_list.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 83. Viewing the list of functions from Lambda console</div>
</div>
<div class="paragraph">
<p>In this application, we have created a function with a name <code>SimpleLambda-XXXX</code>.
Click on the name of the function to see the details.
You should see a screen like <a href="#handson_04_lambda_console_func_detail">Figure 84</a>.
In the editor, you can see the Python function that you have just defined in the code.
Scroll down to the bottom of the screen to see the various settings for the function.</p>
</div>
<div id="handson_04_lambda_console_func_detail" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/lambda_console_func_detail.png" alt="lambda_console_func_detail" width="700">
</div>
<div class="title">Figure 84. Viewing the details of the Lambda function</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The code executed by Lambda can also be edited using the editor on the Lambda console screen (<a href="#handson_04_lambda_console_func_detail">Figure 84</a>).
In some cases, it is faster to directly edit the code here for debugging purpose.
In this case, do not forget to update the CDK code to reflect the edits you made.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_executing_lambda_function">12.1.2. Executing Lambda function</h4>
<div class="paragraph">
<p>Now, let&#8217;s execute (invoke) the Lambda function we have created.
Using the AWS API, we can start executing the function.
Here, we will use the
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/lambda/invoke_one.py">handson/serverless/lambda/invoke _one.py</a>,
which contains a simple code to invoke Lambda function.
Interested readers are recommended to read the code.</p>
</div>
<div class="paragraph">
<p>The following command invokes a Lambda function.
Replace the <code>XXXX</code> part of the command with the string obtained by <code>SimpleLambda.FunctionName = SimpleLambda-XXXX</code> when you deployed it earlier.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python invoke_one.py SimpleLambda-XXXX</code></pre>
</div>
</div>
<div class="paragraph">
<p>After a few seconds, you should get the output <code>"Welcome to Cloud Sushi. Your order is salmon"</code>.
It seems like a toy example, but the function was indeed executed in the cloud, where it generated a random number, selected a random sushi item, and returned the output.
Try running this command a few times and see that different sushi menu is returned for each execution.</p>
</div>
<div class="paragraph">
<p>Now, this command executes one function at a time, but the real power of Lambda is that it can execute a large number of tasks at the same time.
Next, let&#8217;s try sending 100 tasks at once.
We use a Python script saved as
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/lambda/invoke_many.py">handson/serverless/lambda/ invoke_many.py</a>.</p>
</div>
<div class="paragraph">
<p>Run the following command.
Remember to replace the <code>XXXX</code> part as before.
The second argument, <code>100</code>, means to submit 100 tasks.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python invoke_many.py XXXX 100</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output will be something like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash">....................................................................................................
Submitted 100 tasks to Lambda!</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s confirm that 100 tasks are actually running simultaneously.
Go back to the Lambda console (<a href="#handson_04_lambda_console_func_detail">Figure 84</a>), and click on the "Monitoring" tab.
You will see a graph like <a href="#handson_04_lambda_console_monitoring">Figure 85</a>.</p>
</div>
<div id="handson_04_lambda_console_monitoring" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/lambda_console_monitoring.png" alt="lambda_console_monitoring" width="700">
</div>
<div class="title">Figure 85. Monitoring the execution statistics from Lambda console</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>It takes some time for the graph shown in <a href="#handson_04_lambda_console_monitoring">Figure 85</a> to be updated.
If nothing is shown, wait a while and refresh the graph again.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In <a href="#handson_04_lambda_console_monitoring">Figure 85</a>, "Invocations" means how many times the function has been executed.
You can see that it has been indeed executed 100 times.
Furthermore, "Concurrent executions" shows how many tasks were executed simultaneously.
In this case, the number is 96, which means that 96 tasks were executed in parallel.
(The reason this does not equal 100 is that the commands to start the tasks were not sent at exactly the same time.)</p>
</div>
<div class="paragraph">
<p>As we just saw, although it is very simple, using Lambda, we were able to create a cloud system that can execute a task concurrently.</p>
</div>
<div class="paragraph">
<p>If we tried to do this in a traditional serverful cloud, we would have to write a lot of code for scaling the cluster, and also adjust various parameters.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you are interested, you can try submitting 1000 tasks at once.
You will see that Lambda can handle such a large number of requests.
However, be careful not to overdo it, or you will exceed the free usage limit of Lambda.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_deleting_the_stack_3">12.1.3. Deleting the stack</h4>
<div class="paragraph">
<p>Finally, let&#8217;s remove the stack.
To remove the stack, execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:dynamodb_tutorial">12.2. DynamoDB hands-on</h3>
<div class="paragraph">
<p>Next, let&#8217;s work on a short tutorial on DynamoDB.
The source code for the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/serverless/dynamodb">/handson/serverless/dynamodb</a>.</p>
</div>
<div class="paragraph">
<p>A sketch of the application used in this hands-on is shown in <a href="#fig:dynamodb_deploy">Figure 86</a>.
In STEP 1, we deploy an empty DynamoDB tables using AWS CDK.
Then, in STEP 2, we practice basic operations such as writing, reading, and deleting data from the database using the API.</p>
</div>
<div id="fig:dynamodb_deploy" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/dynamodb_deploy.png" alt="dynamodb_deploy" width="700">
</div>
<div class="title">Figure 86. Overview on DynamoDB tutorial</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This hands-on exercise can be performed within the
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free DynamoDB tier</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The program to deploy is written in
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/dynamodb/app.py">handson/serverless/dynamodb/app.py</a>.
Let&#8217;s take a look at the code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">SimpleDynamoDb</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">table</span> <span class="o">=</span> <span class="n">ddb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"SimpleTable"</span><span class="p">,</span>
            <i class="conum" data-value="1"></i><b>(1)</b>
            <span class="n">partition_key</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">Attribute</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s">"item_id"</span><span class="p">,</span>
                <span class="nb">type</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">AttributeType</span><span class="o">.</span><span class="n">STRING</span>
            <span class="p">),</span>
            <i class="conum" data-value="2"></i><b>(2)</b>
            <span class="n">billing_mode</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">BillingMode</span><span class="o">.</span><span class="n">PAY_PER_REQUEST</span><span class="p">,</span>
            <i class="conum" data-value="3"></i><b>(3)</b>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>With this code, an empty DynamoDB table with the minimum configuration is created.
Let us explain the meanings of each parameter.</p>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here we define <strong>partition key</strong> of the table.
Every DynamoDB table must have a partition key.
The partition key is a unique ID for each element (record) in the table.
Every record in the table must have a partition key.
There cannot be more than one element with the same partition key in a table.
(except for the case where sort Key is used. For more information, see
<a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html">official documentation "Core Components of Amazon DynamoDB"</a>).
In this example, the partition key is named <code>item_id</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Here we specify the <code>billing_mode</code> parameter.
By specifying <code>ddb.BillingMode.PAY_PER_REQUEST</code>, DynamoDB table in <strong>on-demand capacity mode</strong> is created.
There is another mode called <code>PROVISIONED</code>, but this is for more advanced use cases.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Here we specify the <code>removal_policy</code>.
It specifies whether DynamoDB table will be removed together when the CloudFormation stack is deleted.
In this code, <code>DESTROY</code> is selected, so all the data will be deleted.
If you select other options, you can define other behaviors such as keeping DynamoDB backups even if the stack is deleted.</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="sec:serverless_dynamodb_deploy">12.2.1. Deploying the application</h4>
<div class="paragraph">
<p>The deployment procedure is almost the same as the previous hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>handson/serverless/dynamodb

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># deploy!</span>
<span class="nv">$ </span>cdk deploy</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the deployment command is executed successfully, you should get an output like <a href="#handson_04_dynamodb_cdk_output">Figure 87</a>.
In the output you should see a message <code>TableName = XXXX</code> where <code>XXXX</code> is some random string.
We will use this <code>XXXX</code> string later, so make a note of it.</p>
</div>
<div id="handson_04_dynamodb_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/handson_04_dynamodb_cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 87. Output of <code>cdk deploy</code></div>
</div>
<div class="paragraph">
<p>Let&#8217;s log in to the AWS console and check the deployed stack.
From the console, go to the DynamoDB page and select "Tables" from the menu bar on the left.
Then, you can see the list of tables in a screen like <a href="#handson_04_dynamodb_table_list">Figure 88</a>.</p>
</div>
<div id="handson_04_dynamodb_table_list" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/dynamodb_table_list.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 88. Viewing the list of DynamoDB tables</div>
</div>
<div class="paragraph">
<p>The deployment will createa a table with a random name starting with <code>SimpleDynamoDb</code>.
Click on the name of the table to see the details.
You should see a screen like <a href="#handson_04_dynamodb_table_detail">Figure 89</a>.
Click on the "Items" tab to see the records in the table.
At this point, the table is empty because no data has been written to it.</p>
</div>
<div id="handson_04_dynamodb_table_detail" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/dynamodb_table_detail.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 89. Viewing the details of the DynamoDB table</div>
</div>
</div>
<div class="sect3">
<h4 id="_read_and_write_operations">12.2.2. Read and write operations</h4>
<div class="paragraph">
<p>Now, let&#8217;s practice read and write operations using the table that we just created.
Here we will use Python and
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a>
library.</p>
</div>
<div class="paragraph">
<p>First, we write a new record in the table.
Open the file named
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/dynamodb/simple_write.py">simple_write.py</a>
in the hands-on directory.
Inside the program, you will find the following code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">uuid</span> <span class="kn">import</span> <span class="n">uuid4</span>
<span class="n">ddb</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">'dynamodb'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">write_item</span><span class="p">(</span><span class="n">table_name</span><span class="p">):</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">ddb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
    <span class="n">table</span><span class="o">.</span><span class="n">put_item</span><span class="p">(</span>
    <span class="n">Item</span><span class="o">=</span><span class="p">{</span>
        <span class="s">'item_id'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid4</span><span class="p">()),</span>
        <span class="s">'first_name'</span><span class="p">:</span> <span class="s">'John'</span><span class="p">,</span>
        <span class="s">'last_name'</span><span class="p">:</span> <span class="s">'Doe'</span><span class="p">,</span>
        <span class="s">'age'</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>If you read the code from the top, you will see that it first imports the boto3 library and then calls the <code>dynamodb</code> resource.
The <code>write_item()</code> function takes the name of the DynamoDB table as an argument.
Then, the <code>put_item()</code> method is called to write a new record to the DB.
The item has four attributes defined: <code>item_id</code>, <code>first_name</code>, <code>last_name</code>, and <code>age</code>.
The <code>item_id</code> corresponds to the partition key described above, and is given a random string using
<a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID4</a>
algorithm.</p>
</div>
<div class="paragraph">
<p>Now, let&#8217;s run <code>simple_write.py</code>.
Replace "XXXX" with the name of the table you deployed (a string starting with <code>SimpleDynamoDb</code>), and then execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python simple_write.py XXXX</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s check from the AWS console that the new record has been written correctly.
Use the same procedure as <a href="#handson_04_dynamodb_table_detail">Figure 89</a> to display the list of records in the table.
You will find a new record as expected, as shown in <a href="#fig:dynamodb_table_new_item">Figure 90</a>.</p>
</div>
<div id="fig:dynamodb_table_new_item" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-serverless/dynamodb_table_new_item.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 90. Viewing the newly added record in the DynamoDB table</div>
</div>
<div class="paragraph">
<p>It is also possible to use boto3 to read elements from a table.
Open the file named
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/dynamodb/simple_read.py">simple_read.py</a>
in the hands-on directory.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">boto3</span>
<span class="n">ddb</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">'dynamodb'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">scan_table</span><span class="p">(</span><span class="n">table_name</span><span class="p">):</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">ddb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
    <span class="n">items</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">scan</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"Items"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>By calling <code>table.scan().get("Items")</code>, all the records in the table are read out.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s run this script with the following command
(Don&#8217;t forget to replace the "XXXX" part correctly).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python simple_read.py XXXX</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should get an output showing the record we just added eariler.</p>
</div>
</div>
<div class="sect3">
<h4 id="_reading_and_writing_a_large_number_of_records">12.2.3. Reading and writing a large number of records</h4>
<div class="paragraph">
<p>The advantage of DynamoDB is that, as mentioned at the beginning, its processing capacity can be freely expanded according to the load.</p>
</div>
<div class="paragraph">
<p>To test the capability of DynamoDB, let&#8217;s simulate the situation where a large amount of data is written at once.
In
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/serverless/dynamodb/batch_rw.py">batch_rw.py</a>,
we have a short script to perform massive write operation to the database.</p>
</div>
<div class="paragraph">
<p>Run the following command (be sure to replace XXXX with the name of your table).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python batch_rw.py XXXX write 1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command generates a thousand random data, and writes them to the database.</p>
</div>
<div class="paragraph">
<p>Furthermore, let&#8217;s search the database.
In the previous command, a random integer from 1 to 50 is assigned to the attribute <code>age</code> in each data.
To search and retrieve only those elements whose <code>age</code> is less than or equal to 2, you execute the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python batch_rw.py XXXX search_under_age 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s try running the above two commands several times to apply a simulated load to the database.
You should see that the results are returned without any significant delay.</p>
</div>
</div>
<div class="sect3">
<h4 id="_deleting_the_stack_4">12.2.4. Deleting the stack</h4>
<div class="paragraph">
<p>When you have had enough fun with DynamoDB, remember to delete the stack.</p>
</div>
<div class="paragraph">
<p>As in the previous hands-on sessions, you can delete the stack by executing the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:s3_tutorial">12.3. S3 hands-on</h3>
<div class="paragraph">
<p>Coming soon&#8230;&#8203;</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec_bashoutter">13. Hands-on #6: Bashoutter</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the sixth and final hands-on session, we will create a simple web service using the serverless cloud technology we have learned so far.
Specifically, let&#8217;s create a social networking service (SNS), named <strong>Bashoutter</strong>, where people can post their own haiku poems.
(<a href="https://en.wikipedia.org/wiki/Haiku">Haiku</a>
is a Japanese poetic form where it is consisted of 17 characters divided in to 5,5,7 character phrases.)
By incorporating all the technologies such as Lambda, DynamoDB, and S3, a simple yet scalable social networking service that makes full use of serverless cloud will be born.
By the end of this hands-on, we will deploy a modern-looking SNS shown in <a href="#handson_05_bashoutter">Figure 91</a>.</p>
</div>
<div id="handson_05_bashoutter" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/bashoutter.png" alt="bashoutter" width="700">
</div>
<div class="title">Figure 91. "Bashoutter" SNS app we will be building in this hands-on session</div>
</div>
<div class="sect2">
<h3 id="_preparation">13.1. Preparation</h3>
<div class="paragraph">
<p>The source code for the hands-on is available on GitHub at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/bashoutter">handson/bashoutter</a>.</p>
</div>
<div class="paragraph">
<p>To run this hands-on, it is assumed that the preparations described in the first hands-on (<a href="#handson_01_prep">Section 4.1</a>) have been completed.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This hands-on exercise can be performed within the
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">free AWS tier</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_reading_the_application_source_code_4">13.2. Reading the application source code</h3>
<div class="sect3">
<h4 id="_api">13.2.1. API</h4>
<div class="paragraph">
<p>In this application, we implement functions such as accepting haiku submissions from people, and retrieving a list of haiku from the database.
As a minimum design to realize this service, we will implement four REST APIs as shown in <a href="#tab_handson_05_api">Table 11</a>.
The APIs for basic data manipulation, such as posting, browsing, and deleting haiku, are provided.
In addition, <code>PATCH /haiku/{item_id}</code> is used to "like" the haiku specified by <code>{item_id}</code>.</p>
</div>
<table id="tab_handson_05_api" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 11. Bashoutter API</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>GET /haiku</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Get a list of haiku</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>POST /haiku</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Post a new haiku</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>PATCH /haiku/{item_id}</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Like a haiku specified by <code>{item_id}</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>DELETE /haiku/{item_id}</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Delete the haiku specified by <code>{item_id}</code></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <strong>Open API Specification</strong> (OAS; formerly known as the Swagger Specification) is a description format for REST APIs.
If the API specification is written according to the OAS, you can easily generate API documentation and client applications.
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/bashoutter/specs/swagger.yml">API specification prepared for this project</a>
is also written according to the OAS.
For more information, see
<a href="https://swagger.io/docs/specification/about/">official Swagger documentation</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="sec:bashoutter_application">13.2.2. Application architecture</h4>
<div class="paragraph">
<p><a href="#handson_05_architecture">Figure 92</a> shows an overview of the application we are creating in this hands-on.</p>
</div>
<div id="handson_05_architecture" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/handson-05-architecture.png" alt="hands-on 05 architecture" width="600">
</div>
<div class="title">Figure 92. Application architecture</div>
</div>
<div class="paragraph">
<p>The summary of the system design is as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>API requests from the client are first sent to the <strong>API Gateway</strong> (described below), and then forwarded to the Lambda function specified by the API path.</p>
</li>
<li>
<p>An independent Lambda function is defined for each API path.</p>
</li>
<li>
<p>A database (powered by DynamoDB) is created to record the haiku information (author, text, submission date, etc.).</p>
</li>
<li>
<p>Give each Lambda function read and write access to DynamoDB.</p>
</li>
<li>
<p>Finally, we create an S3 bucket to deliver the static contents of the web page.
Clients retrive HTML, CSS and JavaScript from this bucket and the contents will be displayed on a web browser.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now, let us take a look at the main application code
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/bashoutter/app.py">handson/bashoutter/app.py</a>)ï¼Ž</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">Bashoutter</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">Stack</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">App</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <i class="conum" data-value="1"></i><b>(1)</b>
        <span class="c1"># dynamoDB table to store haiku
</span>        <span class="n">table</span> <span class="o">=</span> <span class="n">ddb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"Bashoutter-Table"</span><span class="p">,</span>
            <span class="n">partition_key</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">Attribute</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s">"item_id"</span><span class="p">,</span>
                <span class="nb">type</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">AttributeType</span><span class="o">.</span><span class="n">STRING</span>
            <span class="p">),</span>
            <span class="n">billing_mode</span><span class="o">=</span><span class="n">ddb</span><span class="o">.</span><span class="n">BillingMode</span><span class="o">.</span><span class="n">PAY_PER_REQUEST</span><span class="p">,</span>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span>
        <span class="p">)</span>

        <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"Bashoutter-Bucket"</span><span class="p">,</span>
            <span class="n">website_index_document</span><span class="o">=</span><span class="s">"index.html"</span><span class="p">,</span>
            <span class="n">public_read_access</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span>
        <span class="p">)</span>
        <span class="n">s3_deploy</span><span class="o">.</span><span class="n">BucketDeployment</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"BucketDeployment"</span><span class="p">,</span>
            <span class="n">destination_bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span>
            <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="n">s3_deploy</span><span class="o">.</span><span class="n">Source</span><span class="o">.</span><span class="n">asset</span><span class="p">(</span><span class="s">"./gui/dist"</span><span class="p">)],</span>
            <span class="n">retain_on_delete</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">common_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"runtime"</span><span class="p">:</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Runtime</span><span class="o">.</span><span class="n">PYTHON_3_7</span><span class="p">,</span>
            <span class="s">"environment"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">"TABLE_NAME"</span><span class="p">:</span> <span class="n">table</span><span class="o">.</span><span class="n">table_name</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="c1"># define Lambda functions
</span>        <span class="n">get_haiku_lambda</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"GetHaiku"</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_asset</span><span class="p">(</span><span class="s">"api"</span><span class="p">),</span>
            <span class="n">handler</span><span class="o">=</span><span class="s">"api.get_haiku"</span><span class="p">,</span>
            <span class="n">memory_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="o">**</span><span class="n">common_params</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">post_haiku_lambda</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"PostHaiku"</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_asset</span><span class="p">(</span><span class="s">"api"</span><span class="p">),</span>
            <span class="n">handler</span><span class="o">=</span><span class="s">"api.post_haiku"</span><span class="p">,</span>
            <span class="o">**</span><span class="n">common_params</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">patch_haiku_lambda</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"PatchHaiku"</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_asset</span><span class="p">(</span><span class="s">"api"</span><span class="p">),</span>
            <span class="n">handler</span><span class="o">=</span><span class="s">"api.patch_haiku"</span><span class="p">,</span>
            <span class="o">**</span><span class="n">common_params</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">delete_haiku_lambda</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"DeleteHaiku"</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_asset</span><span class="p">(</span><span class="s">"api"</span><span class="p">),</span>
            <span class="n">handler</span><span class="o">=</span><span class="s">"api.delete_haiku"</span><span class="p">,</span>
            <span class="o">**</span><span class="n">common_params</span><span class="p">,</span>
        <span class="p">)</span>

        <i class="conum" data-value="4"></i><b>(4)</b>
        <span class="c1"># grant permissions
</span>        <span class="n">table</span><span class="o">.</span><span class="n">grant_read_data</span><span class="p">(</span><span class="n">get_haiku_lambda</span><span class="p">)</span>
        <span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">post_haiku_lambda</span><span class="p">)</span>
        <span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">patch_haiku_lambda</span><span class="p">)</span>
        <span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">delete_haiku_lambda</span><span class="p">)</span>

        <i class="conum" data-value="5"></i><b>(5)</b>
        <span class="c1"># define API Gateway
</span>        <span class="n">api</span> <span class="o">=</span> <span class="n">apigw</span><span class="o">.</span><span class="n">RestApi</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s">"BashoutterApi"</span><span class="p">,</span>
            <span class="n">default_cors_preflight_options</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">CorsOptions</span><span class="p">(</span>
                <span class="n">allow_origins</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">Cors</span><span class="o">.</span><span class="n">ALL_ORIGINS</span><span class="p">,</span>
                <span class="n">allow_methods</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">Cors</span><span class="o">.</span><span class="n">ALL_METHODS</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">haiku</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">add_resource</span><span class="p">(</span><span class="s">"haiku"</span><span class="p">)</span>
        <span class="n">haiku</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
            <span class="s">"GET"</span><span class="p">,</span>
            <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">get_haiku_lambda</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">haiku</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
            <span class="s">"POST"</span><span class="p">,</span>
            <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">post_haiku_lambda</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">haiku_item_id</span> <span class="o">=</span> <span class="n">haiku</span><span class="o">.</span><span class="n">add_resource</span><span class="p">(</span><span class="s">"{item_id}"</span><span class="p">)</span>
        <span class="n">haiku_item_id</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
            <span class="s">"PATCH"</span><span class="p">,</span>
            <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">patch_haiku_lambda</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">haiku_item_id</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
            <span class="s">"DELETE"</span><span class="p">,</span>
            <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">delete_haiku_lambda</span><span class="p">)</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Here, a DynamoDB table is created to record the haiku information.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>This part creates an S3 bucket to store and deliver the static site contents.
<code>s3_deploy.BucketDeployment()</code> configures the settings to automatically upload the necessary files when the stack is deployed.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>This part defines the Lambda functions to be executed by each API path.
The functions are written in Python 3.7 and the code can be found at
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/bashoutter/api/api.py">handson/bashoutter/api/api.py</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The Lambda function defined in &lt;3&gt; is given read and write access to the database.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Here, the API Gateway is used to link each API path with the corresponding Lambda function.</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_s3_bucket_in_public_access_mode">13.2.3. S3 bucket in Public access mode</h4>
<div class="paragraph">
<p>Take a closer look at the part of the code where an S3 bucket is created.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"Bashoutter-Bucket"</span><span class="p">,</span>
    <span class="n">website_index_document</span><span class="o">=</span><span class="s">"index.html"</span><span class="p">,</span>
    <span class="n">public_read_access</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">removal_policy</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">RemovalPolicy</span><span class="o">.</span><span class="n">DESTROY</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>What you should pay attention to here is the line <code>public_read_access=True</code>.
S3 has a feature called <strong>Public access mode</strong>.
When the public access mode is turned on, the files in the bucket can be viewed without authentication (i.e., by anyone on the Internet).
This setting is ideal for storing static content for public websites, and many serverless web services are designed this way.
When the public access mode is set, a unique URL such as <code><a href="http://XXXX.s3-website-ap-northeast-1.amazonaws.com/" class="bare">http://XXXX.s3-website-ap-northeast-1.amazonaws.com/</a></code> is assigned to the bucket.
When a client accesses this URL, <code>index.html</code> in the bucket is returned to the client, and the page is loaded
(Note that we are specifying which file to be returned in the line <code>website_index_document="index.html"</code>.)</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When operating a web site for production, it is common to add the service called
<a href="https://aws.amazon.com/cloudfront/">CloudFront</a>
to the S3 bucket in public access mode.
CloudFront can be used to configure <strong>Content Delivery Nework (CDN)</strong> and encrypted HTTPS communication.
For more information about CloudFront, please refer to
<a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html">official documentation "What is Amazon CloudFront?</a>.</p>
</div>
<div class="paragraph">
<p>In this hands-on session, CloudFront configuration was not performed to simplify the code, but readers who are interested may find the program at the following link helpful.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/aws-samples/aws-cdk-examples/tree/master/typescript/static-site" class="bare">https://github.com/aws-samples/aws-cdk-examples/tree/master/typescript/static-site</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The public S3 bucket is assigned a random URL by AWS.
If you want to host it in your own domain such as <code>example.com</code>, you can configure Domain Name System (DNS), such as Amazon Route 53, and add an appropriate record.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After creating an S3 bucket in public access mode, the following code is used to upload the website contents to the bucket upon deployment of the stack.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="n">s3_deploy</span><span class="o">.</span><span class="n">BucketDeployment</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"BucketDeployment"</span><span class="p">,</span>
    <span class="n">destination_bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="n">s3_deploy</span><span class="o">.</span><span class="n">Source</span><span class="o">.</span><span class="n">asset</span><span class="p">(</span><span class="s">"./gui/dist"</span><span class="p">)],</span>
    <span class="n">retain_on_delete</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>With this code, the files in the directory <code>./gui/dist</code> will be placed in the bucket when the deployment is started.
The directory <code>./gui/dist</code> contains the static contents (HTML/CSS/JavaScript) of the website.
We will not explain the implementation details of the GUI here, but the code can be found at
<a href="https://github.com/tomomano/learn-aws-by-coding/tree/main/handson/bashoutter/gui">handson/bashoutter/gui</a>.
If you are interested, we recommend to read the source code.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This website was built using the UI frameworks called
<a href="https://vuejs.org/">Vue.js</a>
and
<a href="https://vuetifyjs.com/">Vuetify</a>.
By using Vue, the web page is rendered using single page application (SPA) technology.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_api_handler_functions">13.2.4. API handler functions</h4>
<div class="paragraph">
<p>When an API request comes, the function that performs the requested processing is called the handler function.
Let&#8217;s take a look at the part where the handler function for the <code>GET /haiku</code> API is defined in Lambda.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="n">get_haiku_lambda</span> <span class="o">=</span> <span class="n">_lambda</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"GetHaiku"</span><span class="p">,</span>
    <span class="n">code</span><span class="o">=</span><span class="n">_lambda</span><span class="o">.</span><span class="n">Code</span><span class="o">.</span><span class="n">from_asset</span><span class="p">(</span><span class="s">"api"</span><span class="p">),</span>
    <span class="n">handler</span><span class="o">=</span><span class="s">"api.get_haiku"</span><span class="p">,</span>
    <span class="n">memory_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="o">**</span><span class="n">common_params</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Starting from the simplest part, <code>memory_size=512</code> specifies the memory allocated for this function as 512MB.
<code>code=_lambda.Code.from_asset("api")</code> defines that the source code of the function should be retrieved from an external directory named <code>api/</code>.
Then, the line <code>handler="api.get_haiku"</code> specifies that <code>get_haiku()</code> function from <code>api.py</code> should be executed as a handler function.</p>
</div>
<div class="paragraph">
<p>Next, let&#8217;s look at the source code of <code>get_haiku()</code> function in <code>api.py</code>
(<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/bashoutter/api/api.py">handson/bashoutter/api/api.py</a>)ï¼Ž</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="code"><pre><span class="n">ddb</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">"dynamodb"</span><span class="p">)</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">ddb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">"TABLE_NAME"</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">get_haiku</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="s">"""
    handler for GET /haiku
    """</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">scan</span><span class="p">()</span>

        <span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"Items"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">status_code</span> <span class="o">=</span> <span class="mi">500</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="p">{</span><span class="s">"description"</span><span class="p">:</span> <span class="n">f</span><span class="s">"Internal server error. {str(e)}"</span><span class="p">}</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">"statusCode"</span><span class="p">:</span> <span class="n">status_code</span><span class="p">,</span>
        <span class="s">"headers"</span><span class="p">:</span> <span class="n">HEADERS</span><span class="p">,</span>
        <span class="s">"body"</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">cls</span><span class="o">=</span><span class="n">DecimalEncoder</span><span class="p">)</span>
    <span class="p">}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In the line <code>response = table.scan()</code>, all the elements are retrieved from the DynamoDB table.
If no error occurs, the status code 200 is returned along with the haiku data, and if any error occurs, the status code 500 is returned.</p>
</div>
<div class="paragraph">
<p>By repeating the above operations for other APIs, handler functions for all APIs are defined.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>In the handler function of <code>GET /haiku</code>, notice the line <code>response = table.scan()</code>.
This is actually not the best way to write a data retrieval from DynamoDB.
The <code>scan()</code> method of DynamoDB returns only data up to 1MB in size.
If the size of the data in the database is larger than 1MB, you need to call the <code>scan()</code> method recursively.
For more information, refer to
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Table.scan">the official documentation of boto3 library</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="sec:bashoutter_iam">13.2.5. Identity and Access Management (IAM)</h4>
<div class="paragraph">
<p>Look at the following part of the code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
</pre></td><td class="code"><pre><span class="n">table</span><span class="o">.</span><span class="n">grant_read_data</span><span class="p">(</span><span class="n">get_haiku_lambda</span><span class="p">)</span>
<span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">post_haiku_lambda</span><span class="p">)</span>
<span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">patch_haiku_lambda</span><span class="p">)</span>
<span class="n">table</span><span class="o">.</span><span class="n">grant_read_write_data</span><span class="p">(</span><span class="n">delete_haiku_lambda</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>AWS has an important concept called
<a href="https://aws.amazon.com/iam/">IAM (Identity and Access Management)</a>.
Although we have not mentioned it so far for the sake of simplicity, IAM is a very important concept in designing the cloud system on AWS.
IAM basically defines what permissions a resource has over other resources.
For example, in its default state, Lambda does not have any permissions to access other resources such as DynamoDB.
Therefore, in order for a Lambda function to read or write DynamoDB data, an IAM must be granted to the Lambda function to allow such operation.</p>
</div>
<div class="paragraph">
<p><code>dynamodb.Table</code> object in CDK has a convenient method <code>grant_read_write_data()</code>, which assigns IAM to other resources so that they can perform read and write operation to the database.
Similarly, the <code>s3.Bucket</code> object in CDK has a method <code>grant_read_write()</code> to allow reading and writing to the bucket.
Indeed, we used this method in <a href="#sec_aws_batch">Section 9</a> where we granted AWS Batch to write data to S3 bucket.
Interested readers can look back and check the code.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The best practice to manage IAM is that the minimam permissions necessary for the system to work should be assigned to each resource.
This will not only improve security of the system, but also reduce bugs by, for example, preventing unintended resources from reading or writing to the database.
For this reason, the above code grants only read permission to the handler of <code>GET /haiku</code> API (notice the use of <code>grant_read_data()</code> method instead of <code>grant_read_write_data()</code>).</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_api_gateway">13.2.6. API Gateway</h4>
<div class="paragraph">
<p><a href="https://aws.amazon.com/api-gateway/">API Gateway</a> is literally an gateway that forwards API requests to Lambda, EC2, and other resources according to the API request path (<a href="#fig:bashoutter_api_ gateway">[fig:bashoutter_api_ gateway]</a>).
Then, the outputs of the processing performed by Lambda and EC2 are returned to the client via API Gateway.
In cloud terminology, the server that stands between the client and the backend server whose job is to forward the connection according to the API path is called a <strong>router</strong> or a <strong>reverse proxy</strong>.
Traditionally, routers are usually served by a dedicated virtual server.
API Gateway, on the other hand, is a serverless router service where it achieves routing without a fixed server.
API Gateway is dynamically launched only when the API request arrives.
As a natural consequence of being serverless, it has the ability to automatically increase its routing capacity as the number of accesses increases.</p>
</div>
<div id="fig:bashoutter_api_gateway" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/api_gateway.png" alt="api_gateway" width="700">
</div>
<div class="title">Figure 93. API Gateway</div>
</div>
<div class="paragraph">
<p>By deploying an API Gateway, one can easily build a system that can handle a large number of API requests (thousands to tens of thousands per second) without having to write codes.
The summary of the API Gateway cost is shown in <a href="#tab_handson_05_apigateway_price">Table 12</a>.
API Gateway also offers free tier, so up to one million requests per month can be used for free.</p>
</div>
<table id="tab_handson_05_apigateway_price" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 12. Pricing of API Gateway</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Number of Requests (per month)</th>
<th class="tableblock halign-left valign-top">Price (per million)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">First 333 million</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$4.25</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Next 667 million</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$3.53</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Next 19 billion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$3.00</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Over 20 billion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$1.91</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Let&#8217;s look at the source code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="code"><pre><i class="conum" data-value="1"></i><b>(1)</b>
<span class="n">api</span> <span class="o">=</span> <span class="n">apigw</span><span class="o">.</span><span class="n">RestApi</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="s">"BashoutterApi"</span><span class="p">,</span>
    <span class="n">default_cors_preflight_options</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">CorsOptions</span><span class="p">(</span>
        <span class="n">allow_origins</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">Cors</span><span class="o">.</span><span class="n">ALL_ORIGINS</span><span class="p">,</span>
        <span class="n">allow_methods</span><span class="o">=</span><span class="n">apigw</span><span class="o">.</span><span class="n">Cors</span><span class="o">.</span><span class="n">ALL_METHODS</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<i class="conum" data-value="2"></i><b>(2)</b>
<span class="n">haiku</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">add_resource</span><span class="p">(</span><span class="s">"haiku"</span><span class="p">)</span>
<i class="conum" data-value="3"></i><b>(3)</b>
<span class="n">haiku</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
    <span class="s">"GET"</span><span class="p">,</span>
    <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">get_haiku_lambda</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">haiku</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
    <span class="s">"POST"</span><span class="p">,</span>
    <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">post_haiku_lambda</span><span class="p">)</span>
<span class="p">)</span>

<i class="conum" data-value="4"></i><b>(4)</b>
<span class="n">haiku_item_id</span> <span class="o">=</span> <span class="n">haiku</span><span class="o">.</span><span class="n">add_resource</span><span class="p">(</span><span class="s">"{item_id}"</span><span class="p">)</span>
<i class="conum" data-value="5"></i><b>(5)</b>
<span class="n">haiku_item_id</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
    <span class="s">"PATCH"</span><span class="p">,</span>
    <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">patch_haiku_lambda</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">haiku_item_id</span><span class="o">.</span><span class="n">add_method</span><span class="p">(</span>
    <span class="s">"DELETE"</span><span class="p">,</span>
    <span class="n">apigw</span><span class="o">.</span><span class="n">LambdaIntegration</span><span class="p">(</span><span class="n">delete_haiku_lambda</span><span class="p">)</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>First, an empty API Gateway is created by <code>api = apigw.RestApi()</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Next, we add add the API path <code>/haiku</code> by calling the method <code>api.root.add_resource()</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Next, <code>add_method()</code> is called to define the <code>GET</code> and <code>POST</code> methods for the <code>/haiku</code> path.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Similarly, <code>haiku.add_resource("{item_id}")</code> adds the API path <code>/haiku/{item_id}</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Finally, <code>add_method()</code> is used to define <code>PATCH</code> and <code>DELETE</code> methods in the path <code>/haiku/{item_id}</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As you can see, API Gateway is very simple to use.
All you need to do is to sequentially describe the API path and the methods that will be executed.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When you create a new API with this program, a random URL will be assigned as the API endpoint.
If you want to host it in your own domain such as <code>example.com</code>, you can configure Domain Name System (DNS), such as Amazon Route 53, and add an appropriate record.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When we created a new API with API Gateway, the parameter <code>default_cors_preflight_options</code> was used to set up
<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">Cross Origin Resource Sharing (CORS)</a>.
This setting is necessary when accessing the API from a web browser.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_deploying_the_application_4">13.3. Deploying the application</h3>
<div class="paragraph">
<p>The deployment procedure is almost the same as the previous hands-on.
Here, only the commands are listed (lines starting with <code>#</code> are comments).
If you have forgotten the meaning of each command, review the first hands-on.
You should not forget to set the access key (<a href="#aws_cli_install">Section 14.3</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="c"># move to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>intro-aws/handson/bashoutter

<span class="c"># create venv and install dependent libraries</span>
<span class="nv">$ </span>python3 <span class="nt">-m</span> venv .env
<span class="nv">$ </span><span class="nb">source</span> .env/bin/activate
<span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Deploy!</span>
<span class="nv">$ </span>cdk deploy</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the deployment is successful, you should see an output like <a href="#handson_05_cdk_output">Figure 94</a>.
In the output you should find <code>Bashoutter.BashoutterApiEndpoint = XXXX</code> and <code>Bashoutter.BucketUrl = YYYY</code>.
We will use these string values later, so be sure to make notes of them.</p>
</div>
<div id="handson_05_cdk_output" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/cdk_output.png" alt="cdk output" width="700">
</div>
<div class="title">Figure 94. Output of <code>cdk deploy</code></div>
</div>
<div class="paragraph">
<p>Now, let&#8217;s log in to the AWS console and check the deployed stack.
First, go to the API Gateway page.
You will see a screen like <a href="#handson_05_apigw_console_list">Figure 95</a>, where you can check the list of deployed API endpoints.</p>
</div>
<div id="handson_05_apigw_console_list" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/apigw_console_list.png" alt="apigw_console_list" width="700">
</div>
<div class="title">Figure 95. API Gateway console (1)</div>
</div>
<div class="paragraph">
<p>By clicking on the API named "BashoutterApi", you can move to a screen like <a href="#handson_05_apigw_console_detail">Figure 96</a> and view detailed information.
You can see that <code>GET /haiku</code>, <code>POST /haiku</code>, and other APIs are defined.</p>
</div>
<div class="paragraph">
<p>Click on each method to see detailed information about that method.
In addition to the aforementioned routing functions, API Gateway can also be used to add authentication.
We won&#8217;t be using these authentication feature in this hands-on, but this feature will be useful in many web applications.
Next, in <a href="#handson_05_apigw_console_detail">Figure 96</a>, notice that the Lambda functions called by this API is shown in the area circled in red.
Clicking on the function name will take you to the console of the corresponding Lambda function, where you can view the contents of the function.</p>
</div>
<div id="handson_05_apigw_console_detail" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/apigw_console_detail.png" alt="apigw_console_detail" width="700">
</div>
<div class="title">Figure 96. API Gateway console (2)</div>
</div>
<div class="paragraph">
<p>Next, we will move to the S3 console.
There, you should be able to find a bucket whose name starts with <code>bashouter-XXXX</code> (where <code>XXXX</code> is some random string) (<a href="#handson_05_s3_console">Figure 97</a>).</p>
</div>
<div id="handson_05_s3_console" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/s3_console.png" alt="s3_console" width="700">
</div>
<div class="title">Figure 97. S3 console</div>
</div>
<div class="paragraph">
<p>Let&#8217;s check the contents of the bucket by clicking on the bucket name.
You will find the main html document, <code>index.html</code>, along with <code>css/</code>, <code>js/</code> and other directories which store the components to render the web page (<a href="#handson_05_s3_contents">Figure 98</a>).</p>
</div>
<div id="handson_05_s3_contents" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/s3_contents.png" alt="s3_contents" width="700">
</div>
<div class="title">Figure 98. The files in the S3 bucket</div>
</div>
</div>
<div class="sect2">
<h3 id="sec:bashoutter_test_api">13.4. Sending API requests</h3>
<div class="paragraph">
<p>Now, let&#8217;s actually send API requests to the deployed application.
First, let&#8217;s practice sending API requests from the command line.</p>
</div>
<div class="paragraph">
<p>Here we use a simple HTTP client tool,
<a href="https://httpie.org/">HTTPie</a>,
to send HTTP API requests from the command line.
HTTPie is installed together with the Python virtual environment (venv) when we deployed the stack.
To make sure that the installation is successful, activate the virtual environment and type <code>http</code> on the command line.
If you get a help message, you are ready to go.</p>
</div>
<div class="paragraph">
<p>First, set the URL of the API endpoint to a command line variableã€€(the <code>XXXX</code> string from <code>Bashoutter.BashoutterApiEndpoint = XXXX</code>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">export </span><span class="nv">ENDPOINT_URL</span><span class="o">=</span>XXXX</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, obtain a list of haiku by sending <code>GET /haiku</code> API.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http GET <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Unfortunately, there is no haiku registered in the database at this moment, so you will see an empty array (<code>[]</code>) as return.</p>
</div>
<div class="paragraph">
<p>Next, let&#8217;s post our very first haiku using <code>POST /haiku</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http POST <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku"</span> <span class="se">\</span>
<span class="nv">username</span><span class="o">=</span><span class="s2">"Mastuo Bashou"</span> <span class="se">\</span>
<span class="nv">first</span><span class="o">=</span><span class="s2">"the stillness"</span> <span class="se">\</span>
<span class="nv">second</span><span class="o">=</span><span class="s2">"penetrating the rock"</span> <span class="se">\</span>
<span class="nv">third</span><span class="o">=</span><span class="s2">"a cicada's cry"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The following output will be obtained.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>HTTP/1.1 201 Created
Connection: keep-alive
Content-Length: 49
Content-Type: application/json
....
{
    "description": "Successfully added a new haiku"
}</pre>
</div>
</div>
<div class="paragraph">
<p>It seems we successfully submited a new haiku.
Let&#8217;s confirm that the haiku is indeed added to the database by calling the GET request again.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http GET <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku"</span>

HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 258
Content-Type: application/json
...
<span class="o">[</span>
    <span class="o">{</span>
        <span class="s2">"created_at"</span>: <span class="s2">"2020-07-06T02:46:04+00:00"</span>,
        <span class="s2">"first"</span>: <span class="s2">"the stillness"</span>,
        <span class="s2">"item_id"</span>: <span class="s2">"7e91c5e4d7ad47909e0ac14c8bbab05b"</span>,
        <span class="s2">"likes"</span>: 0.0,
        <span class="s2">"second"</span>: <span class="s2">"penetrating the rock"</span>,
        <span class="s2">"third"</span>: <span class="s2">"a cicada's cry"</span>,
        <span class="s2">"username"</span>: <span class="s2">"Mastuo Bashou"</span>
    <span class="o">}</span>
<span class="o">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Excellent!</p>
</div>
<div class="paragraph">
<p>Next, let&#8217;s add a "like" to this haiku by calling <code>PATCH /haiku/{item_id}</code>.
To do this, run the following command after replacing <code>XXXX</code> with the ID of the haiku that you created in the previous command (i.e. <code>item_id</code> in the response text).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http PATCH <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku/XXXX"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You should get the output <code>{"description": "OK"}</code>.
We confirm that the number of likes has increased by 1 by sending the GET request one more time.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http GET <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku"</span>
...
<span class="o">[</span>
    <span class="o">{</span>
        ...
        <span class="s2">"likes"</span>: 1.0,
        ...
    <span class="o">}</span>
<span class="o">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Lastly, we delete the haiku by sending the DELETE request.
Run the following command after replacing <code>XXXX</code> with the ID of the haiku.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>http DELETE <span class="s2">"</span><span class="k">${</span><span class="nv">ENDPOINT_URL</span><span class="k">}</span><span class="s2">/haiku/XXXX"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>If we send GET request, the return will be an empty array (<code>[]</code>).</p>
</div>
<div class="paragraph">
<p>Now we were able to validate that the basic APIs for posting, retrieving, deleting, and adding "likes" to haiku are working properly.</p>
</div>
</div>
<div class="sect2">
<h3 id="_simulating_a_large_simultaneous_api_request">13.5. Simulating a large simultaneous API request</h3>
<div class="paragraph">
<p>In the previous section, we manually posted haiku one by one.
In a social networking service with a large number of users, several thousand haiku would be posted every second.
By adopting a serverless architecture, we have built a system that can easily handle such instantaneous heavy access.
To demonstrate this point, let&#8217;s simulate a situation where a large number of APIs are sent to the system.</p>
</div>
<div class="paragraph">
<p>In
<a href="https://github.com/tomomano/learn-aws-by-coding/blob/main/handson/bashoutter/client.py">handson/bashoutter/client.py</a>,
we provide a short script to send many API requests simultaneously.
By using this script, we can send <code>POST /haiku</code> API request for a specified number of times.</p>
</div>
<div class="paragraph">
<p>As a test, we will send the API request for 300 times.
Run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python client.py <span class="nv">$ENDPOINT_URL</span> post_many 300</code></pre>
</div>
</div>
<div class="paragraph">
<p>The execution would be completed in a matter of seconds.
If this API had been supported by a single server, it would have taken much longer to process such a large number of requests.
In the worst case, it might have even led to a server shutdown.
The serverless application we have created is a very simple yet scalable cloud system that can handle hundreds of requests every second.
Did you get a glimpse of the benefits and power of a serverless cloud?</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you submit a large number of haiku using the above command, the database will be filled with useless data.
To completely empty the database, use the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python client.py <span class="nv">$ENDPOINT_URL</span> clear_database</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_interacting_with_bashoutter_gui">13.6. Interacting with Bashoutter GUI</h3>
<div class="paragraph">
<p>In the previous part, we practiced sending APIs from the command line.
In a web application, the exact same thing is done behind a web browser to display the contents of a page (see <a href="#fig:web_server">Figure 74</a>).
Lastly, let&#8217;s see what happens when the API is integrated with the GUI.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s check the URL given by <code>Bashoutter.BucketUrl=</code> that is output on the command line when we deployed the stack (<a href="#handson_05_cdk_output">Figure 94</a>).
As mentioned earlier, this is the URL of the S3 bucket in public access mode.</p>
</div>
<div class="paragraph">
<p>Open a web browser and enter the URL of S3 in the address bar to access it.
You should see a page like shown in <a href="#handson_05_bashoutter_2">Figure 99</a>.</p>
</div>
<div id="handson_05_bashoutter_2" class="imageblock text-center">
<div class="content">
<img src="imgs/handson-bashoutter/bashoutter_2.png" alt="bashoutter" width="700">
</div>
<div class="title">Figure 99. Bashoutter GUI</div>
</div>
<div class="paragraph">
<p>When the page is loaded, enter the URL of the <strong>API Gateway</strong> you deployed in the text box at the top that says "API Endpoint URL".
(In this application, the API Gateway URL is randomly assigned, so the GUI is designed like this.)
Then, press the "REFRESH" button on the screen.
If you have already registered some haiku in the database, you will see a list of haiku.
Click on the heart icon at the bottom left of each haiku to give it a "like" vote.</p>
</div>
<div class="paragraph">
<p>To submit a new haiku, enter the new phrase and the name of the author, then press "POST".
After pressing "POST", be sure to press the "REFRESH" button again to retrieve the latest list of haiku from the database.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deleting_the_stack_5">13.7. Deleting the stack</h3>
<div class="paragraph">
<p>This concludes the Bashoutter project!
We created an SNS that can be accessed from anywhere in the world via the Internet.
As we demonstrated in <a href="#simulating_many_apis">[simulating_many_apis]</a>, Bashoutter can scale flexibly to handle a large number of simultaneous access without delay.
Although it is extremely simple, it satisfies the basic requirements for an modern and scalable web service!</p>
</div>
<div class="paragraph">
<p>When you have enjoyed Bashoutter application, don&#8217;t forget to delete the stack.</p>
</div>
<div class="paragraph">
<p>To delete the stack from the command line, use the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk destroy</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Depending on the version of CDK, <code>cdk destroy</code> may output an error if the S3 bucket is not empty.
In this case, you have to delete all the files in the S3 bucket before deleting the stack.</p>
</div>
<div class="paragraph">
<p>To do this from the AWS console, go to the S3 console, open the bucket, select all the files, and execute "Actions" &#8594; "Delete".</p>
</div>
<div class="paragraph">
<p>To do this from the command line, use the following command.
Remember to replace &lt;BUCKET NAME&gt; with the name of your bucket.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 <span class="nb">rm</span> &lt;BUCKET NAME&gt; <span class="nt">--recursive</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_short_summary_2">13.8. Short summary</h3>
<div class="paragraph">
<p>This is the end of Part III of this book.</p>
</div>
<div class="paragraph">
<p>In Part III, we focused on how to create web applications and databases that can be used by the general public as an application of cloud computing.
Along the way, we explained the traditional design of cloud systems and the latest design method called serverless architecture.
In <a href="#sec_intro_serverless">Section 12</a>, we practiced serverless architecture in AWS by using Lambda, S3, and DynamoDB.
Finally, in <a href="#sec_bashoutter">Section 13</a>, we integrated these serverless technologies to create a simple web application called "Bashoutter".</p>
</div>
<div class="paragraph">
<p>Through these exercises, we hope you have gained a better understanding of how web services are developed and maintained in the real world.
We also hope that this hands-on session was a good starting point for you to create amazing web application yourself.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec:appendix_settingup">14. Appendix: Environment setup</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To read through this book, you need to set up an environment on your local machine to run the hands-on programs.
Assuming that you are a beginner in AWS and the command line, this chapter will briefly explain how to install the necessary software and libraries.
A brief table of contents is shown below.
If you have already built your environment, you need to read through only the relevant parts.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Creating an AWS account (<a href="#sec:create_aws_account">Section 14.1</a>)</p>
</li>
<li>
<p>Creating AWS access key (<a href="#aws_secrets">Section 14.2</a>)</p>
</li>
<li>
<p>Installing AWS CLI (<a href="#aws_cli_install">Section 14.3</a>)</p>
</li>
<li>
<p>Installing AWS CDK (<a href="#aws_cdk_install">Section 14.4</a>)</p>
</li>
<li>
<p>Installing WSL (<a href="#sec:install_wsl">Section 14.5</a>)</p>
</li>
<li>
<p>Installing Docker (<a href="#sec:install_docker">Section 14.6</a>)</p>
</li>
<li>
<p>Quick tutorial on Python venv (<a href="#venv_quick_guide">Section 14.7</a>)</p>
</li>
<li>
<p>Working with Docker image for the hands-on exercises (<a href="#sec_handson_docker">Section 14.8</a>)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The OS can be Linux, Mac, or Windows.
Windows users are assumed to use Windows Subsytem for Linux (WSL) (<a href="#sec:install_wsl">Section 14.5</a>).</p>
</div>
<div class="paragraph">
<p>You can also use the
<a href="https://hub.docker.com/repository/docker/tomomano/labc">Docker image</a>
to run the hands-on programs in this book.
This will be useful for readers who know how to use Docker, as it allows them to skip AWS CLI/CDK and Python installation.</p>
</div>
<div class="sect2">
<h3 id="sec:create_aws_account">14.1. Creating an AWS account</h3>
<div class="paragraph">
<p>In order to try the hands-on exercises provided in this book, you need to create your own AWS account.
Detailed instructions for creating an account can be found at
<a href="https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/">official documentation</a>,
so please refer to that as well.
Follow the steps below to create an account.</p>
</div>
<div class="paragraph">
<p>First, access <a href="https://aws.amazon.com/console/">AWS Management Console</a> from your web browser, and click <code>Create an AWS Account</code> in the upper right corner.
(<a href="#fig:aws-signup-1">Figure 100</a>, boxed with a solid line).</p>
</div>
<div id="fig:aws-signup-1" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-1.png" alt="signup-1" width="500">
</div>
<div class="title">Figure 100. Sign up (1) - Accessing AWS Management Console</div>
</div>
<div class="paragraph">
<p>Then, you will be taken to a page where you register your email address and password (<a href="#fig:aws-signup-3">Figure 101</a>).</p>
</div>
<div id="fig:aws-signup-3" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-3.png" alt="signup-3" width="500">
</div>
<div class="title">Figure 101. Sign up (2): Register email and password</div>
</div>
<div class="paragraph">
<p>Next, you will be asked to enter your address, phone number, and other information (<a href="#fig:aws-signup-4">Figure 102</a>).</p>
</div>
<div id="fig:aws-signup-4" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-4.png" alt="signup-4" width="500">
</div>
<div class="title">Figure 102. Sign up (3): Entering address and phone number</div>
</div>
<div class="paragraph">
<p>Next, you will be asked to register your credit card information (<a href="#fig:aws-signup-5">Figure 103</a>).
If you are using AWS as an individual, you will be billed for your usage via your credit card.
Note that you cannot start using AWS without registering your credit card information.</p>
</div>
<div id="fig:aws-signup-5" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-5.png" alt="signup-5" width="500">
</div>
<div class="title">Figure 103. Sign up (4): Registering a credit card</div>
</div>
<div class="paragraph">
<p>On the next page, you will be asked to verify your identity using SMS or voice message on your cell phone (<a href="#fig:aws-signup-6">Figure 104</a>).
Select your preferred authentication method and enter your cell phone number.</p>
</div>
<div id="fig:aws-signup-6" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-6.png" alt="signup-6" width="500">
</div>
<div class="title">Figure 104. Sign up (5): Identify verification by cell phone</div>
</div>
<div class="paragraph">
<p>After successfully verifying your identity, you will be asked to select a support plan (<a href="#fig:aws-signup-8">Figure 105</a>).
You can just select the Basic support plan, which is free.</p>
</div>
<div id="fig:aws-signup-8" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-8.png" alt="signup-8" width="500">
</div>
<div class="title">Figure 105. Sign up (6): Selecting a support plan</div>
</div>
<div class="paragraph">
<p>These steps will complete the creation of your account (<a href="#fig:aws-signup-9">Figure 106</a>).
Let&#8217;s log in and see if we can access the AWS console.</p>
</div>
<div id="fig:aws-signup-9" class="imageblock text-center">
<div class="content">
<img src="imgs/signup-9.png" alt="signup-9" width="500">
</div>
<div class="title">Figure 106. Sign up (7): Sign up is complete!</div>
</div>
</div>
<div class="sect2">
<h3 id="aws_secrets">14.2. Creating AWS access key</h3>
<div class="paragraph">
<p>AWS access key is a key used for user authentication when operating the AWS API from the AWS CLI or AWS CDK.
To use the AWS CLI/CDK, you need to issue a secret key first.
For more information on AWS secret keys, please refer to
<a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html">the official documentation "Understanding and getting your AWS credentials"</a>.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>First, log in to your AWS console</p>
</li>
<li>
<p>Then, click on your account name in the upper right corner of the screen, and select "My Security Credentials" from the pull-down menu (<a href="#fig:aws_secret_key_1">Figure 107</a>)</p>
</li>
<li>
<p>Under "Access keys for CLI, SDK, &amp; API access", find the button that says "Create accesss key" and click it (<a href="#fig:aws_secret_key_2">Figure 108</a>)</p>
</li>
<li>
<p>Record the displayed access key ID and secret access key (if you close the window, they will not be displayed again)</p>
</li>
<li>
<p>If you forget your key, you can reissue it by the same procedure</p>
</li>
<li>
<p>Use the issued secret key by writing it to the file <code>~/.aws/credentials</code> or by setting it to an environment variable (also see <a href="#aws_cli_install">Section 14.3</a>)</p>
</li>
</ol>
</div>
<div id="fig:aws_secret_key_1" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_secret_key_1.png" alt="aws_secret_key_1" width="400">
</div>
<div class="title">Figure 107. Creating an AWS secret key (1)</div>
</div>
<div id="fig:aws_secret_key_2" class="imageblock text-center">
<div class="content">
<img src="imgs/aws_secret_key_2.png" alt="aws_secret_key_2" width="700">
</div>
<div class="title">Figure 108. Creating an AWS secret key (2)</div>
</div>
</div>
<div class="sect2">
<h3 id="aws_cli_install">14.3. Installing AWS CLI</h3>
<div class="paragraph">
<p>This is a brief description of the installation procedure for Linux at the time of writing.
Please remember to always check
<a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">official documentation</a>
for the latest information, as it may change in future versions.</p>
</div>
<div class="paragraph">
<p>Installation of AWS CLI version 2 can be done by downloading and executing the installation script:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>curl <span class="s2">"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"</span> <span class="nt">-o</span> <span class="s2">"awscliv2.zip"</span>
<span class="nv">$ </span>unzip awscliv2.zip
<span class="nv">$ </span><span class="nb">sudo</span> ./aws/install</code></pre>
</div>
</div>
<div class="paragraph">
<p>To confirm that the installation is successful, type the following command to see if the version information is displayed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws <span class="nt">--version</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the installation is complete, run the following command to finish the initial set up (also see <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html">official documentation "Configuring the AWS CLI"</a>).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws configure</code></pre>
</div>
</div>
<div class="paragraph">
<p>When you execute this command, you will be prompted to enter the <code>AWS Access Key ID</code> and <code>AWS Secret Access Key</code>.
See <a href="#aws_secrets">Section 14.2</a> for issuing access keys.
The command also asks for the <code>Default region name</code>.
You can specify your favorite region (e.g. <code>ap-northeast-1</code> = Tokyo) here.
The last entry, <code>Default output format</code>, should be <code>json</code>.</p>
</div>
<div class="paragraph">
<p>After completing this command, you should see files named <code>~/.aws/credentials</code> and <code>~/.aws/config</code>, where the relevant information is stored.
To be sure, you can use the <code>cat</code> command to check the contents.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">cat</span> ~/.aws/credentials
<span class="o">[</span>default]
aws_access_key_id <span class="o">=</span> XXXXXXXXXXXXXXXXXX
aws_secret_access_key <span class="o">=</span> YYYYYYYYYYYYYYYYYYY

<span class="nv">$ </span><span class="nb">cat</span> ~/.aws/config
<span class="o">[</span>profile default]
region <span class="o">=</span> ap-northeast-1
output <span class="o">=</span> json</code></pre>
</div>
</div>
<div class="paragraph">
<p>Authentication key information is stored in <code>~/.aws/credentials</code>, and AWS CLI settings are stored in <code>~/.aws/config</code>.</p>
</div>
<div class="paragraph">
<p>By default, a profile is saved with the name <code>[default]</code>.
If you want to use several different profiles, follow the default example and add a profile with your favorite name.</p>
</div>
<div class="paragraph">
<p>In order to swtich your profile when executing AWS CLI commands, add <code>--profile</code> parameter:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>aws s3 <span class="nb">ls</span> <span class="nt">--profile</span> myprofile</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you find that adding <code>--profile</code> each time you run a command is tedious, you can set the environemntal variable named <code>AWS_PROFILE</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">export </span><span class="nv">AWS_PROFILE</span><span class="o">=</span>myprofile</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or, you can set the access key information in the environmental variables.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nb">export </span><span class="nv">AWS_ACCESS_KEY_ID</span><span class="o">=</span>XXXXXX
<span class="nb">export </span><span class="nv">AWS_SECRET_ACCESS_KEY</span><span class="o">=</span>YYYYYY
<span class="nb">export </span><span class="nv">AWS_DEFAULT_REGION</span><span class="o">=</span>ap-northeast-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>These environmental variables have higher priority than the profiles defined in <code>~/.aws/credentials</code>, so the profie defined by environemtal variables are used (see also
<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html">official documentation "Configuring the AWS CLI"</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="aws_cdk_install">14.4. Installing AWS CDK</h3>
<div class="paragraph">
<p>This is a brief description of the installation procedure for Linux at the time of writing.
Please remember to always check
<a href="https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html">official documentation</a>
for the latest information, as it may change in future versions.</p>
</div>
<div class="paragraph">
<p>If you have Node.js installed, you can install AWS CDK by the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">sudo </span>npm <span class="nb">install</span> <span class="nt">-g</span> aws-cdk</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The hands-on exercises were developed with AWS CDK version 1.100.
Since CDK is a library under active development, the API may change in the future.
If errors occur due to API changes, it is recommended to use version 1.100.0.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>npm <span class="nb">install</span> <span class="nt">-g</span> aws-cdk@1.100</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To confirm that the installation is successful, type the following command to see if the version information is displayed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk <span class="nt">--version</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the installation is complete, run the following command to finish the initial set up:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>cdk bootstrap</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When you run <code>cdk bootstrap</code>, make sure that your AWS credentials and region are set correctly.
By default, the default profile in <code>~/.aws/config</code> is used.
If you want to use a profile other than the default, use the technique described in <a href="#aws_cli_install">Section 14.3</a> to switch profiles.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The configuration of AWS credentials for CDK is basically the same as that of AWS CLI.
See <a href="#aws_cli_install">Section 14.3</a> for details.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="sec:install_wsl">14.5. Installing WSL</h3>
<div class="paragraph">
<p>In this book, the commands are basically written with a UNIX terminal in mind.
Linux and Mac users can use the terminal that comes standard with their OS.
If you are using Windows, we recommend that you use
<a href="https://docs.microsoft.com/en-us/windows/wsl/">Windows Subsystem for Linux (WSL)</a>
to create a virtual Linux environment.
Other tools that emulate the Linux environment, such as
<a href="https://www.cygwin.com/">Cygwin</a>,
are also acceptable, but the programs in this book have been tested only on WSL.</p>
</div>
<div class="paragraph">
<p>WSL is software officially provided by Microsoft to run a Linux virtual environment on a Windows OS.
You can select the Linux distribution you want, such as Ubuntu, and use basically all programs and software made for Linux.</p>
</div>
<div class="paragraph">
<p>At the time of writing,
<a href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions#whats-new-in-wsl-2">WSL 2</a>
is the latest release.
In the following, we will explain the steps to install WSL 2.
For more details, also refer to the
<a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">official documentation</a>.</p>
</div>
<div class="paragraph">
<p>As a prerequisite, the OS must be Windows 10 (Pro or Home edition).
Furthermore, make sure that the version of Windows 10 you are using supports WSL.
For X64 systems, it must be Version 1903, Build 18362 or higher.
If the version does not support WSL, update Windows first.</p>
</div>
<div class="paragraph">
<p>First, start PowerShell with administrator privileges (<a href="#fig:powershell">Figure 109</a>).
To do this, type <code>powershell</code> in the search bar of the Windows menu in the lower left corner, and you should find the PowerShell program.
Then, right-click on it, and select <code>Run as administrator</code> to launch.</p>
</div>
<div id="fig:powershell" class="imageblock text-center">
<div class="content">
<img src="imgs/wsl/powershell.png" alt="powershell" width="500">
</div>
<div class="title">Figure 109. Starting PowerShell with administrator privileges</div>
</div>
<div class="paragraph">
<p>Once the PowerShell is ready, execute the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash">dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the execution, make sure that the command outputs the line <code>â€œThe operation completed successfullyâ€</code>.
Now WSL is enabled on your Windows.</p>
</div>
<div class="paragraph">
<p>Next, using the same PowerShell started with administrator privileges, execute the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash">dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the execution, make sure that the command outputs the line <code>â€œThe operation completed successfullyâ€</code>.
Once this is done, restart your computer.</p>
</div>
<div class="paragraph">
<p>Next, download <strong>Linux kernel update package</strong> from the following link:
<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi" class="bare">https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi</a></p>
</div>
<div class="paragraph">
<p>Double-click on the downloaded file to run it.
Follow the dialog to complete the installation.</p>
</div>
<div class="paragraph">
<p>After that, come back to PowerShell and run the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash">wsl <span class="nt">--set-default-version</span> 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Lastly, install the Linux distribution of your choice.
In this tutorial, let&#8217;s install <strong>Ubuntu 20.04</strong>.</p>
</div>
<div class="paragraph">
<p>Launch the Microsoft Store app and type <code>Ubuntu</code> in the search bar.
Open Ubuntu 20.04 LTS and click the "Get" button (<a href="#fig:microsoft_store">Figure 110</a>).
Wait for a while, and the installation of Ubuntu 20.04 will be completed.</p>
</div>
<div id="fig:microsoft_store" class="imageblock text-center">
<div class="content">
<img src="imgs/wsl/microsoft_store.png" alt="microsoft_store" width="500">
</div>
<div class="title">Figure 110. Installing Ubuntu 20.04 from Microsoft Store</div>
</div>
<div class="paragraph">
<p>The first time you start Ubuntu 20.04, the initial setup will start automatically and you will have to wait for a few minutes.
After the initial setup, you will be prompted to enter your user name and password.</p>
</div>
<div class="paragraph">
<p>This completes the installation of WSL2.
Let&#8217;s launch WSL2!
Type <code>Ubuntu</code> in the search bar of the Windows menu in the lower left corner, and you should find Ubuntu 20.04 (<a href="#fig:ubuntu">Figure 111</a>).
Click on it to start it.</p>
</div>
<div id="fig:ubuntu" class="imageblock text-center">
<div class="content">
<img src="imgs/wsl/ubuntu2004.png" alt="ubuntu2004" width="500">
</div>
<div class="title">Figure 111. Launching Ubuntu 20.04</div>
</div>
<div class="paragraph">
<p>This should bring up a black terminal screen (<a href="#fig:wsl_window">Figure 112</a>).
Try typing <code>ls</code>, <code>top</code>, etc. to confirm that WSL is working properly.</p>
</div>
<div id="fig:wsl_window" class="imageblock text-center">
<div class="content">
<img src="imgs/wsl/wsl_window.png" alt="wsl_window" width="500">
</div>
<div class="title">Figure 112. WSL terminal</div>
</div>
<div class="paragraph">
<p>Optionally, you can install
<a href="https://docs.microsoft.com/en-us/windows/terminal/get-started">Windows Terminal</a>.
Windows Terminal is a tool provided by Microsoft, which gives you more functional and comfortable interface to work with WSL.
We recommend that you to install this tool.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec:install_docker">14.6. Installing Docker</h3>
<div class="paragraph">
<p>The installation method of Docker varies depending on the OS.</p>
</div>
<div class="paragraph">
<p>Mac users should install Docker Desktop.
All you need do is to download Docker Desktop for Mac from
<a href="https://docs.docker.com/docker-for-mac/install/">Docker&#8217;s website</a>,
double-click the downloaded file, and then drag it to the <code>Applications</code> folder.
For more information, see
<a href="https://docs.docker.com/docker-for-mac/install/">official documentation</a>.</p>
</div>
<div class="paragraph">
<p>Windows users should install Docker Desktop.
WSL 2 must be installed in your machine prior to installing Docker Desktop.
See
<a href="https://docs.docker.com/desktop/windows/install/">official documentation</a>
for more information.
After installing Docker Desktop, you can use the <code>docker</code> command from WSL.</p>
</div>
<div class="paragraph">
<p>For Linux users (especially Ubuntu users), there are several approaches to installation.
For more information, please refer to
<a href="https://docs.docker.com/engine/install/ubuntu/">official documentation</a>.
The simplest approach is to use the official Docker installation script.
In this case, the following command will install Docker.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://get.docker.com <span class="nt">-o</span> get-docker.sh
<span class="nv">$ </span><span class="nb">sudo </span>sh get-docker.sh</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the default installation, only the root user is allowed to use the <code>docker</code> command.
Therefore, you need to add <code>sudo</code> to the command every time.
If you find this cumbersome, follow these steps to add the user you are working with to the <code>docker</code> group
(For more information see
<a href="https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user">official documentation "Post-installation steps for Linux"</a>).</p>
</div>
<div class="paragraph">
<p>The first step is to add a group named <code>docker</code>.
Depending on your installation, the <code>docker</code> group may already be created.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">sudo </span>groupadd docker</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, add the user you are currently using to the <code>docker</code> group.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">sudo </span>usermod <span class="nt">-aG</span> docker <span class="nv">$USER</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Once this is done, log out and log back in.
The changes to the group will be reflected in your terminal session.</p>
</div>
<div class="paragraph">
<p>To check if the settings are correct, run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run hello-world</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you can run the container withoug adding <code>sudo</code>, the setting is complete.</p>
</div>
</div>
<div class="sect2">
<h3 id="venv_quick_guide">14.7. Quick tutorial on Python <code>venv</code></h3>
<div class="paragraph">
<p>Many of you may have experienced a situation where a program given to you by someone else does not work because of the library version mismatch.
If you have only one Python environment in your machine, you will have to re-install the correct version every time you switch projects.
This is a lot of work!</p>
</div>
<div class="paragraph">
<p>To make code sharing smoother, library versions should be managed on a project-by-project basis.
This is made possible by tools called <strong>Python virtual environments</strong>.
Programs such as
<a href="https://docs.python.org/3/tutorial/venv.html">venv</a>,
<a href="https://github.com/pyenv/pyenv">pyenv</a>,
and
<a href="https://docs.conda.io/en/latest/">conda</a>
are often used for this purpose.</p>
</div>
<div class="paragraph">
<p>Among them,  <code>venv</code> is very useful because it is included in Python as a standard feature.
Tools like <code>pyenv</code> and <code>conda</code> require separate installation, but they have their own advantages.</p>
</div>
<div class="paragraph">
<p>To create a new virtual environment using <code>venv</code>, you run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>python <span class="nt">-m</span> venv .env</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will create a directory <code>.env/</code> in which the libraries for this virtual environment will be saved.</p>
</div>
<div class="paragraph">
<p>To activate this new virtual environment, you run the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span><span class="nb">source</span> .env/bin/activate</code></pre>
</div>
</div>
<div class="paragraph">
<p>Notice that the shell prompt starts with <code>(.env)</code> (<a href="#fig_venv_prompt">Figure 113</a>).
This is a sign that signifies, "You are now in a venv".</p>
</div>
<div id="fig_venv_prompt" class="imageblock text-center">
<div class="content">
<img src="imgs/venv_shell.png" alt="venv shell" width="500">
</div>
<div class="title">Figure 113. Shell prompt after activating venv</div>
</div>
<div class="paragraph">
<p>When the virtual Python environment is activated, all subsequent <code>pip</code> commands will install libraries under <code>.env/</code> directory.
In this way, you can separate the version of the library used for each project.</p>
</div>
<div class="paragraph">
<p>In Python, it is common practice to describe the dependent libraries in a file called <code>requirements.txt</code>.
If a project you are workin on has a <code>requirements.txt</code> file defined, you can use the following command to install dependent libraries and reproduce the Python environment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can give arbitrary name to the directory where the virtual environment is saved by <code>venv</code>, but the name <code>.env</code> is commonly used.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="sec_handson_docker">14.8. Working with Docker image for the hands-on exercise</h3>
<div class="paragraph">
<p>We prepared a Docker image with Node.js, Python, AWS CDK, etc. installed, which is necessary to run the hands-on exercises.
Using this image, you can run the hands-on code immediately without having to install anything on your local machine.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Some of the commands in the hands-on must be executed outside of Docker (i.e. in the real environment on your local machine).
These are described as notes in the corresponding part of the hands-on.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Docker image is provided at
<a href="https://hub.docker.com/repository/docker/tomomano/labc">the author&#8217;s Docker Hub repository</a>ï¼Ž
The build file for the Docker image is available at
<a href="https://github.com/tomomano/learn-aws-by-coding-source-code/blob/main/docker/Dockerfile">GitHub</a>.</p>
</div>
<div class="paragraph">
<p>Use the following command to launch the container.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">-it</span> tomomano/labc:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first time you run the command, the image will be downloaded (pulled) from Docker Hub.
From the second time onward, the locally downloaded image will be used.</p>
</div>
<div class="paragraph">
<p>When the container is started, you should see an interactive shell like the following (note the <code>-it</code> option at startup).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>root@aws-handson:~$</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the container shell, if you type the <code>ls</code> command, you should find a directory <code>handson/</code>.
Now you move to this directory.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ cd handson</pre>
</div>
</div>
<div class="paragraph">
<p>You will find a directory for each hands-on.
Then, you can move the directory for each exercise, create a Python virtual environment, and deploy the stack (see <a href="#sec_handson_ec2_run">Section 4.4</a>, etc.).
Since each hands-on uses different dependent libraries, the design is to create a virtualenv for each hands-on.</p>
</div>
<div class="paragraph">
<p>Don&#8217;t forget to set your AWS credentials.
An easy way to do this is to set environment variables such as <code>AWS_ACCESS_KEY_ID</code> as described in <a href="#aws_cli_install">Section 14.3</a>.
Alternatively, if your credentials are stored in local machine&#8217;s <code>~/.aws/credentials</code>, you can <strong>mount</strong> this directory in the container and refer to the same credentials file from inside the container.
If you take this option, start the container with the following command.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><span class="nv">$ </span>docker run <span class="nt">-it</span> <span class="nt">-v</span> ~/.aws:/root/.aws:ro tomomano/labc:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>This allows you to mount <code>~/.aws</code> on the local machine to <code>/root/.aws</code> in the container.
The <code>:ro</code> at the end means read-only.
It is recommended to add the read-only flag to prevent accidental rewriting of important authentication files.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>/root/</code> is the home directory in the container environment.
The technique of mounting the authentication file described here can also be used when passing SSH keys to the container.</p>
</div>
</td>
</tr>
</table>
</div>
<style>
  .imageblock > .title {
    text-align: inherit;
  }
</style>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 1.0-en<br>
Last updated 2022-01-13 14:29:12 UTC
</div>
</div>
<style>
pre.rouge table td { padding: 5px; }
pre.rouge table pre { margin: 0; }
pre.rouge .cm {
  color: #999988;
  font-style: italic;
}
pre.rouge .cp {
  color: #999999;
  font-weight: bold;
}
pre.rouge .c1 {
  color: #999988;
  font-style: italic;
}
pre.rouge .cs {
  color: #999999;
  font-weight: bold;
  font-style: italic;
}
pre.rouge .c, pre.rouge .ch, pre.rouge .cd, pre.rouge .cpf {
  color: #999988;
  font-style: italic;
}
pre.rouge .err {
  color: #a61717;
  background-color: #e3d2d2;
}
pre.rouge .gd {
  color: #000000;
  background-color: #ffdddd;
}
pre.rouge .ge {
  color: #000000;
  font-style: italic;
}
pre.rouge .gr {
  color: #aa0000;
}
pre.rouge .gh {
  color: #999999;
}
pre.rouge .gi {
  color: #000000;
  background-color: #ddffdd;
}
pre.rouge .go {
  color: #888888;
}
pre.rouge .gp {
  color: #555555;
}
pre.rouge .gs {
  font-weight: bold;
}
pre.rouge .gu {
  color: #aaaaaa;
}
pre.rouge .gt {
  color: #aa0000;
}
pre.rouge .kc {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kd {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kn {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kp {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kr {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kt {
  color: #445588;
  font-weight: bold;
}
pre.rouge .k, pre.rouge .kv {
  color: #000000;
  font-weight: bold;
}
pre.rouge .mf {
  color: #009999;
}
pre.rouge .mh {
  color: #009999;
}
pre.rouge .il {
  color: #009999;
}
pre.rouge .mi {
  color: #009999;
}
pre.rouge .mo {
  color: #009999;
}
pre.rouge .m, pre.rouge .mb, pre.rouge .mx {
  color: #009999;
}
pre.rouge .sb {
  color: #d14;
}
pre.rouge .sc {
  color: #d14;
}
pre.rouge .sd {
  color: #d14;
}
pre.rouge .s2 {
  color: #d14;
}
pre.rouge .se {
  color: #d14;
}
pre.rouge .sh {
  color: #d14;
}
pre.rouge .si {
  color: #d14;
}
pre.rouge .sx {
  color: #d14;
}
pre.rouge .sr {
  color: #009926;
}
pre.rouge .s1 {
  color: #d14;
}
pre.rouge .ss {
  color: #990073;
}
pre.rouge .s, pre.rouge .sa, pre.rouge .dl {
  color: #d14;
}
pre.rouge .na {
  color: #008080;
}
pre.rouge .bp {
  color: #999999;
}
pre.rouge .nb {
  color: #0086B3;
}
pre.rouge .nc {
  color: #445588;
  font-weight: bold;
}
pre.rouge .no {
  color: #008080;
}
pre.rouge .nd {
  color: #3c5d5d;
  font-weight: bold;
}
pre.rouge .ni {
  color: #800080;
}
pre.rouge .ne {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nf, pre.rouge .fm {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nl {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nn {
  color: #555555;
}
pre.rouge .nt {
  color: #000080;
}
pre.rouge .vc {
  color: #008080;
}
pre.rouge .vg {
  color: #008080;
}
pre.rouge .vi {
  color: #008080;
}
pre.rouge .nv, pre.rouge .vm {
  color: #008080;
}
pre.rouge .ow {
  color: #000000;
  font-weight: bold;
}
pre.rouge .o {
  color: #000000;
  font-weight: bold;
}
pre.rouge .w {
  color: #bbbbbb;
}
pre.rouge {
  background-color: #f8f8f8;
}
</style>
</body>
</html>